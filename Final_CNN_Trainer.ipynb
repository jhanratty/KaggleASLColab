{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5c251a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:00.056762Z",
     "iopub.status.busy": "2023-04-27T09:22:00.056345Z",
     "iopub.status.idle": "2023-04-27T09:22:01.788737Z",
     "shell.execute_reply": "2023-04-27T09:22:01.787457Z",
     "shell.execute_reply.started": "2023-04-27T09:22:00.056725Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNING JUPITER LOCAL\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # Colab\n",
    "    print(\"RUNING ON COLAB\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASE_DIR = \"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
    "    WORKING_DIR = \"/content/asl-work\"\n",
    "    ARCHIVE_DIR = \"/content/drive/MyDrive/GaggleSignLang\"\n",
    "    MODEL_DIR = \"/content/drive/MyDrive/GaggleSignLang/models\"\n",
    "elif os.environ.get('KAGGLE_KERNEL_RUN_TYPE'):\n",
    "    # KAGGLE\n",
    "    print(\"RUNNING ON KAGGLE\")\n",
    "    BASE_DIR = \"/kaggle/input/asl-signs\"\n",
    "    WORKING_DIR = \"/kaggle/working\"\n",
    "    ARCHIVE_DIR = \"/kaggle/working\"\n",
    "    MODEL_DIR  = \"/kaggle/working\"\n",
    "else: \n",
    "    # Jupiter  MacOS\n",
    "    print(\"RUNING JUPITER LOCAL\")\n",
    "    BASE_DIR = \"/Users/johnhanratty/ASLtest/asl-signs\"  #\"/Users/johnhanratty/ASLtest/asl-signs\"\n",
    "    WORKING_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "    ARCHIVE_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "    MODEL_DIR = \"/Users/johnhanratty/ASLtest/models\"\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import seed, sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
    "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
    "\n",
    "FRAMES_OUT = 32 # 16\n",
    "PTS_IN_FRAME = 345\n",
    "DIMC = [0,1,2]\n",
    "DIMS = len(DIMC)\n",
    "WORKERS = 0   # dataoader work var  0 for MAC, 4 for online\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a36e3d",
   "metadata": {},
   "source": [
    "# Create Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a74c4d",
   "metadata": {},
   "source": [
    "## Read Parquet Files (provided)\n",
    "Routine provide by contest to read parquet file containing a video (i.e. landmarks of video) of one sign frame sequence.  Each video can contain 8-500+ frames with different frame rates (frames per second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41802f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:06.975674Z",
     "iopub.status.busy": "2023-04-27T09:22:06.975115Z",
     "iopub.status.idle": "2023-04-27T09:22:06.982263Z",
     "shell.execute_reply": "2023-04-27T09:22:06.981046Z",
     "shell.execute_reply.started": "2023-04-27T09:22:06.975635Z"
    }
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb924a",
   "metadata": {},
   "source": [
    "# Video Preprocessing Model (FeatureGen)\n",
    "The FeatureGen() model recieves one video from the load_relevant_data_subset() and preprocesses it for machine learning. This model was initially written in Numpy but convered to Pytorch tensors to aid the Pytorch to Onnx to tflite conversion.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6048e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:24.657013Z",
     "iopub.status.busy": "2023-04-27T09:22:24.656552Z",
     "iopub.status.idle": "2023-04-27T09:22:24.672857Z",
     "shell.execute_reply": "2023-04-27T09:22:24.671586Z",
     "shell.execute_reply.started": "2023-04-27T09:22:24.656974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Len 675 165 165 180 165\n"
     ]
    }
   ],
   "source": [
    "# CNN TORCH FEATUREGEN MODEL \n",
    "ROWS_PER_FRAME = 543  # combined face, lefth, pose, righth\n",
    "PR_PTS = [40, 44, 48, 52, 56, 60, 43, 46, 50, 54, 58]\n",
    "SC_PTS = [40, 98, 102, 106, 110, 114, 97, 102, 106, 110, 114]\n",
    "PO_PTS = [60, 73, 80, 81, 76, 77, 68, 69, 70, 71, 75, 74]\n",
    "LI_PTS = [5, 0, 4, 8, 12, 16, 20, 24, 28, 32, 36]\n",
    "PR_LEN = len(PR_PTS) * DIMS * 5  # 5 = number of aggregations e.g. max,min\n",
    "SC_LEN = len(SC_PTS) * DIMS * 5\n",
    "PO_LEN = len(PO_PTS) * DIMS * 5\n",
    "LI_LEN = len(LI_PTS) * DIMS * 5\n",
    "CNN_FEAT_LEN = PR_LEN + SC_LEN + PO_LEN + LI_LEN \n",
    "\n",
    "print(\"Feature Len\", CNN_FEAT_LEN, PR_LEN, SC_LEN, PO_LEN, LI_LEN)\n",
    "\n",
    "# FILTER FEATURES IN EACH FRAME  - FACE, POSE & HANDs\n",
    "class FeatureGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x)\n",
    "        \n",
    "        # FILTER TO SPECIFIED FRAMES (FRAMES_OUT)\n",
    "        seed(24)\n",
    "        n_frames = x.size()[0]\n",
    "        # Trim to # of frames to FRAMES_OUT\n",
    "        if n_frames > FRAMES_OUT:\n",
    "            idx = sorted((sample(range(0, n_frames), FRAMES_OUT)))\n",
    "            x=x[idx]\n",
    "        n_frames = x.size()[0]\n",
    "        # FLATTENING ROWS BY TYPE and CONCATENATING TO ONE ROW PER FRAME 3D (XYZ)\n",
    "        # INPUT NUMPY, TORCH OUTPUT\n",
    "\n",
    "        # The Video contains n_frames each containing exactly ROWS_PER_FRAME (543)frames.\n",
    "        # The frames in each are in order of feature type.\n",
    "        # The rows conain x, y, z for a feature\n",
    "        #   Video Format = [n_frames][543 frames][3 xyz coordinates]\n",
    "        \n",
    "        # Create views by data type (e.g. one point on hand) \n",
    "        # by selecting rows for each frame\n",
    "        # face_x = x[:,:468,:].contiguous().view(-1, 468*3)\n",
    "        lips_idx = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "        lips_x = x[:, lips_idx,:].contiguous().view(-1, len(lips_idx)*3)\n",
    "        lefth_x = x[:,468:489,:].contiguous().view(-1, 21*3)\n",
    "        pose_x = x[:,489:522,:].contiguous().view(-1, 33*3)\n",
    "        righth_x = x[:,522:,:].contiguous().view(-1, 21*3)\n",
    "\n",
    "        # Check for primary hand and if left hand swap and rotate hands\n",
    "        if torch.isnan(lefth_x).sum() < torch.isnan(righth_x).sum():\n",
    "            prime_x = lefth_x\n",
    "            second_x = righth_x\n",
    "        else:\n",
    "            prime_x = righth_x.reshape(righth_x.size()[0], -1, DIMS)\n",
    "            prime_x[:,:,0] = torch.from_numpy(np.subtract(np.nanmax(prime_x[:,:,0].numpy(), axis=1).reshape(-1,1),\n",
    "                                    prime_x[:, :, 0].numpy()))\n",
    "            prime_x = prime_x.reshape(prime_x.size()[0],-1)\n",
    "            \n",
    "            second_x = lefth_x.reshape(lefth_x.size()[0], -1, DIMS)\n",
    "            second_x[:,:,0] = torch.from_numpy(np.subtract(np.nanmax(second_x[:,:,0].numpy(), axis=1).reshape(-1,1),\n",
    "                                          second_x[:, :, 0].numpy()))\n",
    "            second_x = second_x.reshape(second_x.size()[0],-1)\n",
    "            \n",
    "        \n",
    "        # create video withfixed number of frames (FRAMES_OUT)\n",
    "        # initialize with NoN so later operations can ignore them (e.g. nanmean()) \n",
    "        xfeat = torch.full([FRAMES_OUT, PTS_IN_FRAME], np.nan)\n",
    "        \n",
    "        # center frames\n",
    "        offset = (FRAMES_OUT - n_frames) // 2  # center frames in output data in each frame in video\n",
    "        \n",
    "        # flatten types into one row per frame\n",
    "        xfeat[offset:n_frames+offset,:] = torch.cat([lips_x, prime_x, pose_x, second_x], axis=1)  # concatenate types\n",
    "        \n",
    "        ############# CNN Specific\n",
    "        # function aggregates frames in one row\n",
    "        # which contains mean, median, max, min and var of frames\n",
    "        def distDiff(ds, ref, pts):\n",
    "            ds = ds.reshape(ds.size()[0],  -1, DIMS)\n",
    "            d = torch.hstack([torch.from_numpy(np.nanmean(ds[:, pts, :].numpy(), axis=0)), \n",
    "                           torch.from_numpy( np.nanmedian(ds[:, pts, :].numpy(), axis=0)), \n",
    "                           torch.from_numpy(np.nanmax(ds[:, pts, :].numpy(), axis=0)), \n",
    "                           torch.from_numpy(np.nanmin(ds[:, pts, :].numpy(), axis=0)),\n",
    "                           torch.from_numpy(np.nanvar(ds[:, pts, :].numpy(), axis=0))\n",
    "                           ]) \n",
    "            d = d.reshape(1, -1) \n",
    "            # NORMALIZE\n",
    "            # d = (d - np.nanmean(d, keepdims=True)) / np.nanstd(d, keepdims=True) # -1 to 1\n",
    "            # Replace NaN with zeros\n",
    "            d = torch.where(torch.isnan(d), torch.tensor(0.0, dtype=torch.float32), d)\n",
    "            return d\n",
    "        \n",
    "        # \n",
    "        d1 = distDiff(xfeat, 40, PR_PTS)\n",
    "        d2 = distDiff(xfeat, 40, SC_PTS)\n",
    "        d3 = distDiff(xfeat, 60, PO_PTS)\n",
    "        d4 = distDiff(xfeat, 5,  LI_PTS)\n",
    "        \n",
    "        return torch.cat([d1,d2,d3,d4], axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1fee39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T10:13:04.044426Z",
     "iopub.status.busy": "2023-04-27T10:13:04.043547Z",
     "iopub.status.idle": "2023-04-27T10:16:04.541551Z",
     "shell.execute_reply": "2023-04-27T10:16:04.540255Z",
     "shell.execute_reply.started": "2023-04-27T10:13:04.044379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert&Save (94477, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 94477/94477 [13:36<00:00, 115.73it/s]\n"
     ]
    }
   ],
   "source": [
    "## PROCESS EACH ROW (ONE PARQUET PER ROW)\n",
    "def convert_row(row):\n",
    "    x = load_relevant_data_subset(os.path.join(BASE_DIR, row[1].path))\n",
    "    x = feature_converter(torch.tensor(x))\n",
    "    return x, row[1].label\n",
    "\n",
    "## LOOP THROUGH PARQUET FILES LISTED IN TRAIN FILE\n",
    "##  SAVE RESULTS \n",
    "def convert_and_save_data():\n",
    "    label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    \n",
    "    print(\"Convert&Save\", df.shape)\n",
    "    #### FOR TESTING #################\n",
    "    #df = df[0:20]\n",
    "    ##################################\n",
    "\n",
    "    npdata = np.zeros((df.shape[0], CNN_FEAT_LEN))  \n",
    "\n",
    "    nplabels = np.zeros(df.shape[0])\n",
    "    \n",
    "    results = map(convert_row, df.iterrows())\n",
    "    for i, (x,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
    "            npdata[i,:] = x\n",
    "            nplabels[i] = y\n",
    "    return npdata, nplabels\n",
    " \n",
    "\n",
    "feature_converter = FeatureGen()\n",
    "datax, datay = convert_and_save_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1762d25f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "np.save(f\"{ARCHIVE_DIR}/cnn_data{FRAMES_OUT}.npy\", datax)\n",
    "np.save(f\"{ARCHIVE_DIR}/cnn_labels.npy\", datay)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b5fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Load dataset\n",
    "datax = np.load(f\"{ARCHIVE_DIR}/cnn_data{FRAMES_OUT}.npy\")\n",
    "datay = np.load(f\"{ARCHIVE_DIR}/cnn_labels.npy\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704dc178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:34.423269Z",
     "iopub.status.busy": "2023-04-27T11:16:34.422846Z",
     "iopub.status.idle": "2023-04-27T11:16:34.445881Z",
     "shell.execute_reply": "2023-04-27T11:16:34.444872Z",
     "shell.execute_reply.started": "2023-04-27T11:16:34.423234Z"
    }
   },
   "outputs": [],
   "source": [
    "#MODEL\n",
    "### NEW SEPARATED INPUTS\n",
    "class ASLData(Dataset):\n",
    "    def __init__(self,datax,datay):\n",
    "        self.datax = datax\n",
    "        self.datay = datay\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datax[index, :], self.datay[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datay)\n",
    "\n",
    "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(ASLModel, self).__init__()\n",
    "        \n",
    "        # DATA in [1, CNN_FEAT_LEN] per video\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        L1OUT = 512  #1024 was ok\n",
    "        L2OUT = 512\n",
    "\n",
    "        self.layer_ph = nn.Linear(PR_LEN, L1OUT)\n",
    "        self.batchnorm_ph = nn.BatchNorm1d(L1OUT)\n",
    "        \n",
    "        self.layer_sh = nn.Linear(SC_LEN, L1OUT)\n",
    "        self.batchnorm_sh = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_po = nn.Linear(PO_LEN, L1OUT)\n",
    "        self.batchnorm_po = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_li = nn.Linear(LI_LEN, L1OUT)\n",
    "        self.batchnorm_li = nn.BatchNorm1d(L1OUT) \n",
    " \n",
    "        self.layer1 = nn.Linear(4*L1OUT, L2OUT)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(L2OUT)\n",
    "\n",
    "        self.layerFC = nn.Linear(L2OUT, 250)\n",
    "        self.softmax = nn.Softmax()\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        phand = x[:,0:PR_LEN]            \n",
    "        shand = x[:,PR_LEN:(PR_LEN+PR_LEN)]\n",
    "        pose =  x[:,(PR_LEN+PR_LEN):(PR_LEN+PR_LEN+PO_LEN)]  \n",
    "        lips =  x[:,(PR_LEN+PR_LEN+PO_LEN):CNN_FEAT_LEN]  \n",
    "        \n",
    "        ph = self.flatten(torch.tensor(phand).float()) \n",
    "        ph = self.layer_ph(ph)\n",
    "        ph = self.batchnorm_ph(ph)\n",
    "        ph = self.relu(ph)\n",
    "        ph = self.dropout(ph)\n",
    "\n",
    "        sh = self.flatten(torch.tensor(shand).float())       \n",
    "        sh = self.layer_sh(sh)\n",
    "        sh = self.batchnorm_sh(sh)\n",
    "        sh = self.relu(sh)\n",
    "        sh = self.dropout(sh)\n",
    "       \n",
    "        po = self.flatten(torch.tensor(pose).float())       \n",
    "        po = self.layer_po(po)\n",
    "        po = self.batchnorm_po(po)\n",
    "        po = self.relu(po)\n",
    "        po = self.dropout(po)\n",
    "        \n",
    "        li = self.flatten(torch.tensor(lips).float())       \n",
    "        li = self.layer_li(li)\n",
    "        li = self.batchnorm_li(li)\n",
    "        li = self.relu(li)\n",
    "        li = self.dropout(li)\n",
    "\n",
    "        x = torch.cat((ph.view(ph.size(0), -1),\n",
    "                       sh.view(sh.size(0), -1),\n",
    "                       po.view(po.size(0), -1),\n",
    "                       li.view(li.size(0), -1)), dim=1)\n",
    "        # x = self.batchnorm0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layerFC(x)\n",
    "       # x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652f101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   truth  cnn\n",
      "0  206.0   78\n",
      "1   20.0   96\n",
      "2  178.0  103\n",
      "3  114.0  114\n",
      "4  221.0  221\n",
      "(14172, 250)\n"
     ]
    }
   ],
   "source": [
    "  PATH = f\"{MODEL_DIR}/model_ccn{FRAMES_OUT}.sd\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/model_ccn{FRAMES_OUT}.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# Save Pred and Perf\n",
    "x = testx.detach().numpy()\n",
    "prob_cnn = model(torch.tensor(x)).detach().numpy()\n",
    "\n",
    "pred_list['cnn'] = np.argmax(prob_cnn, axis=1)\n",
    "print(pred_list.head())\n",
    "\n",
    "with open(f\"{ARCHIVE_DIR}/pred_cnn{FRAMES_OUT}.pkl\", 'wb') as f1:\n",
    "       pickle.dump(pred_list, f1)\n",
    "with open(f\"{ARCHIVE_DIR}/prob_cnn{FRAMES_OUT}.pkl\", 'wb') as f1:\n",
    "       pickle.dump(prob_cnn, f1)\n",
    "print(prob_cnn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f30afac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:40.228537Z",
     "iopub.status.busy": "2023-04-27T11:16:40.227418Z",
     "iopub.status.idle": "2023-04-27T11:17:22.481778Z",
     "shell.execute_reply": "2023-04-27T11:17:22.480359Z",
     "shell.execute_reply.started": "2023-04-27T11:16:40.228485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++using CPU++++\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:0 > Train Loss: 3.4987, Train Acc: 0.2172\n",
      "Epoch:0 > Val Loss: 3.0151, Val Acc: 0.2730\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:1 > Train Loss: 2.3660, Train Acc: 0.4130\n",
      "Epoch:1 > Val Loss: 2.4597, Val Acc: 0.4073\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:2 > Train Loss: 2.0093, Train Acc: 0.4924\n",
      "Epoch:2 > Val Loss: 1.8661, Val Acc: 0.5386\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:3 > Train Loss: 1.7829, Train Acc: 0.5446\n",
      "Epoch:3 > Val Loss: 1.8927, Val Acc: 0.5210\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:4 > Train Loss: 1.6201, Train Acc: 0.5777\n",
      "Epoch:4 > Val Loss: 1.5717, Val Acc: 0.6154\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:5 > Train Loss: 1.4902, Train Acc: 0.6105\n",
      "Epoch:5 > Val Loss: 1.5503, Val Acc: 0.6134\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:6 > Train Loss: 1.3824, Train Acc: 0.6349\n",
      "Epoch:6 > Val Loss: 1.4339, Val Acc: 0.6494\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:7 > Train Loss: 1.3005, Train Acc: 0.6564\n",
      "Epoch:7 > Val Loss: 1.3642, Val Acc: 0.6674\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:8 > Train Loss: 1.2351, Train Acc: 0.6714\n",
      "Epoch:8 > Val Loss: 1.3427, Val Acc: 0.6722\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:9 > Train Loss: 1.1838, Train Acc: 0.6855\n",
      "Epoch:9 > Val Loss: 1.3181, Val Acc: 0.6794\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:10 > Train Loss: 1.1381, Train Acc: 0.6932\n",
      "Epoch:10 > Val Loss: 1.2877, Val Acc: 0.6881\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:11 > Train Loss: 1.1019, Train Acc: 0.7029\n",
      "Epoch:11 > Val Loss: 1.2730, Val Acc: 0.6936\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:12 > Train Loss: 1.0779, Train Acc: 0.7104\n",
      "Epoch:12 > Val Loss: 1.2692, Val Acc: 0.6930\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:13 > Train Loss: 1.0541, Train Acc: 0.7130\n",
      "Epoch:13 > Val Loss: 1.2594, Val Acc: 0.6972\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:14 > Train Loss: 1.0284, Train Acc: 0.7205\n",
      "Epoch:14 > Val Loss: 1.2485, Val Acc: 0.6962\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:15 > Train Loss: 1.0153, Train Acc: 0.7253\n",
      "Epoch:15 > Val Loss: 1.2430, Val Acc: 0.7002\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:16 > Train Loss: 1.0010, Train Acc: 0.7265\n",
      "Epoch:16 > Val Loss: 1.2460, Val Acc: 0.7010\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:17 > Train Loss: 0.9898, Train Acc: 0.7298\n",
      "Epoch:17 > Val Loss: 1.2408, Val Acc: 0.7009\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:18 > Train Loss: 0.9884, Train Acc: 0.7311\n",
      "Epoch:18 > Val Loss: 1.2397, Val Acc: 0.7004\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:19 > Train Loss: 0.9742, Train Acc: 0.7363\n",
      "Epoch:19 > Val Loss: 1.2374, Val Acc: 0.7012\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:20 > Train Loss: 0.9728, Train Acc: 0.7344\n",
      "Epoch:20 > Val Loss: 1.2348, Val Acc: 0.7020\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:21 > Train Loss: 0.9621, Train Acc: 0.7390\n",
      "Epoch:21 > Val Loss: 1.2339, Val Acc: 0.7018\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:22 > Train Loss: 0.9571, Train Acc: 0.7378\n",
      "Epoch:22 > Val Loss: 1.2332, Val Acc: 0.7022\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:23 > Train Loss: 0.9602, Train Acc: 0.7385\n",
      "Epoch:23 > Val Loss: 1.2376, Val Acc: 0.7015\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:24 > Train Loss: 0.9636, Train Acc: 0.7367\n",
      "Epoch:24 > Val Loss: 1.2332, Val Acc: 0.7012\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:25 > Train Loss: 0.9565, Train Acc: 0.7395\n",
      "Epoch:25 > Val Loss: 1.2352, Val Acc: 0.7031\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:26 > Train Loss: 0.9572, Train Acc: 0.7368\n",
      "Epoch:26 > Val Loss: 1.2322, Val Acc: 0.7022\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:27 > Train Loss: 0.9529, Train Acc: 0.7403\n",
      "Epoch:27 > Val Loss: 1.2357, Val Acc: 0.7017\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:28 > Train Loss: 0.9540, Train Acc: 0.7393\n",
      "Epoch:28 > Val Loss: 1.2335, Val Acc: 0.7036\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:29 > Train Loss: 0.9512, Train Acc: 0.7385\n",
      "Epoch:29 > Val Loss: 1.2334, Val Acc: 0.7029\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:30 > Train Loss: 0.9549, Train Acc: 0.7383\n",
      "Epoch:30 > Val Loss: 1.2378, Val Acc: 0.7033\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:31 > Train Loss: 0.9464, Train Acc: 0.7431\n",
      "Epoch:31 > Val Loss: 1.2327, Val Acc: 0.7021\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:32 > Train Loss: 0.9518, Train Acc: 0.7413\n",
      "Epoch:32 > Val Loss: 1.2348, Val Acc: 0.7022\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:33 > Train Loss: 0.9527, Train Acc: 0.7395\n",
      "Epoch:33 > Val Loss: 1.2362, Val Acc: 0.7017\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:34 > Train Loss: 0.9487, Train Acc: 0.7395\n",
      "Epoch:34 > Val Loss: 1.2337, Val Acc: 0.7017\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:35 > Train Loss: 0.9514, Train Acc: 0.7388\n",
      "Epoch:35 > Val Loss: 1.2353, Val Acc: 0.7024\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:36 > Train Loss: 0.9449, Train Acc: 0.7419\n",
      "Epoch:36 > Val Loss: 1.2338, Val Acc: 0.7034\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:37 > Train Loss: 0.9498, Train Acc: 0.7410\n",
      "Epoch:37 > Val Loss: 1.2348, Val Acc: 0.7036\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:38 > Train Loss: 0.9457, Train Acc: 0.7406\n",
      "Epoch:38 > Val Loss: 1.2338, Val Acc: 0.7031\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:39 > Train Loss: 0.9477, Train Acc: 0.7410\n",
      "Epoch:39 > Val Loss: 1.2341, Val Acc: 0.7015\n",
      "==================================================\n",
      "   truth  cnn\n",
      "0  206.0   78\n",
      "1   20.0   96\n",
      "2  178.0   41\n",
      "3  114.0  114\n",
      "4  221.0  221\n",
      "(14172, 250)\n",
      "Accuracy: 0.7015241320914479\n",
      "#### ELAPSED TIME: 1659.1623864250141\n"
     ]
    }
   ],
   "source": [
    "## MULTI TRAINING\n",
    "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"++++using GPU++++\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"++++using CPU++++\")\n",
    "\n",
    "EPOCHS = 21\n",
    "BATCH_SIZE = 64\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
    "#datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
    "\n",
    "# init list for saving predictions for ensemble processing\n",
    "pred_list = pd.DataFrame(testy, columns=[\"truth\"])\n",
    "\n",
    "train_data = ASLData(trainx, trainy)\n",
    "valid_data = ASLData(testx, testy)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=True)\n",
    "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=False)\n",
    "model = ASLModel(0.2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_sum = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_bar = train_loader\n",
    "    for x,y in train_bar:\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device) \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_sum += loss.item()\n",
    "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "        train_total += 1\n",
    "        sched.step()\n",
    "        \n",
    "    val_loss_sum = 0.\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    for x,y in val_loader:\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            val_loss_sum += loss.item()\n",
    "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "            val_total += 1\n",
    "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
    "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
    "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Save the pytorch model\n",
    "PATH = f\"{MODEL_DIR}/model_ccn{FRAMES_OUT}.sd\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/model_ccn{FRAMES_OUT}.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# Save Pred and Perf\n",
    "x = testx.detach().numpy()\n",
    "prob_cnn = model(torch.tensor(x)).detach().numpy()\n",
    "\n",
    "pred_list['cnn'] = np.argmax(prob_cnn, axis=1)\n",
    "print(pred_list.head())\n",
    "\n",
    "with open(f\"{ARCHIVE_DIR}/pred_cnn{FRAMES_OUT}.pkl\", 'wb') as f1:\n",
    "       pickle.dump(pred_list, f1)\n",
    "with open(f\"{ARCHIVE_DIR}/prob_cnn{FRAMES_OUT}.pkl\", 'wb') as f1:\n",
    "       pickle.dump(prob_cnn, f1)\n",
    "print(prob_cnn.shape)\n",
    "\n",
    "print(\"Accuracy:\", np.mean(pred_list.truth == pred_list.cnn))\n",
    "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49046438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:21 > Train Loss: 0.9673, Train Acc: 0.7361\n",
    "# Epoch:21 > Val Loss: 1.2287, Val Acc: 0.7047\n",
    "# ==================================================\n",
    "\n",
    "# ========Full Data - no add Norm, Centered ========\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:38 > Train Loss: 0.9867, Train Acc: 0.7321\n",
    "# Epoch:38 > Val Loss: 1.2608, Val Acc: 0.6988\n",
    "# ==================================================\n",
    "\n",
    "# ========Full Data - no additional Normalizeation/Centering=====================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.4974, Train Acc: 0.6059\n",
    "# Epoch:39 > Val Loss: 1.7298, Val Acc: 0.5839\n",
    "# ==================================================\n",
    "\n",
    "# =====Full no reverse, centered =============================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.2104, Train Acc: 0.6745\n",
    "# Epoch:39 > Val Loss: 1.4204, Val Acc: 0.6515\n",
    "# ==================================================\n",
    "# Additional Normalize and Nan Step  0.6100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee18c7f",
   "metadata": {},
   "source": [
    "# Torch Single Model Save, Retrieve and Rum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53e89433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE MODEL\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/modeltccn{FRAMES_OUT}flat.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "817a73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD MODEL\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/modeltccn{FRAMES_OUT}flat.pt\"\n",
    "mod = torch.load(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cd9f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PYTORCH MODELS\n",
    "class AModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AModel, self).__init__()\n",
    "        \n",
    "        self.InputFormat = FeatureGen() #feature_converter\n",
    "        self.InferModel = mod\n",
    "        self.InferModel.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.InputFormat(x)\n",
    "        pred = self.InferModel(x)\n",
    "        return pred\n",
    "\n",
    "mod_cnn = AModel()\n",
    "mod_cnn_pt_path = f\"{MODEL_DIR}/modelcnn{FRAMES_OUT}test.pt\"\n",
    "torch.save(mod_cnn, mod_cnn_pt_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "885e7ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 2022    56\n",
      "Name: label, dtype: int64 2022    dance\n",
      "Name: sign, dtype: object prediction= 56\n"
     ]
    }
   ],
   "source": [
    "# Run merged PyTorch Model\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "\n",
    "mod_cnn_pt_path = f\"{MODEL_DIR}/modelcnn{FRAMES_OUT}test.pt\"\n",
    "Infmodel = torch.load(mod_cnn_pt_path)\n",
    "\n",
    "d = df[2022:2023]\n",
    "\n",
    "x = load_relevant_data_subset(os.path.join(BASE_DIR, d['path'].item()))\n",
    "pred = Infmodel(x)\n",
    "\n",
    "print(\"truth:\", d.label, d.sign, \"prediction=\", np.argmax(pred.detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cdfa49",
   "metadata": {},
   "source": [
    "# TFLITE CONVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68a4e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 09:30:43.203079: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --quiet --root-user-action=ignore\n",
    "!pip install tensorflow_probability --quiet --root-user-action=ignore\n",
    "\n",
    "!pip install onnx-tf --quiet --root-user-action=ignore\n",
    "!pip install tflite-runtime  --quiet --root-user-action=ignore\n",
    "import onnx_tf\n",
    "import tflite_runtime\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55d70d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 09:50:42.993522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input' with dtype float and shape [?,615]\n",
      "\t [[{{node input}}]]\n",
      "2023-04-30 09:50:42.993602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '10241' with dtype float and shape [512]\n",
      "\t [[{{node 10241}}]]\n",
      "2023-04-30 09:50:42.993649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '10253' with dtype float and shape [512]\n",
      "\t [[{{node 10253}}]]\n",
      "2023-04-30 09:50:42.993717: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '10265' with dtype float and shape [512]\n",
      "\t [[{{node 10265}}]]\n",
      "2023-04-30 09:50:42.993832: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '10277' with dtype float and shape [512]\n",
      "\t [[{{node 10277}}]]\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "2023-04-30 09:50:43.879157: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input' with dtype float and shape [?,615]\n",
      "\t [[{{node serving_default_input}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{MODEL_DIR}/tf_mod_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{MODEL_DIR}/tf_mod_cnn/assets\n"
     ]
    }
   ],
   "source": [
    "## CNN MODEL CONVERSION\n",
    "# pmodel_path = f\"{ARCHIVE_DIR}/models/modelccn16flat.sd\"\n",
    "# modelc = ASLModel(.1)\n",
    "# modelc.load_state_dict(torch.load(py_model_path))\n",
    "# modelc.eval()\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/modeltccn{FRAMES_OUT}flat.pt\"\n",
    "mod = torch.load(PATH)\n",
    "\n",
    "\n",
    "sample_input = torch.rand((64, 615)).float()\n",
    "onnx_mod_cnn_path = f\"{MODEL_DIR}/model_cnn.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    mod,                    # PyTorch Model\n",
    "    sample_input,             # Input tensor\n",
    "    onnx_mod_cnn_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_mod_cnn_gen = onnx.load(onnx_mod_cnn_path)\n",
    "tf_rep = prepare(onnx_mod_cnn_gen)\n",
    "\n",
    "tf_mod_cnn_path = 'f\"{MODEL_DIR}/tf_mod_cnn'\n",
    "tf_rep.export_graph(tf_mod_cnn_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdbc2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "INFO:tensorflow:Assets written to: f\"{MODEL_DIR}/tf_gen_feat/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{MODEL_DIR}/tf_gen_feat/assets\n"
     ]
    }
   ],
   "source": [
    "## FEAT_GEN MODEL CONVERSION\n",
    "# pmodel_path = f\"{ARCHIVE_DIR}/models/modelccn16flat.sd\"\n",
    "# modelc = ASLModel(.1)\n",
    "# modelc.load_state_dict(torch.load(py_model_path))\n",
    "# modelc.eval()\n",
    "\n",
    "gen_feat = FeatureGen()\n",
    "\n",
    "sample_input = torch.rand((50, 543, 3))\n",
    "onnx_gen_feat_path = f\"{MODEL_DIR}/gen_featt.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    gen_feat,                    # PyTorch Model\n",
    "    sample_input,             # Input tensor\n",
    "    onnx_gen_feat_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_feat_gen = onnx.load(onnx_gen_feat_path)\n",
    "tf_rep = prepare(onnx_feat_gen)\n",
    "\n",
    "tf_gen_feat_path = 'f\"{MODEL_DIR}/tf_gen_feat'\n",
    "tf_rep.export_graph(tf_gen_feat_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0770c837",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_85568/180413784.py\", line 16, in call  *\n        features = self.feature_gen(**{'input': input})['output']\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m mytfmodel \u001b[38;5;241m=\u001b[39m ASLInferModel()\n\u001b[1;32m     22\u001b[0m INFER_PATH\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tf_infer_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m---> 23\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mINFER_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1240\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1240\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1402\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1399\u001b[0m       augmented_graph_view)\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n\u001b[1;32m   1404\u001b[0m signature_map \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mcreate_signature_map(signatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:131\u001b[0m, in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    129\u001b[0m wrapped_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature_key, function \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 131\u001b[0m   original_function \u001b[38;5;241m=\u001b[39m signature_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m signature_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a TensorFlow function for which to generate a signature, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Only `tf.functions` with an input signature or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcrete functions can be used as a signature.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:43\u001b[0m, in \u001b[0;36m_get_signature\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_signature\u001b[39m(function):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(function, (defun\u001b[38;5;241m.\u001b[39mFunction, def_function\u001b[38;5;241m.\u001b[39mFunction)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     42\u001b[0m       function\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     function \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:484\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/__autograph_generated_fileuw_uiuth.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 11\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(output_tensors)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel, (), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, (ag__\u001b[38;5;241m.\u001b[39mld(features), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)}), fscope)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:740\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_85568/180413784.py\", line 16, in call  *\n        features = self.feature_gen(**{'input': input})['output']\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ASLInferModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLInferModel, self).__init__()\n",
    "        self.feature_gen = tf.saved_model.load(tf_gen_feat_path)\n",
    "        self.model = tf.saved_model.load(tf_mod_cnn_path)\n",
    "        self.feature_gen.trainable = False\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
    "    ])\n",
    "    def call(self, input):\n",
    "        output_tensors = {}\n",
    "        features = self.feature_gen(**{'input': input})['output']\n",
    "        output_tensors['outputs'] = self.model(**{'input': tf.expand_dims(features, 0)})['output'][0,:]\n",
    "        return output_tensors\n",
    "    \n",
    "    \n",
    "mytfmodel = ASLInferModel()\n",
    "INFER_PATH=f'{MODEL_DIR}/tf_infer_model', \n",
    "tf.saved_model.save(mytfmodel, \n",
    "                    INFER_PATH, \n",
    "                    signatures={'serving_default': mytfmodel.call})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, save_model_path) # save as savemodel form\n",
    "test_model = tf.keras.models.load_model(save_model_path, custom_objects={\"TFBertModel\": transformers.TFBertModel}) # load model and point out the custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1016b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "INSIDE \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_82561/3126969839.py\", line 17, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m mytfmodel \u001b[38;5;241m=\u001b[39m ASLInferModel()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tf_infer_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1240\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1240\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1402\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1399\u001b[0m       augmented_graph_view)\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n\u001b[1;32m   1404\u001b[0m signature_map \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mcreate_signature_map(signatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:131\u001b[0m, in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    129\u001b[0m wrapped_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature_key, function \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 131\u001b[0m   original_function \u001b[38;5;241m=\u001b[39m signature_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m signature_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a TensorFlow function for which to generate a signature, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Only `tf.functions` with an input signature or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcrete functions can be used as a signature.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:43\u001b[0m, in \u001b[0;36m_get_signature\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_signature\u001b[39m(function):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(function, (defun\u001b[38;5;241m.\u001b[39mFunction, def_function\u001b[38;5;241m.\u001b[39mFunction)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     42\u001b[0m       function\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     function \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:484\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/__autograph_generated_filefga8zaue.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINSIDE \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(output_tensors)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:740\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_82561/3126969839.py\", line 17, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ASLInferModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLInferModel, self).__init__()\n",
    "        tf_mod_cnn_path = 'f\"{MODEL_DIR}/tf_mod_cnn'\n",
    "\n",
    "        self.model = tf.saved_model.load(tf_mod_cnn_path)\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
    "    ])\n",
    "    def call(self, input):\n",
    "        output_tensors = {}\n",
    "        print(\"INSIDE \")\n",
    "        output_tensors['outputs'] = self.model(**{'input': input})\n",
    "        print(\"2\")\n",
    "        return output_tensors\n",
    "    \n",
    "    \n",
    "mytfmodel = ASLInferModel()\n",
    "print(\"ok\")\n",
    "tf.saved_model.save(mytfmodel, \n",
    "                    f'{MODEL_DIR}/tf_infer_model', \n",
    "                    signatures={'serving_default': mytfmodel.call})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b09b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO TFLITE\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_mod_cnn_path) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "# Save the model.\n",
    "TF_MODEL_PATH_LITE = f\"{MODEL_DIR}/model_cnn.tflite\"\n",
    "with open(TF_MODEL_PATH, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_PATH_LITE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "print(\"found_signatures\")\n",
    "print(found_signatures[0])\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))   ###CHANGE\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "\n",
    "vid = df.iloc[26].path\n",
    "x = load_relevant_data_subset(f\"{BASE_DIR}/{vid}\")\n",
    "output = prediction_fn(x)\n",
    "#interpreter.invoke()\n",
    "\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b83bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
