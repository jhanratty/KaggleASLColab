{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## FROM: End-to-End Pytorch Training & Submission\n",
        "(Kaggle Notebook) https://www.kaggle.com/code/mayukh18/end-to-end-pytorch-training-submission/notebook"
      ],
      "metadata": {
        "id": "Q45YQFhBqZP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr45cYjhsA6K",
        "outputId": "0f2089a0-ee30-4df1-b61b-c082a112789c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jupiter  MacOS\n",
        "# BASE_DIR = \"/Users/johnhanratty/Library/CloudStorage/OneDrive-Personal/IRMA_GIT/Kaggle_SignLanguage/asl-signs\"\n",
        "# WORKING_DIR = BASE_DIR\n",
        "# !pip install nb_black --quiet\n",
        "# %load_ext lab_black\n",
        "\n",
        "# Colab\n",
        "BASE_DIR = \"/content/asl-signs\"   #\"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
        "WORKING_DIR = \"/content/asl-work\"\n",
        "# !pip install nb_black --quiet\n",
        "# print('-----ok')\n",
        "# %load_ext nb_black\n",
        "\n",
        "# KAGGLE\n",
        "# BASE_DIR = \"/kaggle/input/asl-signs\"\n",
        "# WORKING_DIR = \"/kaggle/working/\"\n",
        "# !pip install nb_black --quiet --root-user-action=ignore\n",
        "# %load_ext lab_black\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
        "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
        "\n",
        "FRAMES_OUT = 12 #16 # 16\n",
        "PTS_IN_FRAME = 115\n",
        "DIMS = 2\n",
        "\n",
        "print('done')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-15T22:04:26.371365Z",
          "iopub.execute_input": "2023-03-15T22:04:26.372355Z",
          "iopub.status.idle": "2023-03-15T22:04:36.169556Z",
          "shell.execute_reply.started": "2023-03-15T22:04:26.372296Z",
          "shell.execute_reply": "2023-03-15T22:04:36.168229Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3XL8evoqZP4",
        "outputId": "1e3e134c-698d-4403-c551-ca800fb13682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COLAB ONLY - DOWNLOAD / EXTRACT PARQUET\n",
        "# Load ASL data for COLAB TO INSTANCE\n",
        "# requires \"/content/kaggle.json\" that is Kaggle token\n",
        "# https://towardsdatascience.com/7-ways-to-load-external-data-into-google-colab-7ba73e7d5fc7 \n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists('/content/asl-signs'):\n",
        "   print(\"Running in Colab and need asl-signs data files\")\n",
        "   from datetime import datetime\n",
        "   print('*******************************')\n",
        "   print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "   shutil.copy(\"/content/drive/MyDrive/GaggleSignLang/asl-signs.zip\", \"/content\")\n",
        "\n",
        "   print('*******************************')\n",
        "   print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "   from zipfile import ZipFile\n",
        "   with ZipFile('/content/asl-signs.zip', 'r') as f:\n",
        "     f.extractall('/content/asl-signs')\n",
        "   \n",
        "   print('*******************************')\n",
        "   print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "else:\n",
        "   print(\"ok\")\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists(WORKING_DIR):\n",
        "  !mkdir '/content/asl-work'\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "  shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/sign_to_prediction_index_map.json\", f\"{WORKING_DIR}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-0p38YXyK_Dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "16b23daa-3add-45bf-8540-1b52b2df9b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab and need asl-signs data files\n",
            "*******************************\n",
            "2023-03-29 13:07:38\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c8b82d18a4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*******************************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m    \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/GaggleSignLang/asl-signs.zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*******************************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROWS_PER_FRAME = 543  # combined face, lefth, pose, righth\n",
        "\n",
        "# FILTER FEATURES IN EACH FRAME  - FACE, POSE & HANDs\n",
        "class FeatureGen(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureGen, self).__init__()\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # FLATTENING ROWS BY TYPE and CONCATENATING TO ONE ROW PER FRAME 3D (XYZ)\n",
        "        # INPUT NUMPY, TORCH OUTPUT\n",
        "\n",
        "        # flatten points for all types\n",
        "        # face_x = x[:,:468,:].contiguous().view(-1, 468*3)\n",
        "        lips_idx = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
        "        lips_x = x[:, lips_idx,:].contiguous().view(-1, len(lips_idx)*3)\n",
        "        lefth_x = x[:,468:489,:].contiguous().view(-1, 21*3)\n",
        "        pose_x = x[:,489:522,:].contiguous().view(-1, 33*3)\n",
        "        righth_x = x[:,522:,:].contiguous().view(-1, 21*3)\n",
        "        \n",
        "        # flatten types into one row per frame\n",
        "        xfeat = torch.cat([lips_x, lefth_x, pose_x, righth_x], axis=1)  # concatenate types\n",
        "\n",
        "        # pad to FRAMES_ROWS with NaN rows\n",
        "        xfeat = F.pad(xfeat, pad=(0, 0, 0, FRAMES_OUT - xfeat.shape[0]), value=float('nan'))\n",
        "        return xfeat\n",
        "\n",
        "def load_relevant_data_subset(pq_path):\n",
        "  # FILTER THE NUMBER OF FAMES \n",
        "  #   FRAME_OUT number of frames, pad if not enough\n",
        "  #   OUTPUT: NUMPY [:, FRAMES_OUT, ROWS_PER_FRAME, 3] \n",
        "  # \n",
        "    data = pd.read_parquet(pq_path)\n",
        "    frame_ids = data['frame'].unique()\n",
        "    n_frames = len(frame_ids)\n",
        "    \n",
        "    if n_frames > FRAMES_OUT:\n",
        "        f_inc = int(round(n_frames / FRAMES_OUT, 0))\n",
        "        f_start = int((n_frames - FRAMES_OUT * f_inc) / 2)\n",
        "        f_idx = [x for x in range(f_start, (FRAMES_OUT * f_inc) + f_start, f_inc) if 0 <= x < n_frames]\n",
        "        frame_ids = frame_ids[f_idx]\n",
        "        n_frames = len(frame_ids)\n",
        "    \n",
        "    data = data.loc[data['frame'].isin(frame_ids)]\n",
        "    data_columns = [\"x\", \"y\", \"z\"]\n",
        "    data = data[data_columns]\n",
        "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
        "    return data.astype(np.float32)\n",
        "\n",
        "## PROCESS EACH ROW (ONE PARQUET PER ROW)\n",
        "def convert_row(row):\n",
        "    x = load_relevant_data_subset(os.path.join(BASE_DIR, row[1].path))\n",
        "    x = feature_converter(torch.tensor(x)).cpu().numpy()\n",
        "    return x, row[1].label\n",
        "\n",
        "## LOOP THROUGH PARQUET FILES LISTED IN TRAIN FILE\n",
        "##  SAVE RESULTS \n",
        "def convert_and_save_data():\n",
        "    label_map = json.load(open(f\"{WORKING_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
        "    df = pd.read_csv(TRAIN_FILE)\n",
        "    df['label'] = df['sign'].map(label_map)\n",
        "    npdata = np.zeros((df.shape[0], FRAMES_OUT, PTS_IN_FRAME))\n",
        "    nplabels = np.zeros(df.shape[0])\n",
        "\n",
        "    results = map(convert_row, df.iterrows())\n",
        "    for i, (x,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
        "            npdata[i,:] = x\n",
        "            nplabels[i] = y\n",
        "    np.save(f\"{WORKING_DIR}/feature_data{FRAMES_OUT}.npy\", npdata)\n",
        "    np.save(f\"{WORKING_DIR}/feature_labels.npy\", nplabels)\n",
        "    if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "       shutil.copy(f\"{WORKING_DIR}/feature_data{FRAMES_OUT}.npy\", \"/content/drive/MyDrive/GaggleSignLang\")\n",
        "       shutil.copy(f\"{WORKING_DIR}/feature_labels.npy\", \"/content/drive/MyDrive/GaggleSignLang\")\n",
        "\n",
        "    return npdata\n",
        " \n",
        "if not os.path.exists(WORKING_DIR):\n",
        "  print('---- WORKING DIRECTORY DOES NOT EXIST----',{WORKING_DIR})\n",
        "else:\n",
        "  feature_converter = FeatureGen()\n",
        "  datax = convert_and_save_data()\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-15T22:08:36.590267Z",
          "iopub.execute_input": "2023-03-15T22:08:36.591413Z",
          "iopub.status.idle": "2023-03-15T22:08:36.623680Z",
          "shell.execute_reply.started": "2023-03-15T22:08:36.591371Z",
          "shell.execute_reply": "2023-03-15T22:08:36.622754Z"
        },
        "trusted": true,
        "id": "Jx7J5bh7qZP7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "9b6638a5-2147-4f88-b597-f85daac2e3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1004/94477 [00:14<22:38, 68.82it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b061b78d4d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0mfeature_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m   \u001b[0mdatax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_and_save_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-b061b78d4d51>\u001b[0m in \u001b[0;36mconvert_and_save_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mnpdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnplabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-b061b78d4d51>\u001b[0m in \u001b[0;36mconvert_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m## PROCESS EACH ROW (ONE PARQUET PER ROW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_relevant_data_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-b061b78d4d51>\u001b[0m in \u001b[0;36mload_relevant_data_subset\u001b[0;34m(pq_path)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;31m#   OUTPUT: NUMPY [:, FRAMES_OUT, ROWS_PER_FRAME, 3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpq_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mframe_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mn_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             result = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             ).to_pandas(**to_pandas_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2825\u001b[0m             )\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2827\u001b[0;31m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   2828\u001b[0m                             use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m   2829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2471\u001b[0m                 )\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN MODEL"
      ],
      "metadata": {
        "id": "4zsk5_XBM8nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COLAB ONLY - MOVE FEATURE FILES TO WORKING DIRECTORY\n",
        "# \n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists(WORKING_DIR):\n",
        "  !mkdir '/content/asl-work'\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_data{FRAMES_OUT}.npy\", f\"{WORKING_DIR}\")\n",
        "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_labels.npy\", f\"{WORKING_DIR}\")\n",
        "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/sign_to_prediction_index_map.json\", f\"{WORKING_DIR}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LYN0XSNKXd0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ASLData(Dataset):\n",
        "    def __init__(self, datax, datay):\n",
        "        self.datax = datax\n",
        "        self.datay = datay\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.datax[index, :], self.datay[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datay)\n",
        "\n",
        "class ASLModel(nn.Module):\n",
        "    def __init__(self, p):\n",
        "        super(ASLModel, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout0 = nn.Dropout(p)\n",
        "        self.layer0 = nn.Linear(FRAMES_OUT * PTS_IN_FRAME * DIMS, 8192)\n",
        "        self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "        self.layer0a = nn.Linear(8192, 2024)\n",
        "        self.layer1 = nn.Linear(2024, 512)\n",
        "        self.layer2 = nn.Linear(512, 250)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        print('flatten', x.shape)\n",
        "\n",
        "        x = self.layer0(x)\n",
        "        print('layer0', x.shape)\n",
        "\n",
        "        x = self.dropout0(x)\n",
        "        x = self.layer0a(x)\n",
        "        #x = self.dropout1(x)      \n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OZknILM8LvVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training (Doesn't work on Jupiter/MacOS  \\\n",
        "Need new Macbood with Navida GPU)"
      ],
      "metadata": {
        "id": "xmjj63ahqZP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############\n",
        "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"++++using GPU++++\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"++++using CPU++++\")\n",
        "\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datax = np.load(f\"{WORKING_DIR}/feature_data{FRAMES_OUT}.npy\")\n",
        "datay = np.load(f\"{WORKING_DIR}/feature_labels.npy\") \n",
        "datax = torch.tensor(datax)\n",
        "\n",
        "# Replace NaNs with 0\n",
        "datax = np.nan_to_num(datax, copy=False)\n",
        "\n",
        "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
        "\n",
        "train_data = ASLData(trainx, trainy)\n",
        "valid_data = ASLData(testx, testy)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
        "\n",
        "model = ASLModel(0.2).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    model.train()\n",
        "    \n",
        "    train_loss_sum = 0.\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    train_bar = train_loader\n",
        "    for x,y in train_bar:\n",
        "        print(\"SHAPE BAR\", x.shape, y.shape)\n",
        "\n",
        "        x = torch.Tensor(x).float().to(device)\n",
        "        y = torch.Tensor(y).long().to(device)  \n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        train_loss_sum += loss.item()\n",
        "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "        train_total += 1\n",
        "        sched.step()\n",
        "        \n",
        "    val_loss_sum = 0.\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    for x,y in val_loader:\n",
        "        x = torch.Tensor(x).float().to(device)\n",
        "        y = torch.Tensor(y).long().to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            val_loss_sum += loss.item()\n",
        "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "            val_total += 1\n",
        "                              \n",
        "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
        "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Save the pytorch model\n",
        "py_model_path = f\"{WORKING_DIR}/py_model.pt\"\n",
        "torch.save(model, py_model_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:16:57.114241Z",
          "iopub.execute_input": "2023-03-13T18:16:57.115451Z",
          "iopub.status.idle": "2023-03-13T18:23:25.123968Z",
          "shell.execute_reply.started": "2023-03-13T18:16:57.115400Z",
          "shell.execute_reply": "2023-03-13T18:23:25.122556Z"
        },
        "trusted": true,
        "id": "RlbigS0EqZP9",
        "outputId": "72de269f-4819-49ac-ef9e-c5e972fcaeb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATAX (94477, 12, 345)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9708f45fc4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DATAX\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdatax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdatax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{WORKING_DIR}/feature_data{FRAMES_OUT}.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdatay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{WORKING_DIR}/feature_labels.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "16 Frames \n",
        "\n",
        "\n",
        "32 FRAMES_OUT 3xlinear\n",
        "==================================================\n",
        "Epoch:39 > Train Loss: 2.2568, Train Acc: 0.5093\n",
        "Epoch:39 > Val Loss: 2.8198, Val Acc: 0.4007\n",
        "==================================================\n",
        "\n",
        "16 FRAMES_OUT 3xlinear\n",
        "==================================================\n",
        "Epoch:39 > Train Loss: 2.2368, Train Acc: 0.5112\n",
        "Epoch:39 > Val Loss: 2.6392, Val Acc: 0.4321\n",
        "==================================================\n",
        "\n",
        "12 FRAMES_OUT 3xlinear\n",
        "==================================================\n",
        "Epoch:39 > Train Loss: 2.3254, Train Acc: 0.4921\n",
        "Epoch:39 > Val Loss: 2.6272, Val Acc: 0.4351\n",
        "==================================================\n",
        "\n",
        "8 FRAMES_OUT 3xlinear\n",
        "==================================================\n",
        "Epoch:39 > Train Loss: 2.4085, Train Acc: 0.4752\n",
        "Epoch:39 > Val Loss: 2.6766, Val Acc: 0.4238\n",
        "=================================================="
      ],
      "metadata": {
        "id": "Rj2k69Ds9Dj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorflow Conversion¶"
      ],
      "metadata": {
        "id": "kzAP6DfBqZP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Not needed for Kaggle\n",
        "!pip install onnx-tf --quiet --root-user-action=ignore\n",
        "!pip install tflite-runtime  --quiet --root-user-action=ignore"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:27:25.262851Z",
          "iopub.execute_input": "2023-03-13T18:27:25.263457Z",
          "iopub.status.idle": "2023-03-13T18:27:45.414772Z",
          "shell.execute_reply.started": "2023-03-13T18:27:25.263417Z",
          "shell.execute_reply": "2023-03-13T18:27:45.413512Z"
        },
        "trusted": true,
        "id": "dAZXTNC1qZP-",
        "outputId": "e1a82c87-4bf5-4dfd-a172-ad722a831811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --root-user-action\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: --root-user-action\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.rand((50, 543, 3))\n",
        "onnx_feat_gen_path = f\"{WORKING_DIR}/feature_gen.onnx\"\n",
        "\n",
        "feature_converter.eval()\n",
        "\n",
        "torch.onnx.export(\n",
        "    feature_converter,                # PyTorch Model\n",
        "    sample_input,                     # Input tensor\n",
        "    onnx_feat_gen_path,               # Output file (eg. 'output_model.onnx')\n",
        "    opset_version=12,                 # Operator support version\n",
        "    input_names=['input'],            # Input tensor name (arbitary)\n",
        "    output_names=['output'],          # Output tensor name (arbitary)\n",
        "    operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,  # added jh\n",
        "    dynamic_axes={\n",
        "        'input' : {0: 'input'}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T17:45:54.195747Z",
          "iopub.execute_input": "2023-03-13T17:45:54.196258Z",
          "iopub.status.idle": "2023-03-13T17:45:54.390491Z",
          "shell.execute_reply.started": "2023-03-13T17:45:54.196216Z",
          "shell.execute_reply": "2023-03-13T17:45:54.389234Z"
        },
        "trusted": true,
        "id": "Y1sGZ3_xqZP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model (trained on colab)\n",
        "#model = ASLModel(0.2)\n",
        "py_model_path = f\"{WORKING_DIR}/py_model.pt\"\n",
        "model = torch.load(py_model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:11:51.830178Z",
          "iopub.execute_input": "2023-03-13T18:11:51.830942Z",
          "iopub.status.idle": "2023-03-13T18:11:51.857183Z",
          "shell.execute_reply.started": "2023-03-13T18:11:51.830894Z",
          "shell.execute_reply": "2023-03-13T18:11:51.856191Z"
        },
        "trusted": true,
        "id": "bsvYEDLWqZP_",
        "outputId": "1ea8e45e-d72e-4a60-ff8b-bbe4746c5320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ASLModel(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (layer0): Linear(in_features=4140, out_features=1024, bias=True)\n",
              "  (layer1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (layer2): Linear(in_features=512, out_features=250, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.rand((1, 3258)).to(device)\n",
        "onnx_model_path = f\"{WORKING_DIR}/asl_model.onnx\"\n",
        "\n",
        "model.eval()\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,                        # PyTorch Model\n",
        "    sample_input,                 # Input tensor\n",
        "    onnx_model_path,              # Output file (eg. 'output_model.onnx')\n",
        "    opset_version=12,             # Operator support version\n",
        "    input_names=['input'],        # Input tensor name (arbitary)\n",
        "    output_names=['output'],      # Output tensor name (arbitary)\n",
        "    operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,  # added jh\n",
        "    dynamic_axes={\n",
        "        'input' : {0: 'input'}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:12:05.380363Z",
          "iopub.execute_input": "2023-03-13T18:12:05.381125Z",
          "iopub.status.idle": "2023-03-13T18:12:05.519427Z",
          "shell.execute_reply.started": "2023-03-13T18:12:05.381084Z",
          "shell.execute_reply": "2023-03-13T18:12:05.518160Z"
        },
        "trusted": true,
        "id": "bZPnkZUcqZP_",
        "outputId": "ec560ce0-a558-46e1-e6b0-eafe97d4d9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-defacc82f212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m torch.onnx.export(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m                        \u001b[0;31m# PyTorch Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msample_input\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# Input tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     _export(\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             \u001b[0m_validate_dynamic_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m             graph, params_dict, torch_out = _model_to_graph(\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pre_trace_quant_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m     \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[0mprev_autocast_cache_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m     trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n\u001b[0m\u001b[1;32m    892\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         graph, out = torch._C._create_graph_by_tracing(\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0min_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-877ca8bceffc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x3258 and 4140x1024)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "\n",
        "tf_feat_gen_path = f'{WORKING_DIR}/tf_feat_gen'\n",
        "onnx_feat_gen = onnx.load(onnx_feat_gen_path)\n",
        "tf_rep = prepare(onnx_feat_gen)\n",
        "tf_rep.export_graph(tf_feat_gen_path)\n",
        "\n",
        "\n",
        "tf_model_path = f'{WORKING_DIR}/tf_model'\n",
        "onnx_model = onnx.load(onnx_model_path)\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph(tf_model_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:12:11.434321Z",
          "iopub.execute_input": "2023-03-13T18:12:11.435329Z",
          "iopub.status.idle": "2023-03-13T18:12:15.147796Z",
          "shell.execute_reply.started": "2023-03-13T18:12:11.435287Z",
          "shell.execute_reply": "2023-03-13T18:12:15.146792Z"
        },
        "trusted": true,
        "id": "QQdGgspMqZQA",
        "outputId": "0a821c9a-81b0-4484-b670-e8f80e087ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"import onnx\\nfrom onnx_tf.backend import prepare\\n\\n\\ntf_feat_gen_path = f'{WORKING_DIR}/tf_feat_gen'\\nonnx_feat_gen = onnx.load(onnx_feat_gen_path)\\ntf_rep = prepare(onnx_feat_gen)\\ntf_rep.export_graph(tf_feat_gen_path)\\n\\n\\ntf_model_path = f'{WORKING_DIR}/tf_model'\\nonnx_model = onnx.load(onnx_model_path)\\ntf_rep = prepare(onnx_model)\\ntf_rep.export_graph(tf_model_path)\";\n                var nbb_formatted_code = \"import onnx\\nfrom onnx_tf.backend import prepare\\n\\n\\ntf_feat_gen_path = f\\\"{WORKING_DIR}/tf_feat_gen\\\"\\nonnx_feat_gen = onnx.load(onnx_feat_gen_path)\\ntf_rep = prepare(onnx_feat_gen)\\ntf_rep.export_graph(tf_feat_gen_path)\\n\\n\\ntf_model_path = f\\\"{WORKING_DIR}/tf_model\\\"\\nonnx_model = onnx.load(onnx_model_path)\\ntf_rep = prepare(onnx_model)\\ntf_rep.export_graph(tf_model_path)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Inference Model in Tensorflow\n",
        "Both of the converted models will be used here one after another."
      ],
      "metadata": {
        "id": "RE1k66nzqZQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ASLInferModel(tf.Module):\n",
        "    def __init__(self):\n",
        "        super(ASLInferModel, self).__init__()\n",
        "        self.feature_gen = tf.saved_model.load(tf_feat_gen_path)\n",
        "        self.model = tf.saved_model.load(tf_model_path)\n",
        "        self.feature_gen.trainable = False\n",
        "        self.model.trainable = False\n",
        "    \n",
        "    @tf.function(input_signature=[\n",
        "      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
        "    ])\n",
        "    def call(self, input):\n",
        "        output_tensors = {}\n",
        "        features = self.feature_gen(**{'input': input})['output']\n",
        "        output_tensors['outputs'] = self.model(**{'input': tf.expand_dims(features, 0)})['output'][0,:]\n",
        "        return output_tensors\n",
        "    \n",
        "    \n",
        "mytfmodel = ASLInferModel()\n",
        "tf.saved_model.save(mytfmodel, f'{WORKING_DIR}/tf_infer_model', signatures={'serving_default': mytfmodel.call})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T17:47:22.202977Z",
          "iopub.execute_input": "2023-03-13T17:47:22.203813Z",
          "iopub.status.idle": "2023-03-13T17:47:23.213227Z",
          "shell.execute_reply.started": "2023-03-13T17:47:22.203768Z",
          "shell.execute_reply": "2023-03-13T17:47:23.212188Z"
        },
        "trusted": true,
        "id": "idhfnFKjqZQA",
        "outputId": "d201dd47-0782-49c4-f20b-db3938e925c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"import tensorflow as tf\\n\\nclass ASLInferModel(tf.Module):\\n    def __init__(self):\\n        super(ASLInferModel, self).__init__()\\n        self.feature_gen = tf.saved_model.load(tf_feat_gen_path)\\n        self.model = tf.saved_model.load(tf_model_path)\\n        self.feature_gen.trainable = False\\n        self.model.trainable = False\\n    \\n    @tf.function(input_signature=[\\n      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\\n    ])\\n    def call(self, input):\\n        output_tensors = {}\\n        features = self.feature_gen(**{'input': input})['output']\\n        output_tensors['outputs'] = self.model(**{'input': tf.expand_dims(features, 0)})['output'][0,:]\\n        return output_tensors\\n    \\n    \\nmytfmodel = ASLInferModel()\\ntf.saved_model.save(mytfmodel, f'{WORKING_DIR}/tf_infer_model', signatures={'serving_default': mytfmodel.call})\";\n                var nbb_formatted_code = \"import tensorflow as tf\\n\\n\\nclass ASLInferModel(tf.Module):\\n    def __init__(self):\\n        super(ASLInferModel, self).__init__()\\n        self.feature_gen = tf.saved_model.load(tf_feat_gen_path)\\n        self.model = tf.saved_model.load(tf_model_path)\\n        self.feature_gen.trainable = False\\n        self.model.trainable = False\\n\\n    @tf.function(\\n        input_signature=[\\n            tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name=\\\"inputs\\\")\\n        ]\\n    )\\n    def call(self, input):\\n        output_tensors = {}\\n        features = self.feature_gen(**{\\\"input\\\": input})[\\\"output\\\"]\\n        output_tensors[\\\"outputs\\\"] = self.model(\\n            **{\\\"input\\\": tf.expand_dims(features, 0)}\\n        )[\\\"output\\\"][0, :]\\n        return output_tensors\\n\\n\\nmytfmodel = ASLInferModel()\\ntf.saved_model.save(\\n    mytfmodel,\\n    f\\\"{WORKING_DIR}/tf_infer_model\\\",\\n    signatures={\\\"serving_default\\\": mytfmodel.call},\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u24bdY4yqZQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the Model"
      ],
      "metadata": {
        "id": "cjdShOL-qZQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "\n",
        "tf_infer_model_path = f'{WORKING_DIR}/tf_infer_model'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(tf_infer_model_path)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_path = 'model.tflite'\n",
        "\n",
        "# Save the model\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T17:59:00.150975Z",
          "iopub.execute_input": "2023-03-13T17:59:00.151403Z",
          "iopub.status.idle": "2023-03-13T17:59:02.014428Z",
          "shell.execute_reply.started": "2023-03-13T17:59:00.151364Z",
          "shell.execute_reply": "2023-03-13T17:59:02.013174Z"
        },
        "trusted": true,
        "id": "xBBxp1JBqZQB",
        "outputId": "24724cc4-362c-4eb3-c5dd-40c3af8cfd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"# Convert the model\\n\\ntf_infer_model_path = f'{WORKING_DIR}/tf_infer_model'\\nconverter = tf.lite.TFLiteConverter.from_saved_model(tf_infer_model_path)\\ntflite_model = converter.convert()\\n\\ntflite_model_path = 'model.tflite'\\n\\n# Save the model\\nwith open(tflite_model_path, 'wb') as f:\\n    f.write(tflite_model)\";\n                var nbb_formatted_code = \"# Convert the model\\n\\ntf_infer_model_path = f\\\"{WORKING_DIR}/tf_infer_model\\\"\\nconverter = tf.lite.TFLiteConverter.from_saved_model(tf_infer_model_path)\\ntflite_model = converter.convert()\\n\\ntflite_model_path = \\\"model.tflite\\\"\\n\\n# Save the model\\nwith open(tflite_model_path, \\\"wb\\\") as f:\\n    f.write(tflite_model)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
        "pq_path = f\"{BASE_DIR}/train_landmark_files/53618/1001379621.parquet\"\n",
        "\n",
        "import tflite_runtime.interpreter as tflite\n",
        "interpreter = tflite.Interpreter(tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "found_signatures = list(interpreter.get_signature_list().keys())\n",
        "\n",
        "# if REQUIRED_SIGNATURE not in found_signatures:\n",
        "#     raise KernelEvalException('Required input signature not found.')\n",
        "\n",
        "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
        "output = prediction_fn(inputs=load_relevant_data_subset(pq_path))\n",
        "sign = np.argmax(output[\"outputs\"])\n",
        "\n",
        "print(sign, output[\"outputs\"].shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T17:59:31.937321Z",
          "iopub.execute_input": "2023-03-13T17:59:31.937720Z",
          "iopub.status.idle": "2023-03-13T17:59:32.162196Z",
          "shell.execute_reply.started": "2023-03-13T17:59:31.937685Z",
          "shell.execute_reply": "2023-03-13T17:59:32.160211Z"
        },
        "trusted": true,
        "id": "iblcFVrXqZQB",
        "outputId": "2ce7417a-a34d-4058-e303-0b6098fdac44"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "30 (250,)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"ROWS_PER_FRAME = 543  # number of landmarks per frame\\npq_path = f\\\"{BASE_DIR}/train_landmark_files/53618/1001379621.parquet\\\"\\n\\nimport tflite_runtime.interpreter as tflite\\ninterpreter = tflite.Interpreter(tflite_model_path)\\ninterpreter.allocate_tensors()\\n\\nfound_signatures = list(interpreter.get_signature_list().keys())\\n\\n# if REQUIRED_SIGNATURE not in found_signatures:\\n#     raise KernelEvalException('Required input signature not found.')\\n\\nprediction_fn = interpreter.get_signature_runner(\\\"serving_default\\\")\\noutput = prediction_fn(inputs=load_relevant_data_subset(pq_path))\\nsign = np.argmax(output[\\\"outputs\\\"])\\n\\nprint(sign, output[\\\"outputs\\\"].shape)\";\n                var nbb_formatted_code = \"ROWS_PER_FRAME = 543  # number of landmarks per frame\\npq_path = f\\\"{BASE_DIR}/train_landmark_files/53618/1001379621.parquet\\\"\\n\\nimport tflite_runtime.interpreter as tflite\\n\\ninterpreter = tflite.Interpreter(tflite_model_path)\\ninterpreter.allocate_tensors()\\n\\nfound_signatures = list(interpreter.get_signature_list().keys())\\n\\n# if REQUIRED_SIGNATURE not in found_signatures:\\n#     raise KernelEvalException('Required input signature not found.')\\n\\nprediction_fn = interpreter.get_signature_runner(\\\"serving_default\\\")\\noutput = prediction_fn(inputs=load_relevant_data_subset(pq_path))\\nsign = np.argmax(output[\\\"outputs\\\"])\\n\\nprint(sign, output[\\\"outputs\\\"].shape)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL ZIP\n",
        "!zip submission.zip $tflite_model_path"
      ],
      "metadata": {
        "id": "VOuqWXf0qZQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}