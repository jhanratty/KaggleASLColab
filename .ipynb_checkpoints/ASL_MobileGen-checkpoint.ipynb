{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ccfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e142d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Jupiter  MacOS\n",
    "BASE_DIR = \"/Users/johnhanratty/ASLtest/asl-signs\"  #\"/Users/johnhanratty/ASLtest/asl-signs\"\n",
    "WORKING_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "ARCHIVE_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "MODEL_DIR = \"/Users/johnhanratty/ASLtest/models\"\n",
    "\n",
    "# !pip install nb_black --quiet\n",
    "# %load_ext lab_black\n",
    "\n",
    "# Colab\n",
    "# BASE_DIR = \"/content/asl-signs\"   #\"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
    "# WORKING_DIR = \"/content/asl-work\"\n",
    "# ARCHIVE_DIR = \"/content/drive/MyDrive/GaggleSignLang\"\n",
    "# MODEL_DIR = \"/content/drive/MyDrive/GaggleSignLang/models\"\n",
    "# !pip install nb_black --quiet\n",
    "# print('-----ok')\n",
    "# %load_ext nb_black\n",
    "\n",
    "# KAGGLE\n",
    "# BASE_DIR = \"/kaggle/input/asl-signs\"\n",
    "# WORKING_DIR = \"/kaggle/working\"\n",
    "# ARCHIVE_DIR = \"/kaggle/working\"\n",
    "# MODEL_DIR  = \"/kaggle/working\"\n",
    "# !pip install nb_black --quiet --root-user-action=ignore\n",
    "# %load_ext lab_black\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import seed, sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
    "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
    "\n",
    "FRAMES_OUT = 64 # 16\n",
    "PTS_IN_FRAME = 345\n",
    "DIMC = [0,1,2]\n",
    "DIMS = len(DIMC)\n",
    "WORKERS = 0   # dataoader work var  0 for MAC, 4 for online\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacc5260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : macOS-10.16-x86_64-i386-64bit\n",
      "python          : 3.8.13\n",
      "tsai            : 0.3.6\n",
      "fastai          : 2.7.12\n",
      "fastcore        : 1.5.29\n",
      "torch           : 2.0.0\n",
      "cpu cores       : 8\n",
      "threads per cpu : 2\n",
      "RAM             : 16.0 GB\n",
      "GPU memory      : N/A\n",
      "++++using CPU++++\n"
     ]
    }
   ],
   "source": [
    "!pip install tsai --quiet\n",
    "from tsai.all import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "\n",
    "my_setup()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  dout = \"cuda\"\n",
    "  print(\"++++using GPU++++\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  dout = \"cpu\"\n",
    "  print(\"++++using CPU++++\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b931bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "datax = np.load(f\"{ARCHIVE_DIR}/tsai_data{FRAMES_OUT}.npy\")\n",
    "datay = np.load(f\"{ARCHIVE_DIR}/tsai_labels.npy\") \n",
    "\n",
    "datax = np.swapaxes(datax,2,1)\n",
    "datax = np.nan_to_num(datax, copy=False)\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ddcef03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14172, 60, 64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b933a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = modi(torch.tensor(testx).float())\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1638d1e0",
   "metadata": {},
   "source": [
    "#MOBILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8959a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATUREGEN MODEL\n",
    "ROWS_PER_FRAME = 543  # combined face, lefth, pose, righth\n",
    "\n",
    "# FILTER FEATURES IN EACH FRAME  - FACE, POSE & HANDs\n",
    "class FeatureGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "        \n",
    "        print(MODEL_DIR)\n",
    "        with open(f\"{MODEL_DIR}/modelPCA_60.pkl\", 'rb') as handle:\n",
    "            self.pca_X = pickle.load(handle)\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # FILTER TO SPECIFIED FRAMES (FRAMES_OUT)\n",
    "        seed(24)\n",
    "        x = np.array(x)\n",
    "        n_frames = x.shape[0]\n",
    "        # Trim to # of frames to FRAMES_OUT\n",
    "        if n_frames > FRAMES_OUT:\n",
    "            idx = sorted((sample(range(0, n_frames), FRAMES_OUT)))\n",
    "            x=x[idx,:,:]\n",
    "        n_frames = x.shape[0]\n",
    "        # FLATTENING ROWS BY TYPE and CONCATENATING TO ONE ROW PER FRAME 3D (XYZ)\n",
    "        # INPUT NUMPY, TORCH OUTPUT\n",
    "\n",
    "        # Grab data type (e.g. one point on hand) by selecting rows for each frame\n",
    "        # face_x = x[:,:468,:].contiguous().view(-1, 468*3)\n",
    "        lips_idx = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "        lips_x = x[:, lips_idx,:].reshape(-1, len(lips_idx)*3)\n",
    "        lefth_x = x[:,468:489,:].reshape(-1, 21*3)\n",
    "        pose_x = x[:,489:522,:].reshape(-1, 33*3)\n",
    "        righth_x = x[:,522:,:].reshape(-1, 21*3)\n",
    "\n",
    "        if np.isnan(lefth_x).sum() < np.isnan(righth_x).sum():\n",
    "            prime_x = lefth_x\n",
    "            second_x = righth_x\n",
    "        else:\n",
    "            prime_x = righth_x.reshape(righth_x.shape[0], -1, DIMS)\n",
    "            prime_x[:,:,0] = np.add(np.nanmax(prime_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                    prime_x[:, :, 0])\n",
    "            prime_x = prime_x.reshape(prime_x.shape[0],-1)\n",
    "            \n",
    "            second_x = lefth_x.reshape(lefth_x.shape[0], -1, DIMS)\n",
    "            second_x[:,:,0] = np.subtract(np.nanmax(second_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                          second_x[:, :, 0])\n",
    "            second_x = second_x.reshape(second_x.shape[0],-1)\n",
    "\n",
    "        # flatten types into one row per frame\n",
    "        xfeat = np.full([FRAMES_OUT, PTS_IN_FRAME], np.nan)\n",
    "        offset = (FRAMES_OUT - n_frames) // 2  # center frames in output data in each frame in video\n",
    "        xfeat[offset:n_frames+offset,:] = np.concatenate([lips_x, prime_x, pose_x, second_x], axis=1)  # concatenate types\n",
    "        \n",
    "        ################### \n",
    "        \n",
    "        xfeat = np.nan_to_num(xfeat, copy=False) \n",
    "        pca_out = self.pca_X.transform(xfeat.reshape(xfeat.shape[0],-1))\n",
    "        return pca_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dd9d974",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionTimePlus(\n",
       "  (backbone): Sequential(\n",
       "    (0): InceptionBlockPlus(\n",
       "      (inception): ModuleList(\n",
       "        (0): InceptionModulePlus(\n",
       "          (bottleneck): ConvBlock(\n",
       "            (0): Conv1d(60, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (convs): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (mp_conv): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(60, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (concat): Concat(dim=1)\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (1): InceptionModulePlus(\n",
       "          (bottleneck): ConvBlock(\n",
       "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (convs): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (mp_conv): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (concat): Concat(dim=1)\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (2): InceptionModulePlus(\n",
       "          (bottleneck): ConvBlock(\n",
       "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (convs): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (mp_conv): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (concat): Concat(dim=1)\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3-4): 2 x InceptionModulePlus(\n",
       "          (bottleneck): ConvBlock(\n",
       "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (convs): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (mp_conv): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (concat): Concat(dim=1)\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU()\n",
       "        )\n",
       "        (5): InceptionModulePlus(\n",
       "          (bottleneck): ConvBlock(\n",
       "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (convs): ModuleList(\n",
       "            (0): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)\n",
       "            )\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "            )\n",
       "            (2): ConvBlock(\n",
       "              (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (mp_conv): Sequential(\n",
       "            (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "            (1): ConvBlock(\n",
       "              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            )\n",
       "          )\n",
       "          (concat): Concat(dim=1)\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (shortcut): ModuleList(\n",
       "        (0): ConvBlock(\n",
       "          (0): Conv1d(60, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): ModuleList(\n",
       "        (0-1): 2 x ReLU()\n",
       "      )\n",
       "      (add): Add\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): GAP1d(\n",
       "        (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "        (flatten): Reshape(bs)\n",
       "      )\n",
       "      (1): LinBnDrop(\n",
       "        (0): Linear(in_features=128, out_features=250, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(f\"{MODEL_DIR}/mtrain_incept{FRAMES_OUT}.pkl\", 'rb') as handle:\n",
    "#   lrni = pickle.load(handle)\n",
    "\n",
    "# with open(f\"{MODEL_DIR}/model_incept{FRAMES_OUT}.pkl\", 'rb') as handle:\n",
    "#   modi = pickle.load(handle)\n",
    "\n",
    "# SAVE TRANSFORMER MODELS\n",
    "PATH = f\"{MODEL_DIR}/model_incept1{FRAMES_OUT}.pkl\"\n",
    "modi = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "modi.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14a8aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 11:19:07.372555: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --quiet --root-user-action=ignore\n",
    "!pip install tensorflow_probability --quiet --root-user-action=ignore\n",
    "\n",
    "!pip install onnx-tf --quiet --root-user-action=ignore\n",
    "!pip install tflite-runtime  --quiet --root-user-action=ignore\n",
    "import onnx_tf\n",
    "import tflite_runtime\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6358fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnhanratty/ASLtest/models\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/johnhanratty/ASLtest/models/modelPCA_64.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# PATH = f\"{MODEL_DIR}/model_incept1{FRAMES_OUT}.pkl\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m feat_gen \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#modi.eval()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m345\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "Cell \u001b[0;32mIn[84], line 10\u001b[0m, in \u001b[0;36mFeatureGen.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28msuper\u001b[39m(FeatureGen, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(MODEL_DIR)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/modelPCA_64.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpca_X \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/johnhanratty/ASLtest/models/modelPCA_64.pkl'"
     ]
    }
   ],
   "source": [
    "# PATH = f\"{MODEL_DIR}/model_incept1{FRAMES_OUT}.pkl\"\n",
    "feat_gen = FeatureGen()\n",
    "#modi.eval()\n",
    "\n",
    "sample_input = torch.rand((64, 345, 3))\n",
    "onnx_gen_path = f\"{MODEL_DIR}/model_gen.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    modi,                    # PyTorch Model\n",
    "    sample_input,             # Input tensor\n",
    "    onnx_gen_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_gen = onnx.load(onnx_gen_path)\n",
    "\n",
    "onnx.checker.check_model(onnx_gen)\n",
    "\n",
    "\n",
    "tf_rep = prepare(onnx_gen)\n",
    "\n",
    "\n",
    "tf_gen_path = f\"{MODEL_DIR}/tf_gen\"\n",
    "tf_rep.export_graph(tf_gen_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee3ca6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 15:03:37.931810: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '32079' with dtype float and shape [32,32,39]\n",
      "\t [[{{node 32079}}]]\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/johnhanratty/ASLtest/models/tf_incept_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 15:03:39.879770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input' with dtype float and shape [?,60,64]\n",
      "\t [[{{node serving_default_input}}]]\n",
      "INFO:tensorflow:Assets written to: /Users/johnhanratty/ASLtest/models/tf_incept_cnn/assets\n"
     ]
    }
   ],
   "source": [
    "# PATH = f\"{MODEL_DIR}/model_incept1{FRAMES_OUT}.pkl\"\n",
    "modi = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "modi.eval()\n",
    "\n",
    "sample_input = torch.rand((64, 60, 64))\n",
    "onnx_mod_cnn_path = f\"{MODEL_DIR}/model_incept.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    modi,                    # PyTorch Model\n",
    "    sample_input,             # Input tensor\n",
    "    onnx_mod_cnn_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_mod_cnn_gen = onnx.load(onnx_mod_cnn_path)\n",
    "\n",
    "onnx.checker.check_model(onnx_mod_cnn_gen)\n",
    "\n",
    "\n",
    "tf_rep = prepare(onnx_mod_cnn_gen)\n",
    "\n",
    "\n",
    "tf_mod_incept_path = f\"{MODEL_DIR}/tf_incept_cnn\"\n",
    "tf_rep.export_graph(tf_mod_incept_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ec01d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 15:28:17.658220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '44149' with dtype float and shape [32,32,39]\n",
      "\t [[{{node 44149}}]]\n",
      "2023-05-01 15:28:18.161888: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '44274' with dtype float and shape [32,32,39]\n",
      "\t [[{{node 44274}}]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_23531/21566451.py\", line 17, in call  *\n        output_tensors['outputs'] = self.model(**{'input': tf.expand_dims(features, 0)})['output'][0,:]\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(1, None, 250) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': TensorSpec(shape=(None, 60, 64), dtype=tf.float32, name='input')}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 24\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output_tensors\n\u001b[1;32m     21\u001b[0m mytfmodel \u001b[38;5;241m=\u001b[39m ASLInferModel()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tf_incept_cnn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1240\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1240\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1402\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1399\u001b[0m       augmented_graph_view)\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n\u001b[1;32m   1404\u001b[0m signature_map \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mcreate_signature_map(signatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:131\u001b[0m, in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    129\u001b[0m wrapped_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature_key, function \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 131\u001b[0m   original_function \u001b[38;5;241m=\u001b[39m signature_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m signature_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a TensorFlow function for which to generate a signature, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Only `tf.functions` with an input signature or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcrete functions can be used as a signature.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:43\u001b[0m, in \u001b[0;36m_get_signature\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_signature\u001b[39m(function):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(function, (defun\u001b[38;5;241m.\u001b[39mFunction, def_function\u001b[38;5;241m.\u001b[39mFunction)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     42\u001b[0m       function\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     function \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:484\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/__autograph_generated_fileushseuw3.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     11\u001b[0m features \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel, (), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28minput\u001b[39m)}), fscope)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(output_tensors)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:740\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_23531/21566451.py\", line 17, in call  *\n        output_tensors['outputs'] = self.model(**{'input': tf.expand_dims(features, 0)})['output'][0,:]\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(1, None, 250) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': TensorSpec(shape=(None, 60, 64), dtype=tf.float32, name='input')}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ASLInferModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLInferModel, self).__init__()\n",
    "        tf_mod_cnn_path = f\"{MODEL_DIR}/tf_incept_cnn\"\n",
    "\n",
    "        self.model = tf.saved_model.load(tf_mod_cnn_path)\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, 60, 64], dtype=tf.float32, name='inputs')\n",
    "    ])\n",
    "    def call(self, input):\n",
    "        output_tensors = {}\n",
    "        features = self.model(**{'input': input})['output']\n",
    "        output_tensors['outputs'] = self.model(**{'input': tf.expand_dims(features, 0)})['output'][0,:]\n",
    "        return output_tensors\n",
    "   \n",
    "    \n",
    "mytfmodel = ASLInferModel()\n",
    "\n",
    "\n",
    "tf.saved_model.save(mytfmodel, \n",
    "                    f'{MODEL_DIR}/tf_incept_cnn', \n",
    "                    signatures={'serving_default': mytfmodel.call})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb59fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
