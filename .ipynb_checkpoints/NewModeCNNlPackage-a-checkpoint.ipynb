{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FEATURE FILES FROM GDRIVE \n",
    "# COLAB ONLY - MOVE FEATURE FILES TO WORKING DIRECTORY\n",
    "# \n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists(WORKING_DIR):\n",
    "  !mkdir '/content/asl-work'\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   # shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_data{FRAMES_OUT}.npy\", f\"{WORKING_DIR}\")\n",
    "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_labels.npy\", f\"{WORKING_DIR}\")\n",
    "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/sign_to_prediction_index_map.json\", f\"{WORKING_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5c251a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:00.056762Z",
     "iopub.status.busy": "2023-04-27T09:22:00.056345Z",
     "iopub.status.idle": "2023-04-27T09:22:01.788737Z",
     "shell.execute_reply": "2023-04-27T09:22:01.787457Z",
     "shell.execute_reply.started": "2023-04-27T09:22:00.056725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Jupiter  MacOS\n",
    "BASE_DIR = \"/Users/johnhanratty/ASLtest/asl-signs\"  #\"/Users/johnhanratty/ASLtest/asl-signs\"\n",
    "WORKING_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "ARCHIVE_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "MODELS_DIR = \"/Users/johnhanratty/ASLtest/models\"\n",
    "\n",
    "# !pip install nb_black --quiet\n",
    "# %load_ext lab_black\n",
    "\n",
    "# Colab\n",
    "# BASE_DIR = \"/content/asl-signs\"   #\"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
    "# WORKING_DIR = \"/content/asl-work\"\n",
    "# ARCHIVE_DIR = \"/content/drive/MyDrive/GaggleSignLang\"\n",
    "# MODEL_DIR = \"/content/drive/MyDrive/GaggleSignLang\"\n",
    "# !pip install nb_black --quiet\n",
    "# print('-----ok')\n",
    "# %load_ext nb_black\n",
    "\n",
    "# KAGGLE\n",
    "# BASE_DIR = \"/kaggle/input/asl-signs\"\n",
    "# WORKING_DIR = \"/kaggle/working\"\n",
    "# ARCHIVE_DIR = \"/kaggle/working\"\n",
    "# MODEL_DIR  = \"/kaggle/working\"\n",
    "# !pip install nb_black --quiet --root-user-action=ignore\n",
    "# %load_ext lab_black\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import seed, sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
    "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
    "\n",
    "FRAMES_OUT = 32 # 16\n",
    "PTS_IN_FRAME = 345\n",
    "DIMC = [0,1,2]\n",
    "DIMS = len(DIMC)\n",
    "WORKERS = 0   # dataoader work var  0 for MAC, 4 for online\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a41802f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:06.975674Z",
     "iopub.status.busy": "2023-04-27T09:22:06.975115Z",
     "iopub.status.idle": "2023-04-27T09:22:06.982263Z",
     "shell.execute_reply": "2023-04-27T09:22:06.981046Z",
     "shell.execute_reply.started": "2023-04-27T09:22:06.975635Z"
    }
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6048e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:24.657013Z",
     "iopub.status.busy": "2023-04-27T09:22:24.656552Z",
     "iopub.status.idle": "2023-04-27T09:22:24.672857Z",
     "shell.execute_reply": "2023-04-27T09:22:24.671586Z",
     "shell.execute_reply.started": "2023-04-27T09:22:24.656974Z"
    }
   },
   "outputs": [],
   "source": [
    "#FEATUREGEN MODEL\n",
    "ROWS_PER_FRAME = 543  # combined face, lefth, pose, righth\n",
    "\n",
    "# FILTER FEATURES IN EACH FRAME  - FACE, POSE & HANDs\n",
    "class FeatureGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # FILTER TO SPECIFIED FRAMES (FRAMES_OUT)\n",
    "        seed(24)\n",
    "        x = np.array(x)\n",
    "        n_frames = x.shape[0]\n",
    "        # Trim to # of frames to FRAMES_OUT\n",
    "        if n_frames > FRAMES_OUT:\n",
    "            idx = sorted((sample(range(0, n_frames), FRAMES_OUT)))\n",
    "            x=x[idx,:,:]\n",
    "        n_frames = x.shape[0]\n",
    "        # FLATTENING ROWS BY TYPE and CONCATENATING TO ONE ROW PER FRAME 3D (XYZ)\n",
    "        # INPUT NUMPY, TORCH OUTPUT\n",
    "\n",
    "        # Grab data type (e.g. one point on hand) by selecting rows for each frame\n",
    "        # face_x = x[:,:468,:].contiguous().view(-1, 468*3)\n",
    "        lips_idx = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "        lips_x = x[:, lips_idx,:].reshape(-1, len(lips_idx)*3)\n",
    "        lefth_x = x[:,468:489,:].reshape(-1, 21*3)\n",
    "        pose_x = x[:,489:522,:].reshape(-1, 33*3)\n",
    "        righth_x = x[:,522:,:].reshape(-1, 21*3)\n",
    "\n",
    "        if np.isnan(lefth_x).sum() < np.isnan(righth_x).sum():\n",
    "            prime_x = lefth_x\n",
    "            second_x = righth_x\n",
    "        else:\n",
    "            prime_x = righth_x.reshape(righth_x.shape[0], -1, DIMS)\n",
    "            prime_x[:,:,0] = np.add(np.nanmax(prime_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                    prime_x[:, :, 0])\n",
    "            prime_x = prime_x.reshape(prime_x.shape[0],-1)\n",
    "            \n",
    "            second_x = lefth_x.reshape(lefth_x.shape[0], -1, DIMS)\n",
    "            second_x[:,:,0] = np.subtract(np.nanmax(second_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                          second_x[:, :, 0])\n",
    "            second_x = second_x.reshape(second_x.shape[0],-1)\n",
    "            \n",
    "        # ?? remove empty frames ???\n",
    "        \n",
    "        # flatten types into one row per frame\n",
    "        xfeat = np.full([FRAMES_OUT, PTS_IN_FRAME], np.nan)\n",
    "        offset = (FRAMES_OUT - n_frames) // 2  # center frames in output data in each frame in video\n",
    "        xfeat[offset:n_frames+offset,:] = np.concatenate([lips_x, prime_x, pose_x, second_x], axis=1)  # concatenate types\n",
    "        \n",
    "        \n",
    "        def distDiff(ds, ref, pts):\n",
    "            ds = ds.reshape(ds.shape[0],  -1, DIMS)\n",
    "            d = np.hstack([np.nanmean(ds[:, pts, :], axis=0), \n",
    "                           np.nanmedian(ds[:, pts, :], axis=0), \n",
    "                           np.nanmax(ds[:, pts, :], axis=0), \n",
    "                           np.nanmin(ds[:, pts, :], axis=0),\n",
    "                           np.nanvar(ds[:, pts, :], axis=0)\n",
    "                           ]) \n",
    "            d = d.reshape(1, -1) \n",
    "            # NORMALIZE\n",
    "           # d = (d - np.nanmean(d, keepdims=True)) / np.nanstd(d, keepdims=True) # -1 to 1\n",
    "            d = np.nan_to_num(d, copy=False)  # replace NaN after normalization\n",
    "            return d\n",
    "        \n",
    "        d1 = distDiff(xfeat, 40, [44, 48, 52, 56, 60, 43, 46, 50, 54, 58])\n",
    "        d2 = distDiff(xfeat, 40, [98, 102, 106, 110, 114, 97, 102, 106, 110, 114])\n",
    "        d3 = distDiff(xfeat, 60, [73, 80, 81, 76, 77, 68, 69, 70, 71, 75, 74])\n",
    "        d4 = distDiff(xfeat, 5,  [0, 4, 8, 12, 16, 20, 24, 28, 32, 36])\n",
    "        \n",
    "        return np.concatenate([d1,d2,d3,d4], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd1fee39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T10:13:04.044426Z",
     "iopub.status.busy": "2023-04-27T10:13:04.043547Z",
     "iopub.status.idle": "2023-04-27T10:16:04.541551Z",
     "shell.execute_reply": "2023-04-27T10:16:04.540255Z",
     "shell.execute_reply.started": "2023-04-27T10:13:04.044379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert&Save (94477, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 94477/94477 [12:40<00:00, 124.21it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## PROCESS EACH ROW (ONE PARQUET PER ROW)\n",
    "def convert_row(row):\n",
    "    x = load_relevant_data_subset(os.path.join(BASE_DIR, row[1].path))\n",
    "    x = feature_converter(torch.tensor(x))\n",
    "    return x, row[1].label\n",
    "\n",
    "## LOOP THROUGH PARQUET FILES LISTED IN TRAIN FILE\n",
    "##  SAVE RESULTS \n",
    "def convert_and_save_data():\n",
    "    label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    \n",
    "    print(\"Convert&Save\", df.shape)\n",
    "    #### FOR TESTING #################\n",
    "    #df = df[0:20]\n",
    "    ##################################\n",
    "\n",
    "    npdata = np.zeros((df.shape[0], 615))  #150+150+165+150\n",
    "\n",
    "    nplabels = np.zeros(df.shape[0])\n",
    "    \n",
    "    results = map(convert_row, df.iterrows())\n",
    "    for i, (x,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
    "            npdata[i,:] = x\n",
    "            nplabels[i] = y\n",
    "    return npdata, nplabels\n",
    " \n",
    "\n",
    "feature_converter = FeatureGen()\n",
    "datax, datay = convert_and_save_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1762d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "np.save(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}.npy\", datax)\n",
    "np.save(f\"{WORKING_DIR}/cnn_labels.npy\", datay)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5b5fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "datax = np.load(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}.npy\")\n",
    "datay = np.load(f\"{WORKING_DIR}/cnn_labels.npy\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "704dc178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:34.423269Z",
     "iopub.status.busy": "2023-04-27T11:16:34.422846Z",
     "iopub.status.idle": "2023-04-27T11:16:34.445881Z",
     "shell.execute_reply": "2023-04-27T11:16:34.444872Z",
     "shell.execute_reply.started": "2023-04-27T11:16:34.423234Z"
    }
   },
   "outputs": [],
   "source": [
    "#MODEL\n",
    "### NEW SEPARATED INPUTS\n",
    "class ASLData(Dataset):\n",
    "    def __init__(self,datax,datay):\n",
    "        self.datax = datax\n",
    "        self.datay = datay\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datax[index, :], self.datay[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datay)\n",
    "\n",
    "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(ASLModel, self).__init__()\n",
    "        \n",
    "        # DATA in [1, 615] per video\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        L1OUT = 512  #1024 was ok\n",
    "        L2OUT = 512\n",
    "\n",
    "        self.layer_ph = nn.Linear(150, L1OUT)\n",
    "        self.batchnorm_ph = nn.BatchNorm1d(L1OUT)\n",
    "        \n",
    "        self.layer_sh = nn.Linear(150, L1OUT)\n",
    "        self.batchnorm_sh = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_po = nn.Linear(165, L1OUT)\n",
    "        self.batchnorm_po = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_li = nn.Linear(150, L1OUT)\n",
    "        self.batchnorm_li = nn.BatchNorm1d(L1OUT) \n",
    " \n",
    "        self.layer1 = nn.Linear(4*L1OUT, L2OUT)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(L2OUT)\n",
    "\n",
    "        self.layerFC = nn.Linear(L2OUT, 250)\n",
    "        self.softmax = nn.Softmax()\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        phand = x[:,0:150]            \n",
    "        shand = x[:,150:300]\n",
    "        pose =  x[:,300:465]  \n",
    "        lips =  x[:,465:615]  \n",
    "        \n",
    "        ph = self.flatten(torch.tensor(phand).float()) \n",
    "        ph = self.layer_ph(ph)\n",
    "        ph = self.batchnorm_ph(ph)\n",
    "        ph = self.relu(ph)\n",
    "        ph = self.dropout(ph)\n",
    "\n",
    "        sh = self.flatten(torch.tensor(shand).float())       \n",
    "        sh = self.layer_sh(sh)\n",
    "        sh = self.batchnorm_sh(sh)\n",
    "        sh = self.relu(sh)\n",
    "        sh = self.dropout(sh)\n",
    "       \n",
    "        po = self.flatten(torch.tensor(pose).float())       \n",
    "        po = self.layer_po(po)\n",
    "        po = self.batchnorm_po(po)\n",
    "        po = self.relu(po)\n",
    "        po = self.dropout(po)\n",
    "        \n",
    "        li = self.flatten(torch.tensor(lips).float())       \n",
    "        li = self.layer_li(li)\n",
    "        li = self.batchnorm_li(li)\n",
    "        li = self.relu(li)\n",
    "        li = self.dropout(li)\n",
    "\n",
    "        x = torch.cat((ph.view(ph.size(0), -1),\n",
    "                       sh.view(sh.size(0), -1),\n",
    "                       po.view(po.size(0), -1),\n",
    "                       li.view(li.size(0), -1)), dim=1)\n",
    "        # x = self.batchnorm0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layerFC(x)\n",
    "       # x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30afac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:40.228537Z",
     "iopub.status.busy": "2023-04-27T11:16:40.227418Z",
     "iopub.status.idle": "2023-04-27T11:17:22.481778Z",
     "shell.execute_reply": "2023-04-27T11:17:22.480359Z",
     "shell.execute_reply.started": "2023-04-27T11:16:40.228485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++using CPU++++\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:0 > Train Loss: 3.5001, Train Acc: 0.2240\n",
      "Epoch:0 > Val Loss: 2.8052, Val Acc: 0.3326\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:1 > Train Loss: 2.3996, Train Acc: 0.4104\n",
      "Epoch:1 > Val Loss: 2.4687, Val Acc: 0.4014\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:2 > Train Loss: 2.0425, Train Acc: 0.4889\n",
      "Epoch:2 > Val Loss: 1.9487, Val Acc: 0.5261\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:3 > Train Loss: 1.8168, Train Acc: 0.5397\n",
      "Epoch:3 > Val Loss: 1.7693, Val Acc: 0.5641\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:4 > Train Loss: 1.6507, Train Acc: 0.5759\n",
      "Epoch:4 > Val Loss: 1.6598, Val Acc: 0.5948\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "## MULTI TRAINING\n",
    "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"++++using GPU++++\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"++++using CPU++++\")\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
    "#datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
    "train_data = ASLData(trainx, trainy)\n",
    "valid_data = ASLData(testx, testy)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=True)\n",
    "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=False)\n",
    "model = ASLModel(0.2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_sum = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_bar = train_loader\n",
    "    for x,y in train_bar:\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device) \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_sum += loss.item()\n",
    "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "        train_total += 1\n",
    "        sched.step()\n",
    "        \n",
    "    val_loss_sum = 0.\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    for x,y in val_loader:\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            val_loss_sum += loss.item()\n",
    "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "            val_total += 1\n",
    "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
    "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
    "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Save the pytorch model\n",
    "PATH = f\"{ARCHIVE_DIR}/models/modelccn{FRAMES_OUT}flat.sd\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49046438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ========Full Data - no add Norm, Centered ========\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:38 > Train Loss: 0.9867, Train Acc: 0.7321\n",
    "# Epoch:38 > Val Loss: 1.2608, Val Acc: 0.6988\n",
    "# ==================================================\n",
    "\n",
    "# ========Full Data - no additional Normalizeation/Centering=====================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.4974, Train Acc: 0.6059\n",
    "# Epoch:39 > Val Loss: 1.7298, Val Acc: 0.5839\n",
    "# ==================================================\n",
    "\n",
    "# =====Full no reverse, centered =============================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.2104, Train Acc: 0.6745\n",
    "# Epoch:39 > Val Loss: 1.4204, Val Acc: 0.6515\n",
    "# ==================================================\n",
    "# Additional Normalize and Nan Step  0.6100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee18c7f",
   "metadata": {},
   "source": [
    "# Torch Single Model Save, Retrieve and Rum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53e89433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE MODEL\n",
    "\n",
    "PATH = f\"{ARCHIVE_DIR}/models/modelccn{FRAMES_OUT}flat.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "817a73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD MODEL\n",
    "\n",
    "PATH = f\"{ARCHIVE_DIR}/models/modelccn{FRAMES_OUT}flat.pt\"\n",
    "tf_mod = torch.load(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cd9f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PYTORCH MODELS\n",
    "class AModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AModel, self).__init__()\n",
    "        \n",
    "        self.InputFormat = FeatureGen() #feature_converter\n",
    "        self.InferModel = tf_mod\n",
    "        self.InferModel.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1,x2,x3,x4 = self.InputFormat(x)\n",
    "        pred = self.InferModel(x1,x2,x3,x4)\n",
    "        return pred\n",
    "\n",
    "mod_cnn = AModel()\n",
    "mod_cnn_pt_path = f\"{ARCHIVE_DIR}/models/modelcnn{FRAMES_OUT}test.pt\"\n",
    "torch.save(mod, PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "885e7ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94477, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "557b3a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 2022    56\n",
      "Name: label, dtype: int64 2022    dance\n",
      "Name: sign, dtype: object prediction= 56\n"
     ]
    }
   ],
   "source": [
    "Infmodel = torch.load(mod_cnn_pt_path)\n",
    "\n",
    "d = df[2022:2023]\n",
    "\n",
    "x = load_relevant_data_subset(os.path.join(BASE_DIR, d['path'].item()))\n",
    "pred = Infmodel(x)\n",
    "\n",
    "print(\"truth:\", d.label, d.sign, \"prediction=\", np.argmax(pred.detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cdfa49",
   "metadata": {},
   "source": [
    "# TFLITE CONVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --quiet --root-user-action=ignore\n",
    "!pip install tensorflow_probability --quiet --root-user-action=ignore\n",
    "\n",
    "!pip install onnx-tf --quiet --root-user-action=ignore\n",
    "!pip install tflite-runtime  --quiet --root-user-action=ignore\n",
    "import onnx_tf\n",
    "import tflite_runtime\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55d70d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{ARCHIVE_DIR}/models/tf_mod_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{ARCHIVE_DIR}/models/tf_mod_cnn/assets\n",
      "2023-04-29 11:06:06.767386: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-29 11:06:06.767406: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-04-29 11:06:06.767643: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: f\"{ARCHIVE_DIR}/models/tf_mod_cnn\n",
      "2023-04-29 11:06:06.770605: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-04-29 11:06:06.770621: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: f\"{ARCHIVE_DIR}/models/tf_mod_cnn\n",
      "2023-04-29 11:06:06.779119: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-04-29 11:06:06.803394: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: f\"{ARCHIVE_DIR}/models/tf_mod_cnn\n",
      "2023-04-29 11:06:06.817658: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 50016 microseconds.\n"
     ]
    }
   ],
   "source": [
    "## CNN MODEL CONVERSION\n",
    "# pmodel_path = f\"{ARCHIVE_DIR}/models/modelccn16flat.sd\"\n",
    "# modelc = ASLModel(.1)\n",
    "# modelc.load_state_dict(torch.load(py_model_path))\n",
    "# modelc.eval()\n",
    "\n",
    "sample_input = torch.rand((50, 543, 3))\n",
    "onnx_mod_cnn_path = f\"{MODEL_DIR}/model_cnn.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    mod,                    # PyTorch Model\n",
    "    sample_input,                    # Input tensor\n",
    "    onnx_mod_cnn_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_mod_cnn_gen = onnx.load(onnx_mod_cnn_path)\n",
    "tf_rep = prepare(onnx_mod_cnn_gen)\n",
    "\n",
    "tf_mod_cnn_path = 'f\"{MODEL_DIR}/tf_mod_cnn'\n",
    "tf_rep.export_graph(tf_mod_cnn_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1016b362",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_61195/716860762.py\", line 15, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})['output'][0,:]\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output_tensors\n\u001b[1;32m     19\u001b[0m mytfmodel \u001b[38;5;241m=\u001b[39m ASLInferModel()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tf_infer_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1240\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1240\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1402\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1399\u001b[0m       augmented_graph_view)\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n\u001b[1;32m   1404\u001b[0m signature_map \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mcreate_signature_map(signatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:131\u001b[0m, in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    129\u001b[0m wrapped_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature_key, function \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 131\u001b[0m   original_function \u001b[38;5;241m=\u001b[39m signature_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m signature_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a TensorFlow function for which to generate a signature, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Only `tf.functions` with an input signature or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcrete functions can be used as a signature.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:43\u001b[0m, in \u001b[0;36m_get_signature\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_signature\u001b[39m(function):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(function, (defun\u001b[38;5;241m.\u001b[39mFunction, def_function\u001b[38;5;241m.\u001b[39mFunction)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     42\u001b[0m       function\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     function \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:484\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/__autograph_generated_filep9qead7n.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(output_tensors)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:740\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_61195/716860762.py\", line 15, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})['output'][0,:]\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ASLInferModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLInferModel, self).__init__()\n",
    "        \n",
    "        self.model = tf.saved_model.load(tf_mod_cnn_path)\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
    "    ])\n",
    "    def call(self, input):\n",
    "        output_tensors = {}\n",
    "        output_tensors['outputs'] = self.model(**{'input': input})['output'][0,:]\n",
    "        return output_tensors\n",
    "    \n",
    "    \n",
    "mytfmodel = ASLInferModel()\n",
    "tf.saved_model.save(mytfmodel, \n",
    "                    f'{MODEL_DIR}/tf_infer_model', \n",
    "                    signatures={'serving_default': mytfmodel.call})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b09b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO TFLITE\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_mod_cnn_path) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "# Save the model.\n",
    "TF_MODEL_PATH_LITE = f\"{MODEL_DIR}/model_cnn.tflite\"\n",
    "with open(TF_MODEL_PATH, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2623c34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found_signatures\n",
      "serving_default\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid number of inputs provided for running a SignatureDef, expected 0 vs provided 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m vid \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m26\u001b[39m]\u001b[38;5;241m.\u001b[39mpath\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m load_relevant_data_subset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#interpreter.invoke()\u001b[39;00m\n\u001b[1;32m     20\u001b[0m sign \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py:230\u001b[0m, in \u001b[0;36mSignatureRunner.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"Runs the SignatureDef given the provided inputs in arguments.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m  Value is the result Tensor.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs):\n\u001b[0;32m--> 230\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid number of inputs provided for running a SignatureDef, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    232\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs provided \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs), \u001b[38;5;28mlen\u001b[39m(kwargs)))\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Resize input tensors\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_name, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid number of inputs provided for running a SignatureDef, expected 0 vs provided 1"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_PATH_LITE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "print(\"found_signatures\")\n",
    "print(found_signatures[0])\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))   ###CHANGE\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "\n",
    "vid = df.iloc[26].path\n",
    "x = load_relevant_data_subset(f\"{BASE_DIR}/{vid}\")\n",
    "output = prediction_fn(x)\n",
    "#interpreter.invoke()\n",
    "\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b83bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
