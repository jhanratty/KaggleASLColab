{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FEATURE FILES FROM GDRIVE \n",
    "# COLAB ONLY - MOVE FEATURE FILES TO WORKING DIRECTORY\n",
    "# \n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists(WORKING_DIR):\n",
    "  !mkdir '/content/asl-work'\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   # shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_data{FRAMES_OUT}.npy\", f\"{WORKING_DIR}\")\n",
    "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_labels.npy\", f\"{WORKING_DIR}\")\n",
    "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/sign_to_prediction_index_map.json\", f\"{WORKING_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5c251a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:00.056762Z",
     "iopub.status.busy": "2023-04-27T09:22:00.056345Z",
     "iopub.status.idle": "2023-04-27T09:22:01.788737Z",
     "shell.execute_reply": "2023-04-27T09:22:01.787457Z",
     "shell.execute_reply.started": "2023-04-27T09:22:00.056725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Jupiter  MacOS\n",
    "BASE_DIR = \"/Users/johnhanratty/ASLtest/asl-signs\"  #\"/Users/johnhanratty/ASLtest/asl-signs\"\n",
    "WORKING_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "ARCHIVE_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "MODELS_DIR = \"/Users/johnhanratty/ASLtest/models\"\n",
    "\n",
    "# !pip install nb_black --quiet\n",
    "# %load_ext lab_black\n",
    "\n",
    "# Colab\n",
    "# BASE_DIR = \"/content/asl-signs\"   #\"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
    "# WORKING_DIR = \"/content/asl-work\"\n",
    "# ARCHIVE_DIR = \"/content/drive/MyDrive/GaggleSignLang\"\n",
    "# !pip install nb_black --quiet\n",
    "# print('-----ok')\n",
    "# %load_ext nb_black\n",
    "\n",
    "# KAGGLE\n",
    "# BASE_DIR = \"/kaggle/input/asl-signs\"\n",
    "# WORKING_DIR = \"/kaggle/working\"\n",
    "# ARCHIVE_DIR = \"/kaggle/working\"\n",
    "# MODEL_DIR  = \"/kaggle/working\"\n",
    "# !pip install nb_black --quiet --root-user-action=ignore\n",
    "# %load_ext lab_black\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import seed, sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
    "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
    "\n",
    "FRAMES_OUT = 32 # 16\n",
    "PTS_IN_FRAME = 345\n",
    "DIMC = [0,1,2]\n",
    "DIMS = len(DIMC)\n",
    "WORKERS = 0   # dataoader work var  0 for MAC, 4 for online\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41802f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:06.975674Z",
     "iopub.status.busy": "2023-04-27T09:22:06.975115Z",
     "iopub.status.idle": "2023-04-27T09:22:06.982263Z",
     "shell.execute_reply": "2023-04-27T09:22:06.981046Z",
     "shell.execute_reply.started": "2023-04-27T09:22:06.975635Z"
    }
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6048e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:24.657013Z",
     "iopub.status.busy": "2023-04-27T09:22:24.656552Z",
     "iopub.status.idle": "2023-04-27T09:22:24.672857Z",
     "shell.execute_reply": "2023-04-27T09:22:24.671586Z",
     "shell.execute_reply.started": "2023-04-27T09:22:24.656974Z"
    }
   },
   "outputs": [],
   "source": [
    "#FEATUREGEN MODEL\n",
    "ROWS_PER_FRAME = 543  # combined face, lefth, pose, righth\n",
    "\n",
    "# FILTER FEATURES IN EACH FRAME  - FACE, POSE & HANDs\n",
    "class FeatureGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # FILTER TO SPECIFIED FRAMES (FRAMES_OUT)\n",
    "        seed(24)\n",
    "        x = np.array(x)\n",
    "        n_frames = x.shape[0]\n",
    "        # Trim to # of frames to FRAMES_OUT\n",
    "        if n_frames > FRAMES_OUT:\n",
    "            idx = sorted((sample(range(0, n_frames), FRAMES_OUT)))\n",
    "            x=x[idx,:,:]\n",
    "        n_frames = x.shape[0]\n",
    "        # FLATTENING ROWS BY TYPE and CONCATENATING TO ONE ROW PER FRAME 3D (XYZ)\n",
    "        # INPUT NUMPY, TORCH OUTPUT\n",
    "\n",
    "        # Grab data type (e.g. one point on hand) by selecting rows for each frame\n",
    "        # face_x = x[:,:468,:].contiguous().view(-1, 468*3)\n",
    "        lips_idx = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "        lips_x = x[:, lips_idx,:].reshape(-1, len(lips_idx)*3)\n",
    "        lefth_x = x[:,468:489,:].reshape(-1, 21*3)\n",
    "        pose_x = x[:,489:522,:].reshape(-1, 33*3)\n",
    "        righth_x = x[:,522:,:].reshape(-1, 21*3)\n",
    "\n",
    "        if np.isnan(lefth_x).sum() < np.isnan(righth_x).sum():\n",
    "            prime_x = lefth_x\n",
    "            second_x = righth_x\n",
    "        else:\n",
    "            prime_x = righth_x.reshape(righth_x.shape[0], -1, DIMS)\n",
    "            prime_x[:,:,0] = np.add(np.nanmax(prime_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                    prime_x[:, :, 0])\n",
    "            prime_x = prime_x.reshape(prime_x.shape[0],-1)\n",
    "            \n",
    "            second_x = lefth_x.reshape(lefth_x.shape[0], -1, DIMS)\n",
    "            second_x[:,:,0] = np.subtract(np.nanmax(second_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                          second_x[:, :, 0])\n",
    "            second_x = second_x.reshape(second_x.shape[0],-1)\n",
    "            \n",
    "        # ?? remove empty frames ???\n",
    "        \n",
    "        # flatten types into one row per frame\n",
    "        xfeat = np.full([FRAMES_OUT, PTS_IN_FRAME], np.nan)\n",
    "        offset = (FRAMES_OUT - n_frames) // 2  # center frames in output data in each frame in video\n",
    "        xfeat[offset:n_frames+offset,:] = np.concatenate([lips_x, prime_x, pose_x, second_x], axis=1)  # concatenate types\n",
    "        \n",
    "        \n",
    "        def distDiff(ds, ref, pts):\n",
    "            ds = ds.reshape(ds.shape[0],  -1, DIMS)\n",
    "            d = np.hstack([np.nanmean(ds[:, pts, :], axis=0), \n",
    "                           np.nanmedian(ds[:, pts, :], axis=0), \n",
    "                           np.nanmax(ds[:, pts, :], axis=0), \n",
    "                           np.nanmin(ds[:, pts, :], axis=0),\n",
    "                           np.nanvar(ds[:, pts, :], axis=0)\n",
    "                           ]) \n",
    "            d = d.reshape(1, -1) \n",
    "            # NORMALIZE\n",
    "           # d = (d - np.nanmean(d, keepdims=True)) / np.nanstd(d, keepdims=True) # -1 to 1\n",
    "            d = np.nan_to_num(d, copy=False)  # replace NaN after normalization\n",
    "            return d\n",
    "        \n",
    "        d1 = distDiff(xfeat, 40, [44, 48, 52, 56, 60, 43, 46, 50, 54, 58])\n",
    "        d2 = distDiff(xfeat, 40, [98, 102, 106, 110, 114, 97, 102, 106, 110, 114])\n",
    "        d3 = distDiff(xfeat, 60, [73, 80, 81, 76, 77, 68, 69, 70, 71, 75, 74])\n",
    "        d4 = distDiff(xfeat, 5,  [0, 4, 8, 12, 16, 20, 24, 28, 32, 36])\n",
    "        return d1, d2, d3, d4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd1fee39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T10:13:04.044426Z",
     "iopub.status.busy": "2023-04-27T10:13:04.043547Z",
     "iopub.status.idle": "2023-04-27T10:16:04.541551Z",
     "shell.execute_reply": "2023-04-27T10:16:04.540255Z",
     "shell.execute_reply.started": "2023-04-27T10:13:04.044379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert&Save (94477, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 2/94477 [00:00<1:23:03, 18.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (23, 543, 3)\n",
      "X.shape (11, 543, 3)\n",
      "X.shape (105, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (30, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                         | 8/94477 [00:00<40:51, 38.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (23, 543, 3)\n",
      "X.shape (57, 543, 3)\n",
      "X.shape (49, 543, 3)\n",
      "X.shape (19, 543, 3)\n",
      "X.shape (33, 543, 3)\n",
      "X.shape (13, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 15/94477 [00:00<31:13, 50.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (19, 543, 3)\n",
      "X.shape (141, 543, 3)\n",
      "X.shape (43, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (22, 543, 3)\n",
      "X.shape (100, 543, 3)\n",
      "X.shape (22, 543, 3)\n",
      "X.shape (13, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (13, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 26/94477 [00:00<22:05, 71.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (12, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (26, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (127, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (11, 543, 3)\n",
      "X.shape (6, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 37/94477 [00:00<19:00, 82.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (63, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (44, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (32, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (53, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 46/94477 [00:00<18:36, 84.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (225, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (38, 543, 3)\n",
      "X.shape (60, 543, 3)\n",
      "X.shape (116, 543, 3)\n",
      "X.shape (16, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 58/94477 [00:00<16:37, 94.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (18, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (48, 543, 3)\n",
      "X.shape (41, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (9, 543, 3)\n",
      "X.shape (59, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (68, 543, 3)\n",
      "X.shape (36, 543, 3)\n",
      "X.shape (24, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                       | 70/94477 [00:00<15:41, 100.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (14, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (125, 543, 3)\n",
      "X.shape (11, 543, 3)\n",
      "X.shape (54, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                       | 82/94477 [00:00<14:50, 106.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (62, 543, 3)\n",
      "X.shape (50, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (62, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (89, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (33, 543, 3)\n",
      "X.shape (19, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                       | 95/94477 [00:01<13:58, 112.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (63, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (60, 543, 3)\n",
      "X.shape (28, 543, 3)\n",
      "X.shape (5, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (59, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 107/94477 [00:01<14:28, 108.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (105, 543, 3)\n",
      "X.shape (163, 543, 3)\n",
      "X.shape (34, 543, 3)\n",
      "X.shape (37, 543, 3)\n",
      "X.shape (13, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (34, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (75, 543, 3)\n",
      "X.shape (43, 543, 3)\n",
      "X.shape (98, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (30, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 118/94477 [00:01<14:44, 106.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (161, 543, 3)\n",
      "X.shape (61, 543, 3)\n",
      "X.shape (53, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (33, 543, 3)\n",
      "X.shape (32, 543, 3)\n",
      "X.shape (24, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 129/94477 [00:01<14:37, 107.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (18, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (11, 543, 3)\n",
      "X.shape (25, 543, 3)\n",
      "X.shape (199, 543, 3)\n",
      "X.shape (55, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (30, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (16, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 142/94477 [00:01<14:01, 112.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (8, 543, 3)\n",
      "X.shape (9, 543, 3)\n",
      "X.shape (76, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (26, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 155/94477 [00:01<13:27, 116.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (71, 543, 3)\n",
      "X.shape (58, 543, 3)\n",
      "X.shape (52, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (3, 543, 3)\n",
      "X.shape (33, 543, 3)\n",
      "X.shape (100, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (20, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 168/94477 [00:01<13:09, 119.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (47, 543, 3)\n",
      "X.shape (11, 543, 3)\n",
      "X.shape (26, 543, 3)\n",
      "X.shape (45, 543, 3)\n",
      "X.shape (42, 543, 3)\n",
      "X.shape (14, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 180/94477 [00:01<14:23, 109.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (311, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (36, 543, 3)\n",
      "X.shape (225, 543, 3)\n",
      "X.shape (42, 543, 3)\n",
      "X.shape (48, 543, 3)\n",
      "X.shape (76, 543, 3)\n",
      "X.shape (105, 543, 3)\n",
      "X.shape (3, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (116, 543, 3)\n",
      "X.shape (13, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 192/94477 [00:01<14:14, 110.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (19, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (39, 543, 3)\n",
      "X.shape (32, 543, 3)\n",
      "X.shape (45, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (8, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 204/94477 [00:02<13:58, 112.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (145, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (56, 543, 3)\n",
      "X.shape (25, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (16, 543, 3)\n",
      "X.shape (37, 543, 3)\n",
      "X.shape (44, 543, 3)\n",
      "X.shape (42, 543, 3)\n",
      "X.shape (16, 543, 3)\n",
      "X.shape (22, 543, 3)\n",
      "X.shape (48, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 216/94477 [00:02<13:48, 113.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (8, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (219, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (9, 543, 3)\n",
      "X.shape (43, 543, 3)\n",
      "X.shape (108, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (10, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 229/94477 [00:02<13:18, 118.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (24, 543, 3)\n",
      "X.shape (34, 543, 3)\n",
      "X.shape (39, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (25, 543, 3)\n",
      "X.shape (30, 543, 3)\n",
      "X.shape (13, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (61, 543, 3)\n",
      "X.shape (6, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 242/94477 [00:02<13:15, 118.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (32, 543, 3)\n",
      "X.shape (34, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (164, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (9, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 254/94477 [00:02<13:17, 118.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (188, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (16, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (128, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (114, 543, 3)\n",
      "X.shape (19, 543, 3)\n",
      "X.shape (13, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 267/94477 [00:02<13:10, 119.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (14, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (24, 543, 3)\n",
      "X.shape (43, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (45, 543, 3)\n",
      "X.shape (86, 543, 3)\n",
      "X.shape (16, 543, 3)\n",
      "X.shape (16, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 279/94477 [00:02<13:12, 118.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (44, 543, 3)\n",
      "X.shape (53, 543, 3)\n",
      "X.shape (52, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (33, 543, 3)\n",
      "X.shape (29, 543, 3)\n",
      "X.shape (9, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (125, 543, 3)\n",
      "X.shape (25, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (130, 543, 3)\n",
      "X.shape (6, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 292/94477 [00:02<12:59, 120.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (17, 543, 3)\n",
      "X.shape (44, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (13, 543, 3)\n",
      "X.shape (100, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (41, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (20, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 305/94477 [00:02<12:56, 121.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (9, 543, 3)\n",
      "X.shape (21, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (33, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (71, 543, 3)\n",
      "X.shape (38, 543, 3)\n",
      "X.shape (8, 543, 3)\n",
      "X.shape (53, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (22, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (52, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                     | 319/94477 [00:02<12:35, 124.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (26, 543, 3)\n",
      "X.shape (15, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (10, 543, 3)\n",
      "X.shape (17, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (56, 543, 3)\n",
      "X.shape (6, 543, 3)\n",
      "X.shape (14, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (25, 543, 3)\n",
      "X.shape (74, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                     | 332/94477 [00:03<12:56, 121.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (14, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (13, 543, 3)\n",
      "X.shape (36, 543, 3)\n",
      "X.shape (12, 543, 3)\n",
      "X.shape (16, 543, 3)\n",
      "X.shape (61, 543, 3)\n",
      "X.shape (18, 543, 3)\n",
      "X.shape (27, 543, 3)\n",
      "X.shape (223, 543, 3)\n",
      "X.shape (196, 543, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                     | 337/94477 [00:03<14:38, 107.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (27, 543, 3)\n",
      "X.shape (23, 543, 3)\n",
      "X.shape (7, 543, 3)\n",
      "X.shape (20, 543, 3)\n",
      "X.shape (84, 543, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m npdata1, npdata2, npdata3, npdata4, nplabels\n\u001b[1;32m     37\u001b[0m feature_converter \u001b[38;5;241m=\u001b[39m FeatureGen()\n\u001b[0;32m---> 38\u001b[0m d1, d2, d3, d4, datay \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_and_save_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 28\u001b[0m, in \u001b[0;36mconvert_and_save_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m nplabels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(convert_row, df\u001b[38;5;241m.\u001b[39miterrows())\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x1,x2,x3,x4,y) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(results), total\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     29\u001b[0m         npdata1[i,:] \u001b[38;5;241m=\u001b[39m x1\n\u001b[1;32m     30\u001b[0m         npdata2[i,:] \u001b[38;5;241m=\u001b[39m x2\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m, in \u001b[0;36mconvert_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m load_relevant_data_subset(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpath))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m x1,x2,x3,x4 \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x1,x2,x3,x4, row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlabel\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m, in \u001b[0;36mFeatureGen.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m d2 \u001b[38;5;241m=\u001b[39m distDiff(xfeat, \u001b[38;5;241m40\u001b[39m, [\u001b[38;5;241m98\u001b[39m, \u001b[38;5;241m102\u001b[39m, \u001b[38;5;241m106\u001b[39m, \u001b[38;5;241m110\u001b[39m, \u001b[38;5;241m114\u001b[39m, \u001b[38;5;241m97\u001b[39m, \u001b[38;5;241m102\u001b[39m, \u001b[38;5;241m106\u001b[39m, \u001b[38;5;241m110\u001b[39m, \u001b[38;5;241m114\u001b[39m])\n\u001b[1;32m     69\u001b[0m d3 \u001b[38;5;241m=\u001b[39m distDiff(xfeat, \u001b[38;5;241m60\u001b[39m, [\u001b[38;5;241m73\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m81\u001b[39m, \u001b[38;5;241m76\u001b[39m, \u001b[38;5;241m77\u001b[39m, \u001b[38;5;241m68\u001b[39m, \u001b[38;5;241m69\u001b[39m, \u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m75\u001b[39m, \u001b[38;5;241m74\u001b[39m])\n\u001b[0;32m---> 70\u001b[0m d4 \u001b[38;5;241m=\u001b[39m \u001b[43mdistDiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxfeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d1, d2, d3, d4\n",
      "Cell \u001b[0;32mIn[3], line 55\u001b[0m, in \u001b[0;36mFeatureGen.forward.<locals>.distDiff\u001b[0;34m(ds, ref, pts)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistDiff\u001b[39m(ds, ref, pts):\n\u001b[1;32m     54\u001b[0m     ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mreshape(ds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, DIMS)\n\u001b[0;32m---> 55\u001b[0m     d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \n\u001b[1;32m     56\u001b[0m                    np\u001b[38;5;241m.\u001b[39mnanmedian(ds[:, pts, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \n\u001b[1;32m     57\u001b[0m                    np\u001b[38;5;241m.\u001b[39mnanmax(ds[:, pts, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \n\u001b[1;32m     58\u001b[0m                    np\u001b[38;5;241m.\u001b[39mnanmin(ds[:, pts, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     59\u001b[0m                    np\u001b[38;5;241m.\u001b[39mnanvar(ds[:, pts, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m                    ]) \n\u001b[1;32m     61\u001b[0m     d \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# NORMALIZE\u001b[39;00m\n\u001b[1;32m     63\u001b[0m    \u001b[38;5;66;03m# d = (d - np.nanmean(d, keepdims=True)) / np.nanstd(d, keepdims=True) # -1 to 1\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1045\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf a is inexact, then out must be inexact\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1045\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m             \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m tot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(arr, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[1;32m   1048\u001b[0m              where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m   1049\u001b[0m avg \u001b[38;5;241m=\u001b[39m _divide_by_count(tot, cnt, out\u001b[38;5;241m=\u001b[39mout)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2296\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "## PROCESS EACH ROW (ONE PARQUET PER ROW)\n",
    "def convert_row(row):\n",
    "    x = load_relevant_data_subset(os.path.join(BASE_DIR, row[1].path))\n",
    "    x1,x2,x3,x4 = feature_converter(torch.tensor(x))\n",
    "    return x1,x2,x3,x4, row[1].label\n",
    "\n",
    "## LOOP THROUGH PARQUET FILES LISTED IN TRAIN FILE\n",
    "##  SAVE RESULTS \n",
    "def convert_and_save_data():\n",
    "    label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    \n",
    "    print(\"Convert&Save\", df.shape)\n",
    "    #### FOR TESTING #################\n",
    "    #df = df[0:20]\n",
    "    ##################################\n",
    "\n",
    "    npdata1 = np.zeros((df.shape[0], 150))\n",
    "    npdata2 = np.zeros((df.shape[0], 150))\n",
    "    npdata3 = np.zeros((df.shape[0], 165))\n",
    "    npdata4 = np.zeros((df.shape[0], 150))\n",
    "\n",
    "    nplabels = np.zeros(df.shape[0])\n",
    "    \n",
    "    results = map(convert_row, df.iterrows())\n",
    "    for i, (x1,x2,x3,x4,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
    "            npdata1[i,:] = x1\n",
    "            npdata2[i,:] = x2\n",
    "            npdata3[i,:] = x3\n",
    "            npdata4[i,:] = x4\n",
    "            nplabels[i] = y\n",
    "    return npdata1, npdata2, npdata3, npdata4, nplabels\n",
    " \n",
    "\n",
    "feature_converter = FeatureGen()\n",
    "d1, d2, d3, d4, datay = convert_and_save_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cbb9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "np.save(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_1.npy\", d1)\n",
    "np.save(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_2.npy\", d2)\n",
    "np.save(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_3.npy\", d3)\n",
    "np.save(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_4.npy\", d4)\n",
    "\n",
    "np.save(f\"{WORKING_DIR}/cnn_labels.npy\", datay)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77025430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "d1 = np.load(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_1.npy\")\n",
    "d2 = np.load(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_2.npy\")\n",
    "d3 = np.load(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_3.npy\")\n",
    "d4 = np.load(f\"{WORKING_DIR}/cnn_data{FRAMES_OUT}_4.npy\")\n",
    "\n",
    "datay = np.load(f\"{WORKING_DIR}/cnn_labels.npy\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "704dc178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:34.423269Z",
     "iopub.status.busy": "2023-04-27T11:16:34.422846Z",
     "iopub.status.idle": "2023-04-27T11:16:34.445881Z",
     "shell.execute_reply": "2023-04-27T11:16:34.444872Z",
     "shell.execute_reply.started": "2023-04-27T11:16:34.423234Z"
    }
   },
   "outputs": [],
   "source": [
    "#MODEL\n",
    "### NEW SEPARATED INPUTS\n",
    "class ASLData(Dataset):\n",
    "    def __init__(self,d1,d2,d3,d4,datay):\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "        self.d3 = d3\n",
    "        self.d4 = d4\n",
    "        self.datay = datay\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.d1[index, :], self.d2[index, :],self.d3[index, :],self.d4[index, :], self.datay[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datay)\n",
    "\n",
    "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(ASLModel, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        L1OUT = 512  #1024 was ok\n",
    "        L2OUT = 512\n",
    "\n",
    "        self.layer_ph = nn.Linear(150, L1OUT)\n",
    "        self.batchnorm_ph = nn.BatchNorm1d(L1OUT)\n",
    "        \n",
    "        self.layer_sh = nn.Linear(150, L1OUT)\n",
    "        self.batchnorm_sh = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_po = nn.Linear(165, L1OUT)\n",
    "        self.batchnorm_po = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_li = nn.Linear(150, L1OUT)\n",
    "        self.batchnorm_li = nn.BatchNorm1d(L1OUT) \n",
    " \n",
    "        self.layer1 = nn.Linear(4*L1OUT, L2OUT)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(L2OUT)\n",
    "\n",
    "        self.layerFC = nn.Linear(L2OUT, 250)\n",
    "        self.softmax = nn.Softmax()\n",
    " \n",
    "        \n",
    "    def forward(self, phand, shand, pose, lips):\n",
    "        print(\"PHAND\", phand.shape)\n",
    "        phand = torch.tensor(phand)  # Convert to Torch Tensor\n",
    "        shand = torch.tensor(shand)  # Convert to Torch Tensor\n",
    "        pose = torch.tensor(pose)  # Convert to Torch Tensor\n",
    "        lips = torch.tensor(lips)  # Convert to Torch Tensor\n",
    "        \n",
    "        ph = self.flatten(torch.tensor(phand).float()) \n",
    "        ph = self.layer_ph(ph)\n",
    "        ph = self.batchnorm_ph(ph)\n",
    "        ph = self.relu(ph)\n",
    "        ph = self.dropout(ph)\n",
    "\n",
    "        sh = self.flatten(torch.tensor(shand).float())       \n",
    "        sh = self.layer_sh(sh)\n",
    "        sh = self.batchnorm_sh(sh)\n",
    "        sh = self.relu(sh)\n",
    "        sh = self.dropout(sh)\n",
    "       \n",
    "        po = self.flatten(torch.tensor(pose).float())       \n",
    "        po = self.layer_po(po)\n",
    "        po = self.batchnorm_po(po)\n",
    "        po = self.relu(po)\n",
    "        po = self.dropout(po)\n",
    "        \n",
    "        li = self.flatten(torch.tensor(lips).float())       \n",
    "        li = self.layer_li(li)\n",
    "        li = self.batchnorm_li(li)\n",
    "        li = self.relu(li)\n",
    "        li = self.dropout(li)\n",
    "\n",
    "        x = torch.cat((ph.view(ph.size(0), -1),\n",
    "                       sh.view(sh.size(0), -1),\n",
    "                       po.view(po.size(0), -1),\n",
    "                       li.view(li.size(0), -1)), dim=1)\n",
    "        # x = self.batchnorm0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layerFC(x)\n",
    "       # x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f30afac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:40.228537Z",
     "iopub.status.busy": "2023-04-27T11:16:40.227418Z",
     "iopub.status.idle": "2023-04-27T11:17:22.481778Z",
     "shell.execute_reply": "2023-04-27T11:17:22.480359Z",
     "shell.execute_reply.started": "2023-04-27T11:16:40.228485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++using CPU++++\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n",
      "PHAND torch.Size([64, 150])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y)\n\u001b[1;32m     46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 47\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     50\u001b[0m train_loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## MULTI TRAINING\n",
    "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"++++using GPU++++\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"++++using CPU++++\")\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
    "#datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "d1 = torch.tensor(d1)  # Convert to Torch Tensor\n",
    "d2 = torch.tensor(d2)  # Convert to Torch Tensor\n",
    "d3 = torch.tensor(d3)  # Convert to Torch Tensor\n",
    "d4 = torch.tensor(d4)  # Convert to Torch Tensor\n",
    "traind1, testd1, traind2, testd2, traind3, tesdt3,traind4,testd4, trainy, testy = train_test_split(d1, d2, d3, d4, datay, test_size=0.15, random_state=42)\n",
    "train_data = ASLData(traind1, traind2, traind3, traind4, trainy)\n",
    "valid_data = ASLData(testd1, testd2, tesdt3, testd4, testy)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=True)\n",
    "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=False)\n",
    "model = ASLModel(0.2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_sum = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_bar = train_loader\n",
    "    for x1,x2,x3,x4,y in train_bar:\n",
    "        x1 = torch.Tensor(x1).float().to(device)\n",
    "        x2 = torch.Tensor(x2).float().to(device)\n",
    "        x3 = torch.Tensor(x3).float().to(device)\n",
    "        x4 = torch.Tensor(x4).float().to(device)\n",
    "\n",
    "        y = torch.Tensor(y).long().to(device) \n",
    "        y_pred = model(x1,x2,x3,x4)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_sum += loss.item()\n",
    "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "        train_total += 1\n",
    "        sched.step()\n",
    "        \n",
    "    val_loss_sum = 0.\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    for x1,x2,x3,x4,y in val_loader:\n",
    "        x1 = torch.Tensor(x1).float().to(device)\n",
    "        x2 = torch.Tensor(x2).float().to(device)\n",
    "        x3 = torch.Tensor(x3).float().to(device)\n",
    "        x4 = torch.Tensor(x4).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x1,x2,x3,x4)\n",
    "            loss = criterion(y_pred, y)\n",
    "            val_loss_sum += loss.item()\n",
    "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "            val_total += 1\n",
    "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
    "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
    "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Save the pytorch model\n",
    "PATH = f\"{ARCHIVE_DIR}/models/modelccn{FRAMES_OUT}flat.sd\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49046438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ========Full Data - no add Norm, Centered ========\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:38 > Train Loss: 0.9867, Train Acc: 0.7321\n",
    "# Epoch:38 > Val Loss: 1.2608, Val Acc: 0.6988\n",
    "# ==================================================\n",
    "\n",
    "# ========Full Data - no additional Normalizeation/Centering=====================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.4974, Train Acc: 0.6059\n",
    "# Epoch:39 > Val Loss: 1.7298, Val Acc: 0.5839\n",
    "# ==================================================\n",
    "\n",
    "# =====Full no reverse, centered =============================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.2104, Train Acc: 0.6745\n",
    "# Epoch:39 > Val Loss: 1.4204, Val Acc: 0.6515\n",
    "# ==================================================\n",
    "# Additional Normalize and Nan Step  0.6100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa2d19",
   "metadata": {},
   "source": [
    "# Torch Single Model Save, Retrieve and Rum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69697942",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE MODEL\n",
    "\n",
    "PATH = f\"{ARCHIVE_DIR}/models/modelccn{FRAMES_OUT}flat.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e78738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD MODEL\n",
    "\n",
    "PATH = f\"{ARCHIVE_DIR}/models/modelccn{FRAMES_OUT}flat.pt\"\n",
    "tf_mod = torch.load(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cd9f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PYTORCH MODELS\n",
    "class AModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AModel, self).__init__()\n",
    "        \n",
    "        self.InputFormat = FeatureGen() #feature_converter\n",
    "        self.InferModel = tf_mod\n",
    "        self.InferModel.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1,x2,x3,x4 = self.InputFormat(x)\n",
    "        pred = self.InferModel(x1,x2,x3,x4)\n",
    "        return pred\n",
    "\n",
    "mod_cnn = AModel()\n",
    "mod_cnn_pt_path = f\"{ARCHIVE_DIR}/models/modelcnn{FRAMES_OUT}test.pt\"\n",
    "torch.save(mod, PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "885e7ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94477, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "557b3a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 2022    56\n",
      "Name: label, dtype: int64 2022    dance\n",
      "Name: sign, dtype: object prediction= 56\n"
     ]
    }
   ],
   "source": [
    "Infmodel = torch.load(mod_cnn_pt_path)\n",
    "\n",
    "d = df[2022:2023]\n",
    "\n",
    "x = load_relevant_data_subset(os.path.join(BASE_DIR, d['path'].item()))\n",
    "pred = Infmodel(x)\n",
    "\n",
    "print(\"truth:\", d.label, d.sign, \"prediction=\", np.argmax(pred.detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8c95c",
   "metadata": {},
   "source": [
    "# TFLITE CONVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --quiet --root-user-action=ignore\n",
    "!pip install tensorflow_probability --quiet --root-user-action=ignore\n",
    "\n",
    "!pip install onnx-tf --quiet --root-user-action=ignore\n",
    "!pip install tflite-runtime  --quiet --root-user-action=ignore\n",
    "import onnx_tf\n",
    "import tflite_runtime\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbb3cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{ARCHIVE_DIR}/models/tf_mod_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{ARCHIVE_DIR}/models/tf_mod_cnn/assets\n",
      "2023-04-29 11:06:06.767386: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-04-29 11:06:06.767406: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-04-29 11:06:06.767643: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: f\"{ARCHIVE_DIR}/models/tf_mod_cnn\n",
      "2023-04-29 11:06:06.770605: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-04-29 11:06:06.770621: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: f\"{ARCHIVE_DIR}/models/tf_mod_cnn\n",
      "2023-04-29 11:06:06.779119: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-04-29 11:06:06.803394: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: f\"{ARCHIVE_DIR}/models/tf_mod_cnn\n",
      "2023-04-29 11:06:06.817658: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 50016 microseconds.\n"
     ]
    }
   ],
   "source": [
    "## CNN MODEL CONVERSION\n",
    "# pmodel_path = f\"{ARCHIVE_DIR}/models/modelccn16flat.sd\"\n",
    "# modelc = ASLModel(.1)\n",
    "# modelc.load_state_dict(torch.load(py_model_path))\n",
    "# modelc.eval()\n",
    "gen_feat = FeatureGen()\n",
    "mod_cnn = tf_mod\n",
    "\n",
    "\n",
    "sample_input = torch.rand((50, 543, 3))\n",
    "onnx_mod_cnn_path = f\"{ARCHIVE_DIR}/models/model_cnn.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    mod,                    # PyTorch Model\n",
    "    sample_input,                    # Input tensor\n",
    "    onnx_mod_cnn_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={\n",
    "        'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_mod_cnn_gen = onnx.load(onnx_mod_cnn_path)\n",
    "tf_rep = prepare(onnx_mod_cnn_gen)\n",
    "\n",
    "tf_mod_cnn_path = 'f\"{ARCHIVE_DIR}/models/tf_mod_cnn'\n",
    "tf_rep.export_graph(tf_mod_cnn_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea9806d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_61195/716860762.py\", line 15, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})['output'][0,:]\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output_tensors\n\u001b[1;32m     19\u001b[0m mytfmodel \u001b[38;5;241m=\u001b[39m ASLInferModel()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tf_infer_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1240\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1240\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1402\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1399\u001b[0m       augmented_graph_view)\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n\u001b[1;32m   1404\u001b[0m signature_map \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mcreate_signature_map(signatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:131\u001b[0m, in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    129\u001b[0m wrapped_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature_key, function \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 131\u001b[0m   original_function \u001b[38;5;241m=\u001b[39m signature_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m signature_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a TensorFlow function for which to generate a signature, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Only `tf.functions` with an input signature or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcrete functions can be used as a signature.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:43\u001b[0m, in \u001b[0;36m_get_signature\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_signature\u001b[39m(function):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(function, (defun\u001b[38;5;241m.\u001b[39mFunction, def_function\u001b[38;5;241m.\u001b[39mFunction)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     42\u001b[0m       function\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     function \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:484\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/__autograph_generated_filep9qead7n.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(output_tensors)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:740\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_61195/716860762.py\", line 15, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})['output'][0,:]\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ASLInferModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLInferModel, self).__init__()\n",
    "        \n",
    "        self.model = tf.saved_model.load(tf_mod_cnn_path)\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
    "    ])\n",
    "    def call(self, input):\n",
    "        output_tensors = {}\n",
    "        output_tensors['outputs'] = self.model(**{'input': input})['output'][0,:]\n",
    "        return output_tensors\n",
    "    \n",
    "    \n",
    "mytfmodel = ASLInferModel()\n",
    "tf.saved_model.save(mytfmodel, \n",
    "                    f'{BASE_DIR}/tf_infer_model', \n",
    "                    signatures={'serving_default': mytfmodel.call})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO TFLITE\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_mod_cnn_path) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "# Save the model.\n",
    "TF_MODEL_PATH_LITE = f\"{ARCHIVE_DIR}/models/model_cnn.tflite\"\n",
    "with open(TF_MODEL_PATH, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a443d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found_signatures\n",
      "serving_default\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid number of inputs provided for running a SignatureDef, expected 0 vs provided 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m vid \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m26\u001b[39m]\u001b[38;5;241m.\u001b[39mpath\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m load_relevant_data_subset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#interpreter.invoke()\u001b[39;00m\n\u001b[1;32m     20\u001b[0m sign \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py:230\u001b[0m, in \u001b[0;36mSignatureRunner.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"Runs the SignatureDef given the provided inputs in arguments.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m  Value is the result Tensor.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs):\n\u001b[0;32m--> 230\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid number of inputs provided for running a SignatureDef, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    232\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs provided \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs), \u001b[38;5;28mlen\u001b[39m(kwargs)))\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Resize input tensors\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_name, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid number of inputs provided for running a SignatureDef, expected 0 vs provided 1"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_PATH_LITE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "print(\"found_signatures\")\n",
    "print(found_signatures[0])\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))   ###CHANGE\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "\n",
    "vid = df.iloc[26].path\n",
    "x = load_relevant_data_subset(f\"{BASE_DIR}/{vid}\")\n",
    "output = prediction_fn(x)\n",
    "#interpreter.invoke()\n",
    "\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea5e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
