{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0957a17a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0957a17a",
    "outputId": "cf171b10-8ea4-47ee-d8bb-3235d9bc94a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5c251a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:00.056762Z",
     "iopub.status.busy": "2023-04-27T09:22:00.056345Z",
     "iopub.status.idle": "2023-04-27T09:22:01.788737Z",
     "shell.execute_reply": "2023-04-27T09:22:01.787457Z",
     "shell.execute_reply.started": "2023-04-27T09:22:00.056725Z"
    },
    "id": "ac5c251a",
    "outputId": "c121b11c-e8f2-49ec-d13b-c80668a65008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Jupiter  MacOS\n",
    "BASE_DIR = \"/Users/johnhanratty/ASLtest/asl-signs\"  #\"/Users/johnhanratty/ASLtest/asl-signs\"\n",
    "WORKING_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "ARCHIVE_DIR = \"/Users/johnhanratty/ASLtest\"\n",
    "MODEL_DIR = \"/Users/johnhanratty/ASLtest/models\"\n",
    "\n",
    "# !pip install nb_black --quiet\n",
    "# %load_ext lab_black\n",
    "\n",
    "# Colab\n",
    "# BASE_DIR = \"/content/asl-signs\"   #\"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
    "# WORKING_DIR = \"/content/asl-work\"\n",
    "# ARCHIVE_DIR = \"/content/drive/MyDrive/GaggleSignLang\"\n",
    "# MODEL_DIR = \"/content/drive/MyDrive/GaggleSignLang/models\"\n",
    "# !pip install nb_black --quiet\n",
    "# print('-----ok')\n",
    "# %load_ext nb_black\n",
    "\n",
    "# KAGGLE\n",
    "# BASE_DIR = \"/kaggle/input/asl-signs\"\n",
    "# WORKING_DIR = \"/kaggle/working\"\n",
    "# ARCHIVE_DIR = \"/kaggle/working\"\n",
    "# MODEL_DIR  = \"/kaggle/working\"\n",
    "# !pip install nb_black --quiet --root-user-action=ignore\n",
    "# %load_ext lab_black\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import seed, sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
    "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
    "\n",
    "FRAMES_OUT = 32 # 16\n",
    "PTS_IN_FRAME = 345\n",
    "DIMC = [0,1,2]\n",
    "DIMS = len(DIMC)\n",
    "WORKERS = 0   # dataoader work var  0 for MAC, 4 for online\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41802f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:06.975674Z",
     "iopub.status.busy": "2023-04-27T09:22:06.975115Z",
     "iopub.status.idle": "2023-04-27T09:22:06.982263Z",
     "shell.execute_reply": "2023-04-27T09:22:06.981046Z",
     "shell.execute_reply.started": "2023-04-27T09:22:06.975635Z"
    },
    "id": "a41802f3"
   },
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6048e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T09:22:24.657013Z",
     "iopub.status.busy": "2023-04-27T09:22:24.656552Z",
     "iopub.status.idle": "2023-04-27T09:22:24.672857Z",
     "shell.execute_reply": "2023-04-27T09:22:24.671586Z",
     "shell.execute_reply.started": "2023-04-27T09:22:24.656974Z"
    },
    "id": "a6048e13"
   },
   "outputs": [],
   "source": [
    "#FEATUREGEN MODEL\n",
    "ROWS_PER_FRAME = 543  # combined face, lefth, pose, righth\n",
    "\n",
    "# FILTER FEATURES IN EACH FRAME  - FACE, POSE & HANDs\n",
    "class FeatureGen(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # FILTER TO SPECIFIED FRAMES (FRAMES_OUT)\n",
    "        seed(24)\n",
    "        x = np.array(x)\n",
    "        n_frames = x.shape[0]\n",
    "        # Trim to # of frames to FRAMES_OUT\n",
    "        if n_frames > FRAMES_OUT:\n",
    "            idx = sorted((sample(range(0, n_frames), FRAMES_OUT)))\n",
    "            x=x[idx,:,:]\n",
    "        n_frames = x.shape[0]\n",
    "        \n",
    "        # FLATTENING ROWS BY TYPE and CONCATENATING TO ONE ROW PER FRAME 3D (XYZ)\n",
    "        # INPUT NUMPY, TORCH OUTPUT\n",
    "        # Grab data type (e.g. one point on hand) by selecting rows for each frame\n",
    "        # face_x = x[:,:468,:].contiguous().view(-1, 468*3)\n",
    "        lips_idx = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
    "        lips_x = x[:, lips_idx,:].reshape(-1, len(lips_idx)*3)\n",
    "        lefth_x = x[:,468:489,:].reshape(-1, 21*3)\n",
    "        pose_x = x[:,489:522,:].reshape(-1, 33*3)\n",
    "        righth_x = x[:,522:,:].reshape(-1, 21*3)\n",
    "\n",
    "        if np.isnan(lefth_x).sum() < np.isnan(righth_x).sum():\n",
    "            prime_x = lefth_x\n",
    "            second_x = righth_x\n",
    "        else:\n",
    "            prime_x = righth_x.reshape(righth_x.shape[0], -1, DIMS)\n",
    "            prime_x[:,:,0] = np.subtract(np.nanmax(prime_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                    prime_x[:, :, 0])\n",
    "            prime_x = prime_x.reshape(prime_x.shape[0],-1)\n",
    "            \n",
    "            second_x = lefth_x.reshape(lefth_x.shape[0], -1, DIMS)\n",
    "            second_x[:,:,0] = np.subtract(np.nanmax(second_x[:,:,0], axis=1).reshape(-1,1),\n",
    "                                          second_x[:, :, 0])\n",
    "            second_x = second_x.reshape(second_x.shape[0],-1)\n",
    "            \n",
    "        \n",
    "        # flatten types into one row per frame\n",
    "        xfeat = np.full([FRAMES_OUT, PTS_IN_FRAME], np.nan)\n",
    "        offset = (FRAMES_OUT - n_frames) // 2  # center frames in output data in each frame in video\n",
    "        xfeat[offset:n_frames+offset,:] = np.concatenate([lips_x, prime_x, pose_x, second_x], axis=1)  # concatenate types\n",
    "        \n",
    "        ############# \n",
    "        \n",
    "        def distDiff(ds, ref, pts):\n",
    "            ds = ds.reshape(ds.shape[0],  -1, DIMS)\n",
    "            d = np.hstack([np.nanmean(ds[:, pts, :], axis=0), \n",
    "                           np.nanmedian(ds[:, pts, :], axis=0), \n",
    "                           np.nanmax(ds[:, pts, :], axis=0), \n",
    "                           np.nanmin(ds[:, pts, :], axis=0),\n",
    "                           np.nanvar(ds[:, pts, :], axis=0)\n",
    "                           ]) \n",
    "            d = d.reshape(1, -1) \n",
    "            # NORMALIZE\n",
    "           # d = (d - np.nanmean(d, keepdims=True)) / np.nanstd(d, keepdims=True) # -1 to 1\n",
    "            d = np.nan_to_num(d, copy=False)  # replace NaN after normalization\n",
    "            return d\n",
    "        \n",
    "        d1 = distDiff(xfeat, 40, [40, 44, 48, 52, 56, 60, 43, 46, 50, 54, 58])\n",
    "        d2 = distDiff(xfeat, 40, [40,98, 102, 106, 110, 114, 97, 102, 106, 110, 114])\n",
    "        d3 = distDiff(xfeat, 60, [60, 73, 80, 81, 76, 77, 68, 69, 70, 71, 75, 74])\n",
    "        d4 = distDiff(xfeat, 5,  [5,0, 4, 8, 12, 16, 20, 24, 28, 32, 36])\n",
    "        \n",
    "        return np.concatenate([d1,d2,d3,d4], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1fee39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T10:13:04.044426Z",
     "iopub.status.busy": "2023-04-27T10:13:04.043547Z",
     "iopub.status.idle": "2023-04-27T10:16:04.541551Z",
     "shell.execute_reply": "2023-04-27T10:16:04.540255Z",
     "shell.execute_reply.started": "2023-04-27T10:13:04.044379Z"
    },
    "id": "dd1fee39",
    "outputId": "973058eb-4f61-4a6c-d891-310f25744dc7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert&Save (94477, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 94477/94477 [13:07<00:00, 119.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## PROCESS EACH ROW (ONE PARQUET PER ROW)\n",
    "def convert_row(row):\n",
    "    x = load_relevant_data_subset(os.path.join(BASE_DIR, row[1].path))\n",
    "    x = feature_converter(torch.tensor(x))\n",
    "    return x, row[1].label\n",
    "\n",
    "## LOOP THROUGH PARQUET FILES LISTED IN TRAIN FILE\n",
    "##  SAVE RESULTS \n",
    "def convert_and_save_data():\n",
    "    label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    \n",
    "    print(\"Convert&Save\", df.shape)\n",
    "    #### FOR TESTING #################\n",
    "    #df = df[0:20]\n",
    "    ##################################\n",
    "\n",
    "    npdata = np.zeros((df.shape[0], 675)) #615))  #150+150+165+150\n",
    "\n",
    "    nplabels = np.zeros(df.shape[0])\n",
    "    \n",
    "    results = map(convert_row, df.iterrows())\n",
    "    for i, (x,y) in tqdm(enumerate(results), total=df.shape[0]):\n",
    "            npdata[i,:] = x\n",
    "            nplabels[i] = y\n",
    "    return npdata, nplabels\n",
    " \n",
    "\n",
    "feature_converter = FeatureGen()\n",
    "datax, datay = convert_and_save_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1762d25f",
   "metadata": {
    "id": "1762d25f"
   },
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "np.save(f\"{ARCHIVE_DIR}/cnn_data{FRAMES_OUT}.npy\", datax)\n",
    "np.save(f\"{ARCHIVE_DIR}/cnn_labels.npy\", datay)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b5fbb8",
   "metadata": {
    "id": "e5b5fbb8"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "datax = np.load(f\"{ARCHIVE_DIR}/cnn_data{FRAMES_OUT}.npy\")\n",
    "datay = np.load(f\"{ARCHIVE_DIR}/cnn_labels.npy\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "704dc178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:34.423269Z",
     "iopub.status.busy": "2023-04-27T11:16:34.422846Z",
     "iopub.status.idle": "2023-04-27T11:16:34.445881Z",
     "shell.execute_reply": "2023-04-27T11:16:34.444872Z",
     "shell.execute_reply.started": "2023-04-27T11:16:34.423234Z"
    },
    "id": "704dc178"
   },
   "outputs": [],
   "source": [
    "#MODEL\n",
    "### NEW SEPARATED INPUTS\n",
    "class ASLData(Dataset):\n",
    "    def __init__(self,datax,datay):\n",
    "        self.datax = datax\n",
    "        self.datay = datay\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.datax[index, :], self.datay[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datay)\n",
    "\n",
    "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "class ASLModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(ASLModel, self).__init__()\n",
    "        \n",
    "        # DATA in [1, 615] per video  (or 675 = 165+165+180+165)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        L1OUT = 512  #1024 was ok\n",
    "        L2OUT = 512\n",
    "\n",
    "        self.layer_ph = nn.Linear(165, L1OUT)\n",
    "        self.batchnorm_ph = nn.BatchNorm1d(L1OUT)\n",
    "        \n",
    "        self.layer_sh = nn.Linear(165, L1OUT)\n",
    "        self.batchnorm_sh = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_po = nn.Linear(180, L1OUT)\n",
    "        self.batchnorm_po = nn.BatchNorm1d(L1OUT)\n",
    " \n",
    "        self.layer_li = nn.Linear(165, L1OUT)\n",
    "        self.batchnorm_li = nn.BatchNorm1d(L1OUT) \n",
    " \n",
    "        self.layer1 = nn.Linear(4*L1OUT, L2OUT)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(L2OUT)\n",
    "\n",
    "        self.layerFC = nn.Linear(L2OUT, 250)\n",
    "        self.softmax = nn.Softmax()\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        phand = x[:,0:165]    #x[:,0:150]            \n",
    "        shand = x[:,165:330]  #x[:,150:300]\n",
    "        pose =  x[:,330:510]  #x[:,300:465]\n",
    "        lips =  x[:,510:675]  \n",
    "        \n",
    "        ph = self.flatten(torch.tensor(phand).float()) \n",
    "        ph = self.layer_ph(ph)\n",
    "        ph = self.batchnorm_ph(ph)\n",
    "        ph = self.relu(ph)\n",
    "        ph = self.dropout(ph)\n",
    "\n",
    "        sh = self.flatten(torch.tensor(shand).float())       \n",
    "        sh = self.layer_sh(sh)\n",
    "        sh = self.batchnorm_sh(sh)\n",
    "        sh = self.relu(sh)\n",
    "        sh = self.dropout(sh)\n",
    "       \n",
    "        po = self.flatten(torch.tensor(pose).float())       \n",
    "        po = self.layer_po(po)\n",
    "        po = self.batchnorm_po(po)\n",
    "        po = self.relu(po)\n",
    "        po = self.dropout(po)\n",
    "        \n",
    "        li = self.flatten(torch.tensor(lips).float())       \n",
    "        li = self.layer_li(li)\n",
    "        li = self.batchnorm_li(li)\n",
    "        li = self.relu(li)\n",
    "        li = self.dropout(li)\n",
    "\n",
    "        x = torch.cat((ph.view(ph.size(0), -1),\n",
    "                       sh.view(sh.size(0), -1),\n",
    "                       po.view(po.size(0), -1),\n",
    "                       li.view(li.size(0), -1)), dim=1)\n",
    "        # x = self.batchnorm0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layerFC(x)\n",
    "       # x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f30afac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-04-27T11:16:40.228537Z",
     "iopub.status.busy": "2023-04-27T11:16:40.227418Z",
     "iopub.status.idle": "2023-04-27T11:17:22.481778Z",
     "shell.execute_reply": "2023-04-27T11:17:22.480359Z",
     "shell.execute_reply.started": "2023-04-27T11:16:40.228485Z"
    },
    "id": "8f30afac",
    "outputId": "d9d11c5e-ad68-400c-d07d-a7c9d6392b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++using CPU++++\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:0 > Train Loss: 3.4574, Train Acc: 0.2235\n",
      "Epoch:0 > Val Loss: 2.5592, Val Acc: 0.3931\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:1 > Train Loss: 2.3528, Train Acc: 0.4151\n",
      "Epoch:1 > Val Loss: 2.0498, Val Acc: 0.4896\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:2 > Train Loss: 2.0060, Train Acc: 0.4931\n",
      "Epoch:2 > Val Loss: 1.9175, Val Acc: 0.5199\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:3 > Train Loss: 1.7804, Train Acc: 0.5458\n",
      "Epoch:3 > Val Loss: 1.7576, Val Acc: 0.5562\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:4 > Train Loss: 1.6150, Train Acc: 0.5816\n",
      "Epoch:4 > Val Loss: 1.5693, Val Acc: 0.6088\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:5 > Train Loss: 1.4820, Train Acc: 0.6128\n",
      "Epoch:5 > Val Loss: 1.4261, Val Acc: 0.6503\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:6 > Train Loss: 1.3812, Train Acc: 0.6351\n",
      "Epoch:6 > Val Loss: 1.4392, Val Acc: 0.6480\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:7 > Train Loss: 1.2946, Train Acc: 0.6560\n",
      "Epoch:7 > Val Loss: 1.3822, Val Acc: 0.6607\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:8 > Train Loss: 1.2289, Train Acc: 0.6728\n",
      "Epoch:8 > Val Loss: 1.3308, Val Acc: 0.6733\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:9 > Train Loss: 1.1795, Train Acc: 0.6839\n",
      "Epoch:9 > Val Loss: 1.3241, Val Acc: 0.6761\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:10 > Train Loss: 1.1296, Train Acc: 0.6961\n",
      "Epoch:10 > Val Loss: 1.2856, Val Acc: 0.6854\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:11 > Train Loss: 1.0988, Train Acc: 0.7034\n",
      "Epoch:11 > Val Loss: 1.2733, Val Acc: 0.6907\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:12 > Train Loss: 1.0682, Train Acc: 0.7110\n",
      "Epoch:12 > Val Loss: 1.2657, Val Acc: 0.6930\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:13 > Train Loss: 1.0433, Train Acc: 0.7157\n",
      "Epoch:13 > Val Loss: 1.2627, Val Acc: 0.6943\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:14 > Train Loss: 1.0220, Train Acc: 0.7229\n",
      "Epoch:14 > Val Loss: 1.2469, Val Acc: 0.6985\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:15 > Train Loss: 1.0113, Train Acc: 0.7244\n",
      "Epoch:15 > Val Loss: 1.2405, Val Acc: 0.6998\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:16 > Train Loss: 0.9963, Train Acc: 0.7286\n",
      "Epoch:16 > Val Loss: 1.2441, Val Acc: 0.6991\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:17 > Train Loss: 0.9815, Train Acc: 0.7319\n",
      "Epoch:17 > Val Loss: 1.2420, Val Acc: 0.6999\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:18 > Train Loss: 0.9744, Train Acc: 0.7338\n",
      "Epoch:18 > Val Loss: 1.2389, Val Acc: 0.6990\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:19 > Train Loss: 0.9659, Train Acc: 0.7366\n",
      "Epoch:19 > Val Loss: 1.2336, Val Acc: 0.7044\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:20 > Train Loss: 0.9578, Train Acc: 0.7390\n",
      "Epoch:20 > Val Loss: 1.2357, Val Acc: 0.7025\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:21 > Train Loss: 0.9589, Train Acc: 0.7371\n",
      "Epoch:21 > Val Loss: 1.2312, Val Acc: 0.7049\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:22 > Train Loss: 0.9556, Train Acc: 0.7377\n",
      "Epoch:22 > Val Loss: 1.2339, Val Acc: 0.7025\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:23 > Train Loss: 0.9532, Train Acc: 0.7381\n",
      "Epoch:23 > Val Loss: 1.2323, Val Acc: 0.7033\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:24 > Train Loss: 0.9475, Train Acc: 0.7412\n",
      "Epoch:24 > Val Loss: 1.2301, Val Acc: 0.7027\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:25 > Train Loss: 0.9484, Train Acc: 0.7397\n",
      "Epoch:25 > Val Loss: 1.2326, Val Acc: 0.7039\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:26 > Train Loss: 0.9496, Train Acc: 0.7399\n",
      "Epoch:26 > Val Loss: 1.2269, Val Acc: 0.7033\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:27 > Train Loss: 0.9463, Train Acc: 0.7416\n",
      "Epoch:27 > Val Loss: 1.2313, Val Acc: 0.7027\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:28 > Train Loss: 0.9418, Train Acc: 0.7404\n",
      "Epoch:28 > Val Loss: 1.2298, Val Acc: 0.7048\n",
      "==================================================\n",
      "DIM=3 FRAMES=32, FEAT=345\n",
      "Epoch:29 > Train Loss: 0.9437, Train Acc: 0.7396\n",
      "Epoch:29 > Val Loss: 1.2299, Val Acc: 0.7043\n",
      "==================================================\n",
      "   truth  cnn\n",
      "0  206.0   78\n",
      "1   20.0   96\n",
      "2  178.0  199\n",
      "3  114.0  114\n",
      "4  221.0  221\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/GaggleSignLang/pred_cnn.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m pred_list[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prob_cnn, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_list\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/drive/MyDrive/GaggleSignLang/pred_cnn.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f1:\n\u001b[1;32m     83\u001b[0m        pickle\u001b[38;5;241m.\u001b[39mdump(pred_cnn, f1)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/GaggleSignLang/prob_cnn.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f1:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/GaggleSignLang/pred_cnn.pkl'"
     ]
    }
   ],
   "source": [
    "## MULTI TRAINING\n",
    "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"++++using GPU++++\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"++++using CPU++++\")\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
    "#datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
    "\n",
    "# init list for saving predictions for ensemble processing\n",
    "pred_list = pd.DataFrame(testy, columns=[\"truth\"])\n",
    "\n",
    "train_data = ASLData(trainx, trainy)\n",
    "valid_data = ASLData(testx, testy)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=True)\n",
    "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=WORKERS, shuffle=False)\n",
    "model = ASLModel(0.2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_sum = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_bar = train_loader\n",
    "    for x,y in train_bar:\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device) \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_sum += loss.item()\n",
    "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "        train_total += 1\n",
    "        sched.step()\n",
    "        \n",
    "    val_loss_sum = 0.\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    for x,y in val_loader:\n",
    "        x = torch.Tensor(x).float().to(device)\n",
    "        y = torch.Tensor(y).long().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            val_loss_sum += loss.item()\n",
    "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
    "            val_total += 1\n",
    "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
    "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
    "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Save the pytorch model\n",
    "PATH = f\"{ARCHIVE_DIR}/models/model_ccn{FRAMES_OUT}.sd\"\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "PATH = f\"{ARCHIVE_DIR}/models/model_ccn{FRAMES_OUT}.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n",
    "# Save Pred and Perf\n",
    "x = testx.detach().numpy()\n",
    "prob_cnn = model(torch.tensor(x)).detach().numpy()\n",
    "\n",
    "pred_list['cnn'] = np.argmax(prob_cnn, axis=1)\n",
    "print(pred_list.head())\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/GaggleSignLang/pred_cnn{FRAMES_OUT}.pkl\", 'wb') as f1:\n",
    "       pickle.dump(pred_list, f1)\n",
    "with open(f\"/content/drive/MyDrive/GaggleSignLang/prob_cnn{FRAMES_OUT}.pkl\", 'wb') as f1:\n",
    "       pickle.dump(prob_cnn, f1)\n",
    "print(prob_cnn.shape)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", np.mean(pred_list.truth == pred_list.cnn))\n",
    "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdace4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Inference with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sfQhGxbg-lNL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfQhGxbg-lNL",
    "outputId": "d91bb0c5-8046-4694-9ad2-b8f3fd00acd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   truth  predc  cnn\n",
      "0  206.0     78   78\n",
      "1   20.0     96   96\n",
      "2  178.0    178  178\n",
      "3  114.0    114  114\n",
      "4  221.0    221  221\n",
      "(14172, 250)\n",
      "Accuracy: 0.6898814563928873\n"
     ]
    }
   ],
   "source": [
    "x = testx.detach().numpy()\n",
    "prob_cnn = model(torch.tensor(x)).detach().numpy()\n",
    "\n",
    "pred_list['cnn'] = np.argmax(prob_cnn, axis=1)\n",
    "print(pred_list.head())\n",
    "\n",
    "with open(f\"/content/drive/MyDrive/GaggleSignLang/pred_cnn.pkl\", 'wb') as f1:\n",
    "       pickle.dump(pred_list, f1)\n",
    "with open(f\"/content/drive/MyDrive/GaggleSignLang/prob_cnn.pkl\", 'wb') as f1:\n",
    "       pickle.dump(prob_cnn, f1)\n",
    "print(prob_cnn.shape)\n",
    "print(\"Accuracy:\", np.mean(pred_list.truth == pred_list.cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49046438",
   "metadata": {
    "id": "49046438"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ========Full Data - no add Norm, Centered ========\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:38 > Train Loss: 0.9867, Train Acc: 0.7321\n",
    "# Epoch:38 > Val Loss: 1.2608, Val Acc: 0.6988\n",
    "# ==================================================\n",
    "\n",
    "# ========Full Data - no additional Normalizeation/Centering=====================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.4974, Train Acc: 0.6059\n",
    "# Epoch:39 > Val Loss: 1.7298, Val Acc: 0.5839\n",
    "# ==================================================\n",
    "\n",
    "# =====Full no reverse, centered =============================================\n",
    "# DIM=3 FRAMES=32, FEAT=345\n",
    "# Epoch:39 > Train Loss: 1.2104, Train Acc: 0.6745\n",
    "# Epoch:39 > Val Loss: 1.4204, Val Acc: 0.6515\n",
    "# ==================================================\n",
    "# Additional Normalize and Nan Step  0.6100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee18c7f",
   "metadata": {
    "id": "fee18c7f"
   },
   "source": [
    "# Torch Single Model Save, Retrieve and Rum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e89433",
   "metadata": {
    "id": "53e89433"
   },
   "outputs": [],
   "source": [
    "## SAVE MODEL\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/mod_ccn{FRAMES_OUT}.pt\"\n",
    "torch.save(model, PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a73ce",
   "metadata": {
    "id": "817a73ce"
   },
   "outputs": [],
   "source": [
    "##LOAD MODEL\n",
    "\n",
    "PATH = f\"{MODEL_DIR}/mod_ccn{FRAMES_OUT}.pt\"\n",
    "mod = torch.load(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9f70a",
   "metadata": {
    "id": "3cd9f70a",
    "outputId": "ee501908-0861-45f9-9879-025eee88f130"
   },
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.AModel'>: it's not the same object as __main__.AModel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m mod_cnn \u001b[38;5;241m=\u001b[39m AModel()\n\u001b[1;32m     16\u001b[0m mod_cnn_pt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/modelcnn\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFRAMES_OUT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_cnn_pt_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:653\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    651\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    652\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 653\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    655\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.AModel'>: it's not the same object as __main__.AModel"
     ]
    }
   ],
   "source": [
    "# SAVE PYTORCH MODELS\n",
    "class AModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AModel, self).__init__()\n",
    "        \n",
    "        self.InputFormat = FeatureGen() #feature_converter\n",
    "        self.InferModel = mod\n",
    "        self.InferModel.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.InputFormat(x)\n",
    "        pred = self.InferModel(x)\n",
    "        return pred\n",
    "\n",
    "mod_cnn = AModel()\n",
    "mod_cnn_pt_path = f\"{MODEL_DIR}/modelcnn{FRAMES_OUT}test.pt\"\n",
    "torch.save(mod_cnn, mod_cnn_pt_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e7ee5",
   "metadata": {
    "id": "885e7ee5",
    "outputId": "221e4d2a-98cf-421d-d9a6-16d3b1ed3194"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed locating file data.pkl: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msign\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(label_map)\n\u001b[1;32m      6\u001b[0m mod_cnn_pt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/modelcnn\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFRAMES_OUT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mtest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m Infmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_cnn_pt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m d \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m2022\u001b[39m:\u001b[38;5;241m2023\u001b[39m]\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m load_relevant_data_subset(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py:1168\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m data_file \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_file\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed locating file data.pkl: file not found"
     ]
    }
   ],
   "source": [
    "# Run merged PyTorch Model\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "\n",
    "mod_cnn_pt_path = f\"{MODEL_DIR}/modelcnn{FRAMES_OUT}test.pt\"\n",
    "Infmodel = torch.load(mod_cnn_pt_path)\n",
    "\n",
    "d = df[2022:2023]\n",
    "\n",
    "x = load_relevant_data_subset(os.path.join(BASE_DIR, d['path'].item()))\n",
    "pred = Infmodel(x)\n",
    "\n",
    "print(\"truth:\", d.label, d.sign, \"prediction=\", np.argmax(pred.detach().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b3a32",
   "metadata": {
    "id": "557b3a32"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80cdfa49",
   "metadata": {
    "id": "80cdfa49"
   },
   "source": [
    "# TFLITE CONVERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a4e72f",
   "metadata": {
    "id": "68a4e72f"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --quiet --root-user-action=ignore\n",
    "!pip install tensorflow_probability --quiet --root-user-action=ignore\n",
    "\n",
    "!pip install onnx-tf --quiet --root-user-action=ignore\n",
    "!pip install tflite-runtime  --quiet --root-user-action=ignore\n",
    "import onnx_tf\n",
    "import tflite_runtime\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55d70d18",
   "metadata": {
    "id": "55d70d18",
    "outputId": "1628ca76-f9f6-42fb-ad98-81b59429ea4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{MODEL_DIR}/tf_mod_cnn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: f\"{MODEL_DIR}/tf_mod_cnn/assets\n"
     ]
    }
   ],
   "source": [
    "## CNN MODEL CONVERSION\n",
    "# pmodel_path = f\"{ARCHIVE_DIR}/models/modelccn16flat.sd\"\n",
    "# modelc = ASLModel(.1)\n",
    "# modelc.load_state_dict(torch.load(py_model_path))\n",
    "# modelc.eval()\n",
    "\n",
    "mod_cnn_pt_path = f\"{MODEL_DIR}/modelcnn{FRAMES_OUT}test.pt\"\n",
    "mod = torch.load(mod_cnn_pt_path)\n",
    "\n",
    "sample_input = torch.rand((50, 543, 3))\n",
    "onnx_mod_cnn_path = f\"{MODEL_DIR}/model_cnn.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    mod,                    # PyTorch Model\n",
    "    sample_input,             # Input tensor\n",
    "    onnx_mod_cnn_path,        # Output file (eg. 'output_model.onnx')\n",
    "    opset_version=12,         # Operator support version\n",
    "    input_names=['input'],     # Input tensor name (arbitary)\n",
    "    output_names=['output'], # Output tensor name (arbitary)\n",
    "    dynamic_axes={'input' : {0: 'input'}\n",
    "    }\n",
    ")\n",
    "onnx_mod_cnn_gen = onnx.load(onnx_mod_cnn_path)\n",
    "tf_rep = prepare(onnx_mod_cnn_gen)\n",
    "\n",
    "tf_mod_cnn_path = 'f\"{MODEL_DIR}/tf_mod_cnn'\n",
    "tf_rep.export_graph(tf_mod_cnn_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b39bc",
   "metadata": {
    "id": "683b39bc"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, save_model_path) # save as savemodel form\n",
    "test_model = tf.keras.models.load_model(save_model_path, custom_objects={\"TFBertModel\": transformers.TFBertModel}) # load model and point out the custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016b362",
   "metadata": {
    "id": "1016b362",
    "outputId": "be329db8-05c0-42b8-e20e-745b64f9f954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "INSIDE \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_82561/3126969839.py\", line 17, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m mytfmodel \u001b[38;5;241m=\u001b[39m ASLInferModel()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mMODEL_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tf_infer_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmytfmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1240\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1240\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py:1402\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mfind_function_to_export(\n\u001b[1;32m   1399\u001b[0m       augmented_graph_view)\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n\u001b[1;32m   1404\u001b[0m signature_map \u001b[38;5;241m=\u001b[39m signature_serialization\u001b[38;5;241m.\u001b[39mcreate_signature_map(signatures)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:131\u001b[0m, in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    129\u001b[0m wrapped_functions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m signature_key, function \u001b[38;5;129;01min\u001b[39;00m signatures\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 131\u001b[0m   original_function \u001b[38;5;241m=\u001b[39m signature_function \u001b[38;5;241m=\u001b[39m \u001b[43m_get_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m signature_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a TensorFlow function for which to generate a signature, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Only `tf.functions` with an input signature or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcrete functions can be used as a signature.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py:43\u001b[0m, in \u001b[0;36m_get_signature\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_signature\u001b[39m(function):\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(function, (defun\u001b[38;5;241m.\u001b[39mFunction, def_function\u001b[38;5;241m.\u001b[39mFunction)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     42\u001b[0m       function\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     function \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(function, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1238\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1236\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1237\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1242\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1243\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    768\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 171\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:484\u001b[0m, in \u001b[0;36mclass_method_to_instance_method.<locals>.bound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_fn(weak_instance(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# However, the replacer is still responsible for attaching self properly.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Is it possible to do it here instead?\u001b[39;00m\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1189\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/__autograph_generated_filefga8zaue.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     11\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINSIDE \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(output_tensors)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/load.py:740\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/p5/bqxhgw2x5bgfr_7ndb9qv2z00000gn/T/ipykernel_82561/3126969839.py\", line 17, in call  *\n        output_tensors['outputs'] = self.model(**{'input': input})\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {'input': <tf.Tensor 'input:0' shape=(None, 543, 3) dtype=float32>}\n    \n     Expected these arguments to match one of the following 1 option(s):\n    \n    Option 1:\n      Positional arguments (0 total):\n        * \n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class ASLInferModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(ASLInferModel, self).__init__()\n",
    "        tf_mod_cnn_path = 'f\"{MODEL_DIR}/tf_mod_cnn'\n",
    "\n",
    "        self.model = tf.saved_model.load(tf_mod_cnn_path)\n",
    "        self.model.trainable = False\n",
    "    \n",
    "    @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None, 543, 3], dtype=tf.float32, name='inputs')\n",
    "    ])\n",
    "    def call(self, input):\n",
    "        output_tensors = {}\n",
    "        print(\"INSIDE \")\n",
    "        output_tensors['outputs'] = self.model(**{'input': input})\n",
    "        print(\"2\")\n",
    "        return output_tensors\n",
    "    \n",
    "    \n",
    "mytfmodel = ASLInferModel()\n",
    "print(\"ok\")\n",
    "tf.saved_model.save(mytfmodel, \n",
    "                    f'{MODEL_DIR}/tf_infer_model', \n",
    "                    signatures={'serving_default': mytfmodel.call})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b09b72",
   "metadata": {
    "id": "e8b09b72"
   },
   "outputs": [],
   "source": [
    "# CONVERT MODEL TO TFLITE\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(tf_mod_cnn_path) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "# Save the model.\n",
    "TF_MODEL_PATH_LITE = f\"{MODEL_DIR}/model_cnn.tflite\"\n",
    "with open(TF_MODEL_PATH, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623c34a",
   "metadata": {
    "id": "2623c34a"
   },
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_PATH_LITE)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "print(\"found_signatures\")\n",
    "print(found_signatures[0])\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "\n",
    "label_map = json.load(open(f\"{BASE_DIR}/sign_to_prediction_index_map.json\", \"r\"))   ###CHANGE\n",
    "df = pd.read_csv(TRAIN_FILE)\n",
    "df['label'] = df['sign'].map(label_map)\n",
    "\n",
    "vid = df.iloc[26].path\n",
    "x = load_relevant_data_subset(f\"{BASE_DIR}/{vid}\")\n",
    "output = prediction_fn(x)\n",
    "#interpreter.invoke()\n",
    "\n",
    "sign = np.argmax(output[\"outputs\"])\n",
    "\n",
    "print(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b83bf",
   "metadata": {
    "id": "331b83bf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
