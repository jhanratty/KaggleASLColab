{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NOTES\n",
        "- PCA Doesn't help much\n",
        "        multipath, no_poly, no PCA     \n",
        "- Mult-path worth .02\n",
        "        - single path/no_poly/PCA_all  0.7176\n",
        "        - multi path / no_poly/PCA_all 0.7368\n",
        "- POLYGONS don't seem to help  - same performance\n",
        "        -multi path /poly / PCA_all \n"
      ],
      "metadata": {
        "id": "a27R0vE7DNpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mediapipe Specs\n",
        "https://google.github.io/mediapipe/solutions/pose.html \n",
        "\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=download&id=1nSdlOv09Isye_wtDIfHQlrJbhPqWhx3M\" width=\"400\">\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=download&id=1nW9OZDMGXQEv_KHRPJ5SveOjLP0O_CfA\" width=\"400\">\n",
        "\n",
        "\n",
        "\n",
        "Face\n",
        "https://github.com/google/mediapipe/blob/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png \n"
      ],
      "metadata": {
        "id": "9ZedVyPyRP8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hhTKwwaiev4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr45cYjhsA6K",
        "outputId": "e99ac636-3503-45e0-a2e9-93b7100ac859"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jupiter  MacOS\n",
        "# BASE_DIR = \"/Users/johnhanratty/Library/CloudStorage/OneDrive-Personal/IRMA_GIT/Kaggle_SignLanguage/asl-signs\"\n",
        "# WORKING_DIR = BASE_DIR\n",
        "# !pip install nb_black --quiet\n",
        "# %load_ext lab_black\n",
        "\n",
        "# Colab\n",
        "BASE_DIR = \"/content/asl-signs\"   #\"/content/drive/MyDrive/GaggleSignLang/asl-signs\"\n",
        "WORKING_DIR = \"/content/asl-work\"\n",
        "# !pip install nb_black --quiet\n",
        "# print('-----ok')\n",
        "# %load_ext nb_black\n",
        "\n",
        "# KAGGLE\n",
        "# BASE_DIR = \"/kaggle/input/asl-signs\"\n",
        "# WORKING_DIR = \"/kaggle/working/\"\n",
        "# !pip install nb_black --quiet --root-user-action=ignore\n",
        "# %load_ext lab_black\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "LANDMARK_FILES_DIR = f'{BASE_DIR}/train_landmark_files'\n",
        "TRAIN_FILE = f\"{BASE_DIR}/train.csv\"\n",
        "\n",
        "FRAMES_OUT = 24 # 16\n",
        "PTS_IN_FRAME = 115\n",
        "DIMC = [0,1,2]\n",
        "DIMS = len(DIMC)\n",
        "\n",
        "  \n",
        "HANDIDX = {\"WRIST\":0, \"THUMB_CMC\":1, \"THUMB_MCP\":2,     \"THUMB_IP\":3,          \"THUMB_TIP\":4,\n",
        "        \"INDEX_FINGER_MCP\":5, \"INDEX_FINGER_PIP\":6,  \"INDEX_FINGER_DIP\":7,  \"INDEX_FINGER_TIP\":8,\n",
        "        \"MIDDLE_FINGER_MCP\":9,\"MIDDLE_FINGER_PIP\":10,\"MIDDLE_FINGER_DIP\":11,\"MIDDLE_FINGER_TIP\":12,\n",
        "        \"RING_FINGER_MCP\":13, \"RING_FINGER_PIP\":14,  \"RING_FINGER_DIP\":15,  \"RING_FINGER_TIP\":16,\n",
        "        \"PINKY_FINGER_MCP\":17,\"PINKY_FINGER_PIP\":18,  \"PINKY_FINGER_DIP\":19,\"PINKY_FINGER_TIP\":20}\n",
        "\n",
        "POSEIDX = {\"NOSE\":0,        \"LEFT_EYE_INNER\":1,\"LEFT_EYE\":2,   \"LEFT_EYE_OUTER\":3, \"RIGHT_EYE_INNER\":4, \"RIGHT_EYE\":5,      \"RIGHT_EYE_OUTER\":6,\n",
        "        \"LEFT_EAR\":7,    \"RIGHT_EAR\":8,     \"MOUTH_LEFT\":9, \"MOUTH_RIGHT\":10,   \"LEFT_SHOULDER\":11,  \"RIGHT_SHOULDER\":12,\n",
        "        \"LEFT_ELBOW\":13, \"RIGHT_ELBOW\":14,  \"LEFT_WRIST\":15, \"RIGHT_WRIST\":16, \n",
        "        \"LEFT_PINKY\":17, \"RIGHT_PINKY\":18,  \"LEFT_INDEX\":19,\"RIGHT_INDEX\":20,   \"RIGHT_THUMB\":21,    \"LEFT_THUMB\":22,\n",
        "        \"LEFT_HIP\":23,   \"RIGHT_HIP\":24,    \"LEFT_KNEE\":25, \"RIGHT_KNEE\":26,    \"LEFT_ANKLE\":27,     \"RIGHT_ANKLE\":28,\n",
        "        \"LEFT_HEEL\":29,  \"RIGHT_HEEL\":30,   \"LEFT_FOOT_INDEX\":31, \"RIGHT_FOOT_INDEX\":32}\n",
        "\n",
        "LIPSIDX = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 95, 88, 178, 87, 14, 317, 402, 318, 324, 146, 91, 181, 84, 17, 314, 405, 321, 375]\n",
        "LIPSIDX_sm = [185, 39, 0,  269,  409,  78,  80,  82,  312,  310,  308,  88,  87,  317,  318,  146,  181,  17,  405, 375]\n",
        "\n",
        "\n",
        "# need to rerun parquet processing to grab data points\n",
        "#LIPSIDX1 = [12, 268,271,272,407, 293, 325,319,403,316,15,86,179,89,96,62, 183,42,41,38]\n",
        "\n",
        "METALEN = len(LIPSIDX) + len(POSEIDX) + 2 * len(HANDIDX)\n",
        "\n",
        "def PRIM_HAND(idx): return(40 + HANDIDX[idx])\n",
        "def POSE(idx):  return(40 + 21 + POSEIDX[idx])\n",
        "def SEC_HAND(idx):  return(40 + 21 + 33 + HANDIDX[idx])\n",
        "\n",
        "print(POSE(\"NOSE\"))\n",
        "print(SEC_HAND(\"WRIST\"))\n",
        "METALEN\n",
        "\n",
        "print('done')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-15T22:04:26.371365Z",
          "iopub.execute_input": "2023-03-15T22:04:26.372355Z",
          "iopub.status.idle": "2023-03-15T22:04:36.169556Z",
          "shell.execute_reply.started": "2023-03-15T22:04:26.372296Z",
          "shell.execute_reply": "2023-03-15T22:04:36.168229Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3XL8evoqZP4",
        "outputId": "80985d00-a3cc-45dc-aaae-0b75699181ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n",
            "94\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GET FEATURE FILES FROM GDRIVE \n",
        "# COLAB ONLY - MOVE FEATURE FILES TO WORKING DIRECTORY\n",
        "# \n",
        "import os\n",
        "import gc\n",
        "import shutil\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\") and not os.path.exists(WORKING_DIR):\n",
        "  !mkdir '/content/asl-work'\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_data{FRAMES_OUT}.npy\", f\"{WORKING_DIR}\")\n",
        "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/feature_labels.npy\", f\"{WORKING_DIR}\")\n",
        "    shutil.copy(f\"/content/drive/MyDrive/GaggleSignLang/sign_to_prediction_index_map.json\", f\"{WORKING_DIR}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LYN0XSNKXd0d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPOCESS-A  - FRAMES OUTPUT\n",
        "import psutil\n",
        "\n",
        "def preProc():\n",
        "  dx = np.load(f\"{WORKING_DIR}/feature_data{FRAMES_OUT}.npy\")\n",
        "  datay = np.load(f\"{WORKING_DIR}/feature_labels.npy\") \n",
        "\n",
        "  data_rows = dx.shape[0]\n",
        "\n",
        "  print(\"DX BASE\", dx.base)   #BASE1 ROOT READ FROM FILE\n",
        "  print(\"dx shape\", dx.shape)\n",
        "  # MAKE COPY OF DX1 input from file\n",
        "  dx = dx.reshape((data_rows, FRAMES_OUT, -1, 3))  # BASE 1\n",
        "  print(\"DX BASE\", dx.base[0,0,0]) \n",
        "\n",
        "  # DEFINE VIEW MATRICES \n",
        "  start_lips =  0\n",
        "  start_left =  PRIM_HAND(\"WRIST\")\n",
        "  start_pose =  POSE(\"NOSE\")\n",
        "  start_right = SEC_HAND(\"WRIST\")\n",
        "  end_right =   METALEN\n",
        "\n",
        "  lips_3d =   dx[:, :, 0:PRIM_HAND(\"WRIST\"), :]\n",
        "  lefth_3d =  dx[:, :, PRIM_HAND(\"WRIST\"):POSE(\"NOSE\"), :]\n",
        "  pose_3d =   dx[:, :, POSE(\"NOSE\"):SEC_HAND(\"WRIST\"),:]\n",
        "  righth_3d = dx[:, :, SEC_HAND(\"WRIST\"):METALEN, :]   # BASE1\n",
        "  print(\"BASE RIGHT\", righth_3d.base[0,0,0])\n",
        "\n",
        "  # Combind Componets to dx\n",
        "  dx=np.concatenate((lips_3d, lefth_3d, pose_3d, righth_3d), axis=2)  ## COPY\n",
        "  print(\"CONCATX BASE\", dx.base)  # BASE2 ROOT\n",
        "  \n",
        "  split_bar = '='*20\n",
        "  memory_info = psutil.virtual_memory()._asdict()\n",
        "  print(f\"{split_bar} Memory Usage {split_bar}\")\n",
        "  for k,v in memory_info.items():\n",
        "    print(k, v)\n",
        "\n",
        "  MIRROR = True\n",
        "  if MIRROR: \n",
        "      # Mirror data on x-axis (max-value)\n",
        "      lips_m = lips_3d\n",
        "      lips_m[:,:,:,0] = np.nanmax(lips_3d[:,:,:,0]) - lips_3d[:,:,:,0]\n",
        "      left_m = lefth_3d\n",
        "      left_m[:,:,:,0] = np.nanmax(lefth_3d[:,:,:,0]) - lefth_3d[:,:,:,0]\n",
        "      pose_m = pose_3d\n",
        "      pose_m[:,:,:,0] = np.nanmax(pose_3d[:,:,:,0]) - pose_3d[:,:,:,0]\n",
        "      right_m = righth_3d\n",
        "      print(\"RIGHT_M BASE1\", right_m.base[0,0,0])\n",
        "      right_m[:,:,:,0] = np.nanmax(righth_3d[:,:,:,0]) - righth_3d[:,:,:,0]\n",
        "      print(\"RIGHT_M BASE2\", right_m.base[0,0,0])\n",
        "\n",
        "      # NOTE: reversed and swapped position of left_m and right_m \n",
        "      # so last slot is primary hand\n",
        "      datam = np.concatenate((lips_m, right_m, pose_m, left_m), axis=2)\n",
        "      print(\"DATAM\", datam.shape)\n",
        "\n",
        "      # find primary hand (Count NaNs)\n",
        "      #  -check whether lefth_3d OR righth_3d has more NaNs\n",
        "      cl = lefth_3d.reshape(lefth_3d.shape[0],-1)\n",
        "      cr = righth_3d.reshape(lefth_3d.shape[0],-1)\n",
        "      cc = np.isnan(cl).sum(axis=1) > np.isnan(cr).sum(axis=1)\n",
        "      dx[cc,:,:,:] = datam[cc,:,:,:]  # replace \n",
        "\n",
        "  memory_info = psutil.virtual_memory()._asdict()\n",
        "  print(f\"{split_bar} Memory Usage {split_bar}\")\n",
        "  for k,v in memory_info.items():\n",
        "    print(k, v)\n",
        "\n",
        "  # REPLACE NaNs\n",
        "  print('DX NANS FOR REPLACEMENT', np.isnan(dx).sum())\n",
        "  #dx = np.nan_to_num(dx, copy=False)\n",
        "\n",
        "  # SET 3D or 2D (SELECT dim columns)\n",
        "  print(dx.shape)\n",
        "  if DIMS !=3:\n",
        "    dx = datax[:,:,:,DIMC]\n",
        "\n",
        "  print(\"FINAL SHAPE\")\n",
        "  print(\"dx\", dx.shape)\n",
        "  print(\"datay\", datay.shape)\n",
        "  return(dx, datay)\n",
        "\n",
        "# FINAL SHAPE separate line for seq and feature\n",
        "\n",
        "datax, datay = preProc()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNWN8LmKx_gw",
        "outputId": "985e9efe-fb50-407a-fa40-b20b881eb303"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DX BASE None\n",
            "dx shape (94477, 24, 345)\n",
            "DX BASE 0.4689520001411438\n",
            "BASE RIGHT 0.4689520001411438\n",
            "CONCATX BASE None\n",
            "==================== Memory Usage ====================\n",
            "total 27331178496\n",
            "available 12545323008\n",
            "percent 54.1\n",
            "used 14373883904\n",
            "free 440602624\n",
            "active 2662277120\n",
            "inactive 23638167552\n",
            "buffers 291819520\n",
            "cached 12224872448\n",
            "shared 3534848\n",
            "slab 427745280\n",
            "RIGHT_M BASE1 0.5005468130111694\n",
            "RIGHT_M BASE2 0.5005468130111694\n",
            "DATAM (94477, 24, 115, 3)\n",
            "==================== Memory Usage ====================\n",
            "total 27331178496\n",
            "available 4798177280\n",
            "percent 82.4\n",
            "used 22150004736\n",
            "free 4493627392\n",
            "active 317739008\n",
            "inactive 22229389312\n",
            "buffers 75780096\n",
            "cached 611766272\n",
            "shared 3567616\n",
            "slab 139628544\n",
            "DX NANS FOR REPLACEMENT 349448745\n",
            "(94477, 24, 115, 3)\n",
            "FINAL SHAPE\n",
            "dx (94477, 24, 115, 3)\n",
            "datay (94477,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CAN SKIP and load dpoly in next cell\n",
        "### Build Primary Hand Polygons and save to pickle file\n",
        "\n",
        "\n",
        "!pip install pyny3d --quiet\n",
        "\n",
        "#Calculate area\n",
        "import pyny3d.geoms as pyny\n",
        "import pickle\n",
        "\n",
        "datax1 = datax\n",
        "print(datax1.shape)\n",
        "def fun(x,):\n",
        "    x = x.reshape(-1,3)\n",
        "    x = x[~np.isnan(x).any(axis=1), :]\n",
        "    if x.shape[0] <3:\n",
        "        return np.nan\n",
        "    poly = pyny.Polygon(x)\n",
        "  \n",
        "    #RETURNS value {arez, [a,b,c,d]} where a*x + b*y + c*z = 0\n",
        "    a,b,c,d = poly.get_parametric()\n",
        "    return poly.get_area(), a,b,c,d\n",
        "\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "hlist = [[\"WRIST\", \"INDEX_FINGER_MCP\", \"PINKY_FINGER_MCP\"],\n",
        "         [\"WRIST\", \"MIDDLE_FINGER_TIP\", \"INDEX_FINGER_TIP\"],\n",
        "         [\"WRIST\", \"THUMB_TIP\", \"PINKY_FINGER_TIP\"]]\n",
        "#[[\"INDEX_FINGER_MCP\", \"THUMB_TIP\", \"INDEX_FINGER_PIP\"],\n",
        "#         [\"INDEX_FINGER_MCP\", \"MIDDLE_FINGER_TIP\", \"INDEX_FINGER_TIP\"],\n",
        "#         [\"WRIST\", \"INDEX_FINGER_TIP\", \"PINKY_FINGER_TIP\"]]\n",
        "\n",
        "area_out = np.zeros([datax1.shape[0]*datax1.shape[1], 5*len(hlist)], dtype=float)\n",
        "\n",
        "for i,d in enumerate(hlist):\n",
        "  print(\"##### PRIM_HAND\", i)\n",
        "  pts = [PRIM_HAND(d[0]), PRIM_HAND(d[1]), PRIM_HAND(d[2])]\n",
        "  print(pts)\n",
        "  dd = datax1[:,:, pts, :]\n",
        "  \n",
        "  ar  = np.apply_along_axis(fun, 1, dd.reshape(dd.shape[0]*dd.shape[1], -1)) \n",
        "  area_out[:,5*i:5*i+5] = ar #get area for each {frame}\n",
        "\n",
        "  print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
        "\n",
        "with open(f\"/content/drive/MyDrive/GaggleSignLang/area_out3.pkl\", 'wb') as handle:\n",
        "  pickle.dump(area_out, handle)\n",
        "print(\"DONE\")\n",
        "print(area_out.shape)\n",
        "print(area_out)\n",
        "\n",
        "print(\"#### FINAL TIME:\", time.perf_counter()-start_time)\n"
      ],
      "metadata": {
        "id": "aq8IKei0WWPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## RETRIEVE PRIMARY HAND POLGONS AND AGGREGATE\n",
        "import pickle\n",
        "\n",
        "with open(f\"/content/drive/MyDrive/GaggleSignLang/area_out3.pkl\", 'rb') as handle:\n",
        "       area_out = pickle.load(handle)\n",
        "\n",
        "\n",
        "area_out = area_out.reshape(datax.shape[0],datax.shape[1],-1)\n",
        "print(\"AREA_OUT\", area_out.shape)\n",
        "dpoly =  np.hstack([np.nanmean(area_out[:,:,:], axis=1), \n",
        "                    np.nanmedian(area_out[:,:,:], axis=1), \n",
        "                    np.nanmax(area_out[:,:,:], axis=1), \n",
        "                    np.nanmin(area_out[:,:,:], axis=1),\n",
        "                    np.nanvar(area_out[:,:,:], axis=1)\n",
        "                    ])\n",
        "dpoly = np.expand_dims(dpoly, axis=1)\n",
        "dpoly = np.nan_to_num(dpoly, copy=False)\n",
        "print(\"DPOLY\", dpoly.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbYmpXStkByd",
        "outputId": "f789ab1f-3dd7-4cd9-93d8-0e0445265f3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AREA_OUT (94477, 24, 20)\n",
            "DPOLY (94477, 1, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## AGGREGATE POINTWISE DATA HANDS, POSE, LIPS\n",
        "\n",
        "def distDiff(ds, ref, pts, use_ref=99):\n",
        "    if type(pts) is not list:\n",
        "      print(\"###ERROR: must pts must be a list, call with brackets '[pts]'\")\n",
        " \n",
        "    if use_ref==0:  # Diff from frame to frame (Out: [:,FRAMESOUT - 1,:,:)      \n",
        "        d = ds[:,1:, pts, :]  - ds[:,:-1, pts, :]\n",
        "\n",
        "    elif use_ref == 1:  # sumarize frame \n",
        "        #d1 = ds[:,:, pts, :].mean(axis=1)\n",
        "        #print(\"DD\", np.sum( np.linalg.norm(ds[:,1:, pts, :] - ds[:,:-1, pts, :], axis=3), axis=1).shape)\n",
        "        #print(\"D1\", np.nanmax(ds[:,:, pts, :], axis=1).shape)\n",
        "        d = np.hstack([np.nanmean(ds[:,:, pts, :], axis=1), \n",
        "                       np.nanmedian(ds[:,:, pts, :], axis=1), \n",
        "                       np.nanmax(ds[:,:, pts, :], axis=1), \n",
        "                       np.nanmin(ds[:,:, pts, :], axis=1),\n",
        "                       np.nanvar(ds[:,:, pts, :], axis=1)\n",
        "                       ]) \n",
        "        print('D!', d.shape)\n",
        "        d = np.expand_dims(d, axis=1)\n",
        "\n",
        "    else:   # points relative to reference (Out: [:, FRAMES_OUT,:,:)    \n",
        "        d = ds[:,:, pts, :] - ds[:,:, ref:(ref+1), :]\n",
        "        #d = d[:,:-1, :, :]\n",
        "\n",
        "\n",
        "    print(\"NEW REF\", d.shape)\n",
        "\n",
        "    #dshape = d.shape\n",
        "    d = d.reshape(d.shape[0], d.shape[1], -1)\n",
        "    \n",
        "    # NORMALIZE\n",
        "    #d = (d - np.nanmin(d, keepdims=True)) / (np.nanmax(d, keepdims=True) - np.nanmin(d, keepdims=True))\n",
        "    d = (d - np.nanmean(d, keepdims=True)) / np.nanstd(d, keepdims=True) # -1 to 1\n",
        "    return d\n",
        "\n",
        "\n",
        "d1 = distDiff(datax, PRIM_HAND(\"WRIST\"), \n",
        "              [PRIM_HAND(\"THUMB_TIP\"),\n",
        "               PRIM_HAND(\"INDEX_FINGER_TIP\"),\n",
        "               PRIM_HAND(\"MIDDLE_FINGER_TIP\"),\n",
        "               PRIM_HAND(\"RING_FINGER_TIP\"), \n",
        "               PRIM_HAND(\"PINKY_FINGER_TIP\"),\n",
        "               PRIM_HAND(\"THUMB_IP\"),\n",
        "               PRIM_HAND(\"INDEX_FINGER_PIP\"),\n",
        "               PRIM_HAND(\"MIDDLE_FINGER_PIP\"),\n",
        "               PRIM_HAND(\"RING_FINGER_PIP\"), \n",
        "               PRIM_HAND(\"PINKY_FINGER_PIP\")], 1)\n",
        "d2 = distDiff(datax, SEC_HAND(\"WRIST\"), \n",
        "              [SEC_HAND(\"THUMB_TIP\"),\n",
        "               SEC_HAND(\"INDEX_FINGER_TIP\"),\n",
        "               SEC_HAND(\"MIDDLE_FINGER_TIP\"),\n",
        "               SEC_HAND(\"RING_FINGER_TIP\"), \n",
        "               SEC_HAND(\"PINKY_FINGER_TIP\"),\n",
        "               SEC_HAND(\"THUMB_IP\"),\n",
        "               SEC_HAND(\"INDEX_FINGER_TIP\"),\n",
        "               SEC_HAND(\"MIDDLE_FINGER_TIP\"),\n",
        "               SEC_HAND(\"RING_FINGER_TIP\"), \n",
        "               SEC_HAND(\"PINKY_FINGER_TIP\")], 1)\n",
        "\n",
        "d3 = distDiff(datax, POSE(\"NOSE\"), \n",
        "              [#POSE(\"LEFT_EYE\"),       #\n",
        "               #POSE(\"RIGHT_EYE\"),     #\n",
        "               #POSE(\"LEFT_SHOULDER\"),  #\n",
        "               POSE(\"RIGHT_SHOULDER\"), #\n",
        "               POSE(\"LEFT_INDEX\"),\n",
        "               POSE(\"RIGHT_INDEX\"),\n",
        "               #POSE(\"LEFT_PINKY\"),   #\n",
        "               #POSE(\"RIGHT_PINKY\"),  #\n",
        "               #POSE(\"LEFT_THUMB\"),   #\n",
        "               #POSE(\"RIGHT_THUMB\"),  #\n",
        "               POSE(\"LEFT_WRIST\"),\n",
        "               POSE(\"RIGHT_WRIST\"),\n",
        "               POSE(\"LEFT_EAR\"),\n",
        "               POSE(\"RIGHT_EAR\"),\n",
        "               POSE(\"MOUTH_LEFT\"),\n",
        "               POSE(\"MOUTH_RIGHT\"),\n",
        "               POSE(\"RIGHT_ELBOW\"), \n",
        "               POSE(\"LEFT_ELBOW\")], 1)\n",
        "\n",
        "d4 = distDiff(datax, 5, list(range(0, 40, 4)), 1 ) # use 10 samples of mouth\n",
        "\n",
        "print(\"D1 phand NaNs\", d1.shape, np.isnan(d1).mean())\n",
        "print(\"D2 shand NaNs\", d2.shape, np.isnan(d2).mean())\n",
        "print(\"D3 pose NaNs\", d3.shape, np.isnan(d3).mean())\n",
        "print(\"D4 lips NaNs\", d4.shape, np.isnan(d4).mean())\n",
        "\n",
        "if d1.shape[1] > min(d1.shape[1], d2.shape[1], d3.shape[1], d4.shape[1]):\n",
        "  d1 = d1[:,:-1, :]\n",
        "if d2.shape[1] > min(d1.shape[1], d2.shape[1], d3.shape[1], d4.shape[1]):\n",
        "  d2 = d2[:,:-1, :]\n",
        "if d3.shape[1] > min(d1.shape[1], d2.shape[1], d3.shape[1], d4.shape[1]):\n",
        "  d3 = d3[:,:-1, :]\n",
        "if d4.shape[1] > min(d1.shape[1], d2.shape[1], d3.shape[1], d4.shape[1]):\n",
        "  d4 = d4[:,:-1, :]\n",
        "\n",
        "d1 = np.nan_to_num(d1, copy=False)\n",
        "d2 = np.nan_to_num(d2, copy=False)\n",
        "d3 = np.nan_to_num(d3, copy=False)\n",
        "d4 = np.nan_to_num(d4, copy=False)\n",
        "print(\"SHAPES\", d1.shape, d2.shape, d3.shape, d4.shape)\n",
        "##datax = np.concatenate((d1, d2, d3, d4), axis=2)\n",
        "print('DATAX NANS FOR REPLACEMENT', np.isnan(datax).sum())\n",
        "#datax = np.nan_to_num(datax, copy=False)\n",
        "\n",
        "#datax = datax.reshape(datax.shape[0], datax.shape[1],-1,DIMS)\n",
        "print(datax.shape)\n",
        "\n",
        "PTS_IN_FRAME = datax.shape[2]\n",
        "FRAMES_MODEL = datax.shape[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sgZEC3UrX47",
        "outputId": "30eff449-e642-4e17-e6bd-68ea5a471dec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D! (94477, 50, 3)\n",
            "NEW REF (94477, 1, 50, 3)\n",
            "D! (94477, 50, 3)\n",
            "NEW REF (94477, 1, 50, 3)\n",
            "D! (94477, 55, 3)\n",
            "NEW REF (94477, 1, 55, 3)\n",
            "D! (94477, 50, 3)\n",
            "NEW REF (94477, 1, 50, 3)\n",
            "D1 phand NaNs (94477, 1, 150) 0.004911248240312457\n",
            "D2 shand NaNs (94477, 1, 150) 0.9674523958212051\n",
            "D3 pose NaNs (94477, 1, 165) 0.0\n",
            "D4 lips NaNs (94477, 1, 150) 0.0002857838415699059\n",
            "SHAPES (94477, 1, 150) (94477, 1, 150) (94477, 1, 165) (94477, 1, 150)\n",
            "DATAX NANS FOR REPLACEMENT 349448745\n",
            "(94477, 24, 115, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POLY MODEL"
      ],
      "metadata": {
        "id": "udy4Q7L3netm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA COVERSION\n",
        "N = 40\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca_d1 = PCA(n_components=N, random_state=999)\n",
        "pca_d1.fit(d1.reshape(d1.shape[0], -1))\n",
        "pca_d2 = PCA(n_components=N, random_state=999)\n",
        "pca_d2.fit(d2.reshape(d2.shape[0], -1))\n",
        "pca_d3 = PCA(n_components=N, random_state=999)\n",
        "pca_d3.fit(d3.reshape(d3.shape[0], -1))\n",
        "pca_d4 = PCA(n_components=N, random_state=999)\n",
        "pca_d4.fit(d4.reshape(d4.shape[0], -1))\n",
        "\n",
        "d1 = pca_d1.transform(d1.reshape(datax.shape[0],-1))\n",
        "d1 = np.expand_dims(d1, axis=1)\n",
        "d2 = pca_d2.transform(d2.reshape(datax.shape[0],-1))\n",
        "d2 = np.expand_dims(d2, axis=1)\n",
        "d3 = pca_d3.transform(d3.reshape(datax.shape[0],-1))\n",
        "d3 = np.expand_dims(d3, axis=1)\n",
        "d4 = pca_d4.transform(d4.reshape(datax.shape[0],-1))\n",
        "d4 = np.expand_dims(d4, axis=1)\n",
        "\n",
        "print(d1.shape, d2.shape, d3.shape, d4.shape)\n",
        "\n",
        "print(np.cumsum(pca_d1.explained_variance_ratio_ *100))\n",
        "print(np.cumsum(pca_d2.explained_variance_ratio_ *100))\n",
        "print(np.cumsum(pca_d2.explained_variance_ratio_ *100))\n",
        "print(np.cumsum(pca_d2.explained_variance_ratio_ *100))"
      ],
      "metadata": {
        "id": "GkV7mQDHkzXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### NEW SEPARATED INPUTS\n",
        "class ASLData(Dataset):\n",
        "    def __init__(self,dpoly,d1,d2,d3,d4,datay):\n",
        "        self.dpoly = dpoly\n",
        "        self.d1 = d1\n",
        "        self.d2 = d2\n",
        "        self.d3 = d3\n",
        "        self.d4 = d4\n",
        "        \n",
        "\n",
        "        self.datay = datay\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.dpoly[index, :], self.d1[index, :], self.d2[index, :],self.d3[index, :],self.d4[index, :], self.datay[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datay)\n",
        "\n",
        "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
        "class ASLModel(nn.Module):\n",
        "    def __init__(self, p):\n",
        "        super(ASLModel, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        L1OUT = 512  #1024 was ok\n",
        "        L2OUT = 512\n",
        "\n",
        "        self.layer_ply = nn.Linear(dpoly.shape[1]*dpoly.shape[2], L1OUT)\n",
        "        self.batchnorm_ply = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_ph = nn.Linear(d1.shape[1]*d1.shape[2], L1OUT)\n",
        "        self.batchnorm_ph = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_sh = nn.Linear(d2.shape[1]*d2.shape[2], L1OUT)\n",
        "        self.batchnorm_sh = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_po = nn.Linear(d3.shape[1]*d3.shape[2], L1OUT)\n",
        "        self.batchnorm_po = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_li = nn.Linear(d4.shape[1]*d4.shape[2], L1OUT)\n",
        "        self.batchnorm_li = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        " \n",
        "        self.layer1 = nn.Linear(4*L1OUT, L2OUT)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(L2OUT)\n",
        "\n",
        "        self.layerFC = nn.Linear(L2OUT, 250)\n",
        "        self.softmax = nn.Softmax()\n",
        " \n",
        "        \n",
        "    def forward(self, poly, phand, shand, pose, lips):\n",
        "\n",
        "        ph = self.flatten(phand)       \n",
        "        ph = self.layer_ph(ph)\n",
        "        ph = self.batchnorm_ph(ph)\n",
        "        ph = self.relu(ph)\n",
        "        ph = self.dropout(ph)\n",
        "\n",
        "        sh = self.flatten(shand)       \n",
        "        sh = self.layer_sh(sh)\n",
        "        sh = self.batchnorm_sh(sh)\n",
        "        sh = self.relu(sh)\n",
        "        sh = self.dropout(sh)\n",
        "       \n",
        "        po = self.flatten(pose)       \n",
        "        po = self.layer_po(po)\n",
        "        po = self.batchnorm_po(po)\n",
        "        po = self.relu(po)\n",
        "        po = self.dropout(po)\n",
        "        \n",
        "        li = self.flatten(lips)       \n",
        "        li = self.layer_li(li)\n",
        "        li = self.batchnorm_li(li)\n",
        "        li = self.relu(li)\n",
        "        li = self.dropout(li)\n",
        "\n",
        "        # ply = self.flatten(poly) \n",
        "        # ply = self.layer_ply(ply)\n",
        "        # ply = self.batchnorm_ply(ply)\n",
        "        # ply = self.relu(ply)\n",
        "        # ply = self.dropout(ply)\n",
        "\n",
        "        x = torch.cat((#ply.view(ply.size(0), -1),\n",
        "                       ph.view(ph.size(0), -1),\n",
        "                       sh.view(sh.size(0), -1),\n",
        "                       po.view(po.size(0), -1),\n",
        "                       li.view(li.size(0), -1)), dim=1)\n",
        "        # x = self.batchnorm0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layerFC(x)\n",
        "       # x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "iu2KFJGymmXu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MULTI TRAINING\n",
        "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"++++using GPU++++\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"++++using CPU++++\")\n",
        "\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "start_time = time.perf_counter()\n",
        "print(\"DATAX SHAPE IN\", datax.shape)\n",
        "\n",
        "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
        "print(\"DATAX SHAPE IN2\", datax.shape)\n",
        "datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
        "\n",
        "trainply, testply, traind1, testd1, traind2, testd2, traind3, tesdt3,traind4,testd4, trainy, testy = train_test_split(dpoly, d1, d2, d3, d4, datay, test_size=0.15, random_state=42)\n",
        "\n",
        "train_data = ASLData(trainply, traind1, traind2, traind3, traind4, trainy)\n",
        "valid_data = ASLData(testply, testd1, testd2, tesdt3, testd4, testy)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
        "\n",
        "model = ASLModel(0.2).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    model.train()\n",
        "    \n",
        "    train_loss_sum = 0.\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    train_bar = train_loader\n",
        "    for xp,x1,x2,x3,x4,y in train_bar:\n",
        "        xp = torch.Tensor(xp).float().to(device)\n",
        "        x1 = torch.Tensor(x1).float().to(device)\n",
        "        x2 = torch.Tensor(x2).float().to(device)\n",
        "        x3 = torch.Tensor(x3).float().to(device)\n",
        "        x4 = torch.Tensor(x4).float().to(device)\n",
        "\n",
        "        y = torch.Tensor(y).long().to(device)  \n",
        "        y_pred = model(xp,x1,x2,x3,x4)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        train_loss_sum += loss.item()\n",
        "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "        train_total += 1\n",
        "        sched.step()\n",
        "        \n",
        "    val_loss_sum = 0.\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    for xp,x1,x2,x3,x4,y in val_loader:\n",
        "        xp = torch.Tensor(xp).float().to(device)\n",
        "        x1 = torch.Tensor(x1).float().to(device)\n",
        "        x2 = torch.Tensor(x2).float().to(device)\n",
        "        x3 = torch.Tensor(x3).float().to(device)\n",
        "        x4 = torch.Tensor(x4).float().to(device)\n",
        "        y = torch.Tensor(y).long().to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_pred = model(xp,x1,x2,x3,x4)\n",
        "            loss = criterion(y_pred, y)\n",
        "            val_loss_sum += loss.item()\n",
        "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "            val_total += 1\n",
        "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
        "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
        "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Save the pytorch model\n",
        "py_model_path = f\"{WORKING_DIR}/py_model.pt\"\n",
        "torch.save(model, py_model_path)\n",
        "\n",
        "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:16:57.114241Z",
          "iopub.execute_input": "2023-03-13T18:16:57.115451Z",
          "iopub.status.idle": "2023-03-13T18:23:25.123968Z",
          "shell.execute_reply.started": "2023-03-13T18:16:57.115400Z",
          "shell.execute_reply": "2023-03-13T18:23:25.122556Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5b7c0d7-789d-4e28-fccc-b9d793c9e66b",
        "id": "WPCyd8Nzn4-J"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++using CPU++++\n",
            "DATAX SHAPE IN torch.Size([94477, 24, 115, 3])\n",
            "DATAX SHAPE IN2 torch.Size([94477, 24, 115, 3])\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:0 > Train Loss: 3.1717, Train Acc: 0.2749\n",
            "Epoch:0 > Val Loss: 2.5199, Val Acc: 0.3845\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:1 > Train Loss: 2.1989, Train Acc: 0.4539\n",
            "Epoch:1 > Val Loss: 2.0724, Val Acc: 0.4917\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:2 > Train Loss: 1.9085, Train Acc: 0.5195\n",
            "Epoch:2 > Val Loss: 1.8198, Val Acc: 0.5543\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:3 > Train Loss: 1.7234, Train Acc: 0.5609\n",
            "Epoch:3 > Val Loss: 1.7233, Val Acc: 0.5806\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:4 > Train Loss: 1.5742, Train Acc: 0.5932\n",
            "Epoch:4 > Val Loss: 1.5983, Val Acc: 0.6121\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:5 > Train Loss: 1.4612, Train Acc: 0.6224\n",
            "Epoch:5 > Val Loss: 1.4485, Val Acc: 0.6497\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:6 > Train Loss: 1.3745, Train Acc: 0.6399\n",
            "Epoch:6 > Val Loss: 1.3919, Val Acc: 0.6656\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:7 > Train Loss: 1.3040, Train Acc: 0.6576\n",
            "Epoch:7 > Val Loss: 1.3502, Val Acc: 0.6774\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:8 > Train Loss: 1.2407, Train Acc: 0.6707\n",
            "Epoch:8 > Val Loss: 1.3478, Val Acc: 0.6749\n",
            "==================================================\n",
            "DIM=3 FRAMES=24, FEAT=115\n",
            "Epoch:9 > Train Loss: 1.1968, Train Acc: 0.6833\n",
            "Epoch:9 > Val Loss: 1.2985, Val Acc: 0.6868\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-65f655d1a7c3>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtrain_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrain_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FULL TEST PREDICTION"
      ],
      "metadata": {
        "id": "LqmycLU18KJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xp = torch.Tensor(testply).float().to(device)\n",
        "x1 = torch.Tensor(testd1).float().to(device)\n",
        "x2 = torch.Tensor(testd2).float().to(device)\n",
        "x3 = torch.Tensor(tesdt3).float().to(device)\n",
        "x4 = torch.Tensor(testd4).float().to(device)\n",
        "\n",
        "y = torch.Tensor(testy).long().to(device)\n",
        "model.eval()  \n",
        "y_pred1 = model(xp,x1,x2,x3,x4)\n",
        "y_pred = y_pred1.detach().cpu().numpy() \n",
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGmLmHji606W",
        "outputId": "a80febaf-9fa9-4e46-abdd-9f6857dc0a12"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14172, 250)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"/content/drive/MyDrive/GaggleSignLang/proba_cnn.pkl\", 'wb') as f1:\n",
        "       pickle.dump(y_pred, f1)\n"
      ],
      "metadata": {
        "id": "m1ZSoEUB5r-5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ek-jY76c0q",
        "outputId": "1d1d2853-3d8f-49b2-dd93-cbd537a016f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14172, 250])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TfaVYEpS6cgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VISUALZE"
      ],
      "metadata": {
        "id": "NJ4ZhShVkyT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### VISUALIZE DATA\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "\n",
        "lips_m = np.nan_to_num(lips_3d[:,:,:,DIMC], copy=False)\n",
        "lips_m[:,:,:,0] = lips_3d[:,:,:,0].max() - lips_3d[:,:,:,0]\n",
        "left_m = np.nan_to_num(lefth_3d[:,:,:,DIMC], copy=False)\n",
        "left_m[:,:,:,0] = lefth_3d[:,:,:,0].max() - lefth_3d[:,:,:,0]\n",
        "pose_m = np.nan_to_num(pose_3d[:,:,:,DIMC], copy=False)\n",
        "pose_m[:,:,:,0] = pose_3d[:,:,:,0].max() - pose_3d[:,:,:,0]\n",
        "right_m = np.nan_to_num(righth_3d[:,:,:,DIMC], copy=False)\n",
        "right_m[:,:,:,0] = righth_3d[:,:,:,0].max() - righth_3d[:,:,:,0]\n",
        "\n",
        "\n",
        "\n",
        "# Functions to define landmark lines from the data\n",
        "def get_hand_points(hand):\n",
        "    x = [[hand[0,0],  hand[1,0],  hand[2,0],  hand[3,0], hand[4,0]], # Thumb\n",
        "         [hand[5,0],  hand[6,0],  hand[7,0],  hand[8,0]], # Index\n",
        "         [hand[9,0],  hand[10,0], hand[11,0], hand[12,0]], \n",
        "         [hand[13,0], hand[14,0], hand[15,0], hand[16,0]], \n",
        "         [hand[17,0], hand[18,0], hand[19,0], hand[20,0]], \n",
        "         [hand[0,0],  hand[5,0],  hand[9,0],  hand[13,0], hand[17,0], hand[0,0]]]\n",
        "\n",
        "    y = [[hand[0,1],  hand[1,1],  hand[2,1],  hand[3,1], hand[4,1]], # Thumb\n",
        "         [hand[5,1],  hand[6,1],  hand[7,1],  hand[8,1]], # Index\n",
        "         [hand[9,1],  hand[10,1], hand[11,1], hand[12,1]], \n",
        "         [hand[13,1], hand[14,1], hand[15,1], hand[16,1]], \n",
        "         [hand[17,1], hand[18,1], hand[19,1], hand[20,1]], \n",
        "         [hand[0,1],  hand[5,1],  hand[9,1],  hand[13,1], hand[17,1], hand[0,1]]]\n",
        "\n",
        "    return x, y\n",
        "\n",
        "def get_pose_points(pose):\n",
        "    x = [[pose.iloc[8].x, pose.iloc[6].x, pose.iloc[5].x, pose.iloc[4].x, pose.iloc[0].x, pose.iloc[1].x, pose.iloc[2].x, pose.iloc[3].x, pose.iloc[7].x], \n",
        "         [pose.iloc[10].x, pose.iloc[9].x], \n",
        "         [pose.iloc[22].x, pose.iloc[16].x, pose.iloc[20].x, pose.iloc[18].x, pose.iloc[16].x, pose.iloc[14].x, pose.iloc[12].x, \n",
        "          pose.iloc[11].x, pose.iloc[13].x, pose.iloc[15].x, pose.iloc[17].x, pose.iloc[19].x, pose.iloc[15].x, pose.iloc[21].x], \n",
        "         [pose.iloc[12].x, pose.iloc[24].x, pose.iloc[26].x, pose.iloc[28].x, pose.iloc[30].x, pose.iloc[32].x, pose.iloc[28].x], \n",
        "         [pose.iloc[11].x, pose.iloc[23].x, pose.iloc[25].x, pose.iloc[27].x, pose.iloc[29].x, pose.iloc[31].x, pose.iloc[27].x], \n",
        "         [pose.iloc[24].x, pose.iloc[23].x]\n",
        "        ]\n",
        "\n",
        "    y = [[pose.iloc[8].y, pose.iloc[6].y, pose.iloc[5].y, pose.iloc[4].y, pose.iloc[0].y, pose.iloc[1].y, pose.iloc[2].y, pose.iloc[3].y, pose.iloc[7].y], \n",
        "         [pose.iloc[10].y, pose.iloc[9].y], \n",
        "         [pose.iloc[22].y, pose.iloc[16].y, pose.iloc[20].y, pose.iloc[18].y, pose.iloc[16].y, pose.iloc[14].y, pose.iloc[12].y, \n",
        "          pose.iloc[11].y, pose.iloc[13].y, pose.iloc[15].y, pose.iloc[17].y, pose.iloc[19].y, pose.iloc[15].y, pose.iloc[21].y], \n",
        "         [pose.iloc[12].y, pose.iloc[24].y, pose.iloc[26].y, pose.iloc[28].y, pose.iloc[30].y, pose.iloc[32].y, pose.iloc[28].y], \n",
        "         [pose.iloc[11].y, pose.iloc[23].y, pose.iloc[25].y, pose.iloc[27].y, pose.iloc[29].y, pose.iloc[31].y, pose.iloc[27].y], \n",
        "         [pose.iloc[24].y, pose.iloc[23].y]\n",
        "        ]\n",
        "    return x, y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "IJfMQ9QAIBNX",
        "outputId": "5e6829a8-593b-4e28-f1fb-b675683df06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAABcNm1kYXQAAAKuBgX//6rcRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MTUgbG9v\n",
              "a2FoZWFkX3RocmVhZHM9MiBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxh\n",
              "Y2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHly\n",
              "YW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3\n",
              "ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTMgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
              "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
              "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAABT+ZYiE\n",
              "ABT//vfHT8Cm6Plmy51FPSEwitj6SCi9WOzQMnUAAAMAAAMAAAMBFAvtFYF5kQFdeAAABkwA10K/\n",
              "8KYT+AiGMb1ahHd39xMd2b++iKJ05Nc9l6yPjRv411EZrwormlZQt2uwCpXRTUWAI/V9TrHYRZNj\n",
              "AU3qsA/MSdyg33WaE2A5vmY/qalaqA3H8QJxkEJLF+ioUY669aTC4CcbzpR/8x/ZJwa/QqgIzn7Q\n",
              "B5Evk26Xtgl7I/pwQ9IRislwl7Qz/YBxZScXc+f/87NAc6+qX/SyZc5CTDVuXHoHjh3m3+bKxz1c\n",
              "p+LmUXp/Zfp9MkjsBhOrysAazI56K3vSfZeO3e3dbURu76B+GlwVrESyKZzpfLGIu1pZ5Oy5bpu6\n",
              "HXxKea7dqLRkiAD2uHfVIksEPVQgYBNBEUwNDrHm9kHcQJgo4kD8BjkFJ3WEP2oy5c+60mye6T2q\n",
              "7qFqzcIIehlq8l2BvA0+ieZISlX9pnbWXmII+WmitDY30W7/6vxik3QC5hdeIn41c5piKhCWlXa6\n",
              "XTs2ozBGVB9mH/SXrpcDZnnkAe0BOoZ9bEAkwAjnqK+QItKWDQmPVFP36bDlKYaEpypQPJ1KbVk3\n",
              "/eI4ygW+9UhQYEoyjWohAXrV57VVahLihoMYGtVtWMLU+CjFTyQXc5+sOwIfRl565qVvQjsZLkOz\n",
              "DqPUAW2PS5YMVqM0uX5vXGFsX8YRJ/VB9FCqpqTop6zXbFZtatV04hUpJXOn2Z4UwJsHSwjKcuPs\n",
              "gvbjBBdJaKZiISbM9T/Xr/Rwvh2BO3rDL0076StshiIRs8Oooq2w9A4RN/whOv1USu31bbln8KQb\n",
              "aGfsC709l7Ktk/dISGBarpxjLJmRVfUQwUFETukT7/u5obrkEUb6v/uUfhjxbYTfqCJwGevc1TDf\n",
              "i9bt2qENhkLwr2UgVNj39gnh7460KXvuooARI+h9gSEhfujlALHBWWmm0AAvR1Z3b8ti0PAnsqDj\n",
              "3pkq2j5NkG42o4LlhZst/2FK15Pbxgb7fQiIiR2nwqXavHQM8QmMARqR8KucHAqF9T3JMbAOoMvS\n",
              "E/lk8zqqHJ530eHicHerdRALSTenGWG7YwOMK9bXBzLyJOzX7cf7AxfKM31Zd1YQljlROWDir2EU\n",
              "KprGk9UJvY8PlSrW4lVwUiXAR1CSOpK81NLKupGG1BcffXP7HTlX9D9orfZhuVMna5B0ydEXpgzT\n",
              "HedmeFzjJNvHs3zFdAruXlAKMiK0m7DMGBtkYms1j49L3IFl8bueUlFRHdBg+l+RrhXy+MEL0XgH\n",
              "1PQsSvmt4jE9FHIVOc4VSk8Ym63ZQ2hprSWDGEEIcm4G2rDs5FHUe/zyzXmyJXvELFAF1ywIC1p1\n",
              "7HRP55yXt2lLM58cqHuz/wCNWL4y9lIDdFzsZH4AV/wfzD+L3WykQ/Ot8gU+i1nQHmkJWAr0mRW8\n",
              "jgtwQoH2sxMy54oL2zcevpldaKkLNIv1eH4roHyMak+aikDarYhdGgi7c2zH6ZuZ3EPeVE+87B2E\n",
              "vJ9BLmcG4U9wuDboHeWVosakG/u2lzxQNzeT8f8CQSkTewkgx+BjoWVWpjggxoeVI7N+e007Js2m\n",
              "22rhGODh9KkNotROREQl9IPMZn1k0CQYa1xqPgRLPNPybp/4IzANHk++PKTWFB5GHrKPFkVI2EZN\n",
              "7YRfIg6H/yTeefmEccHZ8shWXZik0BlfAW2RIggo0gw6ofp2Cj6sovcp+gf0tC1CfCqeBTWPnPR0\n",
              "tssJYlTAxp3QJXKYh0Xv1+tfyEOHFnw9fvJBh/bZv6iMJfzC5YtshnMrrkAvOBA2/INBnZcKhvvF\n",
              "d8tmCJZGKNlmBVZT0pCljijH+IkuFInVv8Tcuq1jBZ5FCIJMFEjmzdagJWYJP27tctfHGyL4mfzj\n",
              "fHWHWpBzcwqDOpFGTldjCAEI8r5akU5uC/ii4Kgwos8qKdx7UA577z6U4QmGV6t4dvZlBDf1153a\n",
              "FgQStKtcUADlhE1Dp0n7EDlRJvoPSk//uV1rWvpYuWNCU+X+7MQKKjH8/96sEB8YsoMKU1i0rJAq\n",
              "eNyeCSGplWupSROFfMRPLRAjvxHFnuvBGM1Ighiz/i4T82Jtw8O7G1c1BqCKVYXKZh8EqBs0xiUt\n",
              "cUAYDCIkxyUucA5YlUCE1ORXQzq3tP/3AyOa82CweZ6ePXix+TkkcPQIpqc702I8ZYDqDRgxx45L\n",
              "5VUCG5Yq7LM4L/O5+IeGuZlY1t8w1dfsUSTp0quWuVSCSiQKUOBpll+vrPcCYn8BtUhmM9dh5QKl\n",
              "RIrZ2Mk/PWvM2JO1dGMKtoa+XiOibO0npqoQpLlCSh9ztIykF/CDlHQY2dQxaQz6m7QMW8Klqegh\n",
              "Ft5rTlp5+XXcIMkkcJ80JATCswqIUp14vw+/xDQURbWfWHu3Y289xwGEvPhkGshFP0IN2dl0HxIb\n",
              "0dntxLu2Yb61GLb5A8pnMjlAn//6/qnfoda3ym+x7UD9pMgkSljQK20En9dmyIcb2C+zfTR4F29R\n",
              "zQF0GmrYeZy3/os1yohG/W61C0i8qR8VN3DkS8XUp5fTSCAZ554JlXPuYn8qaFe/y/lyyFzc99ZB\n",
              "Vhz2//NmWe33TfExJd8+anIPcLKFqAnnAD7wFL4pBy5nFujozi9L/e35uNWr2nEyrM6fpocbEshV\n",
              "PRFH0cR8D1H3gTANM8ufk57Ozk34PIKdbkP2A5/iBoAdJMTjNwWPKrB6iuzXi9Ax0AWHuz2mneAs\n",
              "Q86eBnzW7N8fOH3d8VleBsbvDPvOFZJxXUiJfg2LCrlDD4MB0jwXpiAVbRWYjuVw2T5HFP9s6u2j\n",
              "xfdimkEk9UR91F8BymhlHBGTLdd2y89JhCYMnmFB90lVJ5jeFqNG1DrY7BGu/+Ztq6ZLXSgH1AmM\n",
              "+xANdK3ILeTaVe0RzFcUP7wjDm/dYSbojU6OdI0kD7khdp9LAvOdCdHDgSuou24QgcU/Era1VTX8\n",
              "N6osUKeEM9ebzGFfi70hlNVBhV8fQbH64THmj8k5jhuVaLixGA5FIwtGPLiyOILPWwaNKuzhvWJU\n",
              "xvr5f5MqUHgx4nG7tjDNn7mCmZPPbSbkBn/QzHfVLIaYUOYcZB00PpGcbITNkUocYW5kOLYyODk/\n",
              "qd/BiUi1hG59Hyds3xJV4NZ+7iHBQk5qEBZBbbYZGGbY+JsPsD1X43p8tF9L4r8+/2JozFQiVDeF\n",
              "l3qhq25Z+f/xPg7he+L9X6td9k5z+F5AGrnuIYTVRlICTorEGqwQQr+3ZrkJWtjMtclszbWgL/Oj\n",
              "mMzaaxlzyBtcOTQlTm8WQoopt/H/YrLs9GblQ1sEf1+L5I8OpZaGG6F5v3yXcIWFlN4NPF2DQAQb\n",
              "atb3iV+vWop22jznWAcX/LmAS6Li9SCitobrQjOLyxZ0myy53av5fvZqzpUEynaiaHrCgcRNR8Zm\n",
              "IeZ9fiItJXj2lriej9JQ1QupCrMgxnEJZVWdgLa1GVtbEQ/478h/wbIWt0DGayB4OM8PVZNfTumI\n",
              "0rdka9uwUMTK3OUDCSOtUO7uPeyWhRxLtbILZvgAJ9+eUqZQ4ZLpZ66f0p9rJIR9Ath2GEYpAdqI\n",
              "1E2ZMZI2gvrg2JlvmFGKUpXpft6T+yTjTxrb+HTcJXJONoY7axhDtNdcYSulFSm2Jf0u/+gxv/Ma\n",
              "vxdpnT1oxwuti/LBNGdGri7oDk4NYCg9uHYIzPptOzRUGwjyAaqn+CAzR/v/fsT+cGuF0BDv3LHi\n",
              "R0tH9FiZ+q9WHh8cS/Rw/UXl4mn/q5h/xEbNDng+tZ1qf2x0qzrI3LXsogOBchlKS/DhGQNXrFlJ\n",
              "nC2zCnOEYjZzsM19P/Fb9V+zayspflhqaB16eRNPI5ccB1WbuNc7BEOOEwbl2n/ZbF6wqSJei5Dm\n",
              "PudWQpZdvERnDSg+IpLO5JpKk5rvQfaHHgngJnOtRMqNeH+7FngukE3NMB1ne+cJpvmWXVV66DkH\n",
              "l5ZCP3HdjEuRKt1CMRFkOFqwS6G+wZgB5tf/4LNoel2g2J1OqsM5yeJ2MfMoy+NY/aR9ycUGO+rh\n",
              "t1C5wdxY6CPtPYg8hec53UrHx/OQhDEnU9ybXiHwNwogkUbzKNsu53txB5qf2RQuehctILurWPjQ\n",
              "NJpiZHUL5ejoBCa3Bfg68EEBOgwNfvpAPS1/YQ5aNsOOns1VR9KEN/6tL12T+qcQLqfuL6r+YZPK\n",
              "wYdtaQN12BrYtUvCqCvinbo8EOlEkYaIJf/Z5w2RXQpOOzJKKnpyeYJeFwOgrb5/wFqYcVlLgra7\n",
              "HZ1f2S0hhA+w/xztIDnKNBcCGnOKzT5TozAxMG1lO5shrwZCFLaLqSOawN86rHufEVi60ua/I4vK\n",
              "URJj3XT8oMV2X7RLe1r8spDKtc+n6T49WPem0hFO6kCTuA2YR/fotIZ1vCqs68o3Wxc38lQLS2NX\n",
              "SyI7RXrIxc7ga6fhXTQ3OKmbxjoji7sS5bt16KDl31HrLS7MTjrQeUTwHMoLfkR0Dlo5CjnOTgZy\n",
              "WrFv9LG7aAvw2tdBm7MgS5/HCsfefIr5Si1bRf3vP1RQBL6rk0CKqw4W4WIF82uHjwJ8H8BoHWHm\n",
              "qD3UpyToIqzvlcpQYDD9XdoaJtcTllSFyjtvSbigrOlN3kIpKW+0ao/6Al0zGy8VHC6qm6BsGOXX\n",
              "J3T70qq2seM/aULtGqZYSEsCZKrqiTadB56mzOErtVndrZT6w+XVmGV/WBjTaCHIH2td52G+PhSB\n",
              "f+6FxwC26DHpYVzM+sGeDCtJAAgJoiUxmJeRqKaPHGILxr5ZBTRzxM/LLVHyXhxZGX6T758xPkrB\n",
              "HWmYVHK6lwRX3s5p2E8/LUexdTBeK/lDplB13Y/Q99hJ75R2oCiLTcFGr+339tkOOmhrBKd8e/92\n",
              "K/wkPdc9M8lRJgxK/kGk3LUXH9JIj5ps7yNy5lQtHQwB5Vun8xPvr3AUXKS3XXacCsqT1riO4u71\n",
              "2TjJVrL3zZgElOSGSDXR/pYy4Xm/NsvrEerSTlMfzCFFE3cUGoPkDXiEauj5s3CYv2aNZGwfFUXz\n",
              "twDQNeL5nX50MAxXUb5vgGMwgDgBYBeKEjAuVV0Os5b5axhIaegH9JaPTF0OhUBBPXEjSRfpMhRB\n",
              "k/Yc8zBw9ununaWewscnwsTekPg17gKrZ7QLkyhTrTRpM4YElsZsq4B+GID7zs57VWXZ1EHsIUAz\n",
              "GesBLYikdNf/dzevB7jTT5Wjl7kDhvSTt8iTDpHSw5KAnukl41ybvGSIlxKW+zvxypj/5WS7SiTA\n",
              "CGUB7DBtwt84zAlNvq2Z1cboKDTG9zmn7JTBiqSBCvXQrVGt6AFclgYurQ0qHcCF2FOcGLr3VbPu\n",
              "Kmdmh/78oBupSbyqrOOtKJdl0AexM0kxFeL2AEEkz5wnsaSxAZ7428mayIivz2YINu7AP7vIb5t0\n",
              "5mzT6j5t+5yg513Wr53carZmaugoj2JrNWSnxdzhY5Zz3k3Ozj0CKLHlGnGPTpdj5l+KayNmkN2Q\n",
              "gJB5CnxTyjpqGhM/UGIgDPAQSVUyALma/s9iKBE/VzyBFh2G+e8SBm/nEjwhJBTzk8m2SV1lg6MK\n",
              "9Rlfj3bdjQcQjz2fp7ZFhoDJRtzteoBeQBsBITfKIsb97hU5BDK/OWWvsNa3dVK6YdoQOdM3z+Kj\n",
              "n5vZ/04CD0kn//xgFaKtu7goHOwLbRSKuAz6zH6MvuQs8+Hf6PY9f2PAxwYuFd89dhJo8vteHn9+\n",
              "F7Bgr7ClSzRRk57DpZFoEV/pSurCQRCIuHUuGKg0LFlA0pIqhjTOimtXTepOhwgdIXEyiPtf9Mua\n",
              "w2p2lUTOXHfEuXCpSrzm8UyjQCMinELJjHL3dokniDDh145kvzAcqyCvsdynKEkDoXb4pErWm2Lz\n",
              "IFzk7PvK15tna+pcqtccSBRftMFE6yMl+fZo6ZrtncNdqNToXx4x9Ey9vDb3P3+14I/bdeO2A8jM\n",
              "0ylTJHmNBiosTl6a/OvKUevwGqFQSGD3mrigOCvchbIng3b/4rC/zOkTMTir/CajbIqp9iPTUF7V\n",
              "/beTN7Pz+HODTH1v5BhPoFU1EpZFDV9/QUZuq7O+RTAEP6y1NgLwAn6j3lvnC+ReT6dkwqApbsa+\n",
              "YoVYxAjoSOBAfN6apkQzOnxJp1zGVuw0H9ZZdA1m1Kxd19m0MbX4udpGao2BTnATETDAqh/W24IK\n",
              "vlJUpGqljbIwHSfI8Xryvf9tuXHyrA484YdN86JpcyLecwxD0IY8Z/xo8EHBtZ7QzIkrpTI13Jq8\n",
              "TKhnC6E1n+gZmdo+jKfxGPHvWy0kTg9cYZ/HGFCS3IljNXSZaYtmUA/Z+nTqLKQ3zYBEluvGD7th\n",
              "5dkXQgCZFrQUrpL+jQVI124bwMSls8O/j/I/CkA6VwElNmqPQuhvPAaJTp9qPRszR2gapCXsuLWE\n",
              "2ylJpaWfrziinT6uZGQW0eEFRyzNfjiGCfSNHL2mNEvQl5syPu7UwtMDBZvXGdC3iP+Bsc2NdW5c\n",
              "iso3l6jR91zy9pX1Gwv4upO5+QYQKOL80pGd8I7ys661sSQF7jCmKfzzrlMqc8aME2RRIJtZF6qn\n",
              "W2YEQLG0Z6/7a/dA8zLGNM42XCgC1oUmg+L/Ja3B/wydM+zRn+Ya01t1TB+N5+HYBvnU6NUh0JtR\n",
              "O2ZRel+ElARk030Tz1qLGntwud9cJJTqHIa5dLMr7WJu4VHR4sg2Im8svEnm2gfast1AQsvUABVx\n",
              "GVSZ6fXrM14Bv0EgnaQjpwodLQ3ZxPM2oQ2u9bYBGBOGhKNqbRlDN2Qf1/wHqiQiLECYewkUNpC1\n",
              "twOuUDxTm+enzh2XEyJTm1MDcovYlDlV8NfSbbwAO8D8zPK15V5ACu48On3HaQN9zwq9s1m4tOPm\n",
              "0vNjsmF52TOPXB0cy3+UAUrfQiK0fZ9r/3dr8OCvlnT6/9JgIW++tjYuLjrFs0znuSScZPuxl0yz\n",
              "saFvpP8h+pdIW7n/EuGm7zYFUDE3YhOd85iNluZlEoEzukhZKSTUFitw9fnT4ava4u+fmWssArPx\n",
              "T3hS70FJrNdcniHUev7B6PQ4UT1w3TgZq+tVEjWP/tK90ol0djTOpx0Zg3clh7tf0syrtTBQJCZR\n",
              "nqeQAeMoDkxawfEU/B2cEWA3nNYZ7DwMxo//5BsJczuaVpmn8ddM6b8QbYTBlabKhiwHZhffWhar\n",
              "nXzQ+fsbFyRAAABNwQAAB6lBmiJsQU/+1oywAAs30/6TYFLu9sD3pXwRaA1SOF4kfDyYAsJ2E1eG\n",
              "B85t4yPKn3MjHNIkRnJf+HadVtfTfFcdIa1Qcjp+HG/jqCMZOGJrvmO4AbD70HnzTwGZl3V+Z3/B\n",
              "tU6YRHGcLz45NT+u6cwwRWGo6DeF3qY4irdrSrqIA/9iSWQyc45MF2b4fL4Z/0tk5WGU85lkBjYZ\n",
              "jUx2R/jlrE828GbxhzS/ZXokfBFXLmn/1lLPvvhXeNk4MWxX+/ZJmYaaauT4WGDh1shtSbIqnOgZ\n",
              "3HpAAQffKsN8lO1Shc5yOJ898Vf3e/CcxzH/aOvDkAS028A361hk/CO/4YQozfH4LACpNYydXb82\n",
              "yWyF6spantPLvMNRdZWJBlmldBKDxcbrgh/huUnmrJ/Il+wr2nFbWXICqQzWLaCRqu48GOwViHCV\n",
              "3/BCU/IzHCq0bk6e3RwLb9N2PSC5mCe7fqxE9xar2YzaNvUiIfo46jzq+EuWgQEbftTIjpJRYiJ4\n",
              "pqUikXnKlzZoWffHBNiZW3RQDHfbcYesfiDRj7ukbSgLVgmg8JPhMy2hFNlTOyCqe7amYItmDT1z\n",
              "hlZCerjYAGHHOIsw1rDDK2TNoEXSq84BwYAgj6gATSlKdUYu8jzlNsLe195RmPAyoR3JPSP38tA0\n",
              "VzXgjDaICt0w4IvEYkDG9Rna/D05w4pcsUN1BiML2Dv7Lqhq+8GWxkasIUnPJHsDMXiWyMir75/j\n",
              "vI7+qWAPYE0lsLRwl8KC/PIxXfGyroGRmpVpGc0htjxwoDk7a7OvERJ4v17GkfhYuKhFvBkv0Fyq\n",
              "D03BxoTF24mvrk7x8IR9ux5RDvuzbTxIpz/C6GHTnaubvLqRtrzeAX8vQoGkwTh/U2Fw8RW9IahM\n",
              "41cmURBPIA/VJNjYfufXV0SgKLs/mkg5QX3GuqA0r7dJSocBNS2SdEfnzLFvTaAsD2SzLARBk1qq\n",
              "o351fl1gcBDJ2+cDXu7pRdc0A4TITQo6LbMOi0ZEHRz8qxlfEPEgWB81dpk5w1kTcuuFe1ASvS/k\n",
              "K537TsRNuZpLAQ89+YM5aqgkaueP1cETF5izsLVr8FA9FsaDsdePDpEVQI+Fk6iE6fZePKDahzVP\n",
              "gkIB6h5JKTGvzvaaXATdi8R8HYsnrZMz1DPBbgov6z08q7SXAvvYz0s9Hz2ZErJqkZQzVquH5G5j\n",
              "WY+scpJNoHf+X5lzinrQCZUxcA/3uKFA6BFQ0+meM5tukeAA4o6OuB0af3nFWNYhmKTcf7loIzVg\n",
              "m4eGECMf5sMAu4/MrKMJwV410rARDQbKPMWCGU7rE2W+kT+TW1Vaj6UDgi0VIBA5Ds2RH+tfWSAC\n",
              "EJvNp7vsUPZ4n23PWbg+oJN9919PjCsKCTDPm70i47uX07X1QVIfWQuF6DuGdqb27uF+7CFO3LQ/\n",
              "Pi10hr/VJrFRpgYr/Appe9w19Cr+LhqdYPD4J5X64SbTEvjsKANQ+j36cA4Yo7XegPsFso7JbbOW\n",
              "Rvh6nqTvdu/Od4B8Cgcw2nbeN9IMU5cJZOnnykCzcQBXRXyBZqRW7Y0DH5UZ6JO4C8zprs13Vwl6\n",
              "mnvgGpvUDasnfKGxZf1T43q+4cdgysLPfv1BUKxYeT5zcdVJOexC5kEiS2rG+u2SWK565I7fCTi2\n",
              "MJqhwcP8PuNqxqRV5W+hxbGJoh2YA5aF2C1YPU5fz+jRp9RfpwE1UrEV9mDbGhqS2X0T4f57+C8W\n",
              "+tFC7RWP/+a/K7rMjDu1KuiDvv7hioNNW8KhXqhi0FadkwBcH9B16/wQDwPMhJLZMo+dTQYyDnHt\n",
              "WrM57OmetWwQQKrsHSSwZNoD4xV/6ZfFBOvhsYwD3Md5k2AoFsX+vB2edUeonEk0+oWPFr/dfWsq\n",
              "I7wkRQ7TtESan9ytpVhUaujdWdzuUqrz5sQt6P3Y2WcVV8R5IkDb3hvBcrLPJlMcgXZluH0hSlVB\n",
              "kcVEG4+qn0qRnogekQTXglgc73J1AMWGdpMTU7+GGq5qnfkjPj7x06jbfRJdG6AmXKVH2B6sTebj\n",
              "05wTXx/+SvvQABHtScV7b/c/4Qx9NoEE+5GdnBatk1+ftK0hqlGuTnqXXsBaivQHI+rIPQy8w6pj\n",
              "iKmegr/A6fDrz0c9O+DUxaiuSgv9SFiQxWpg6FlyE43AJiu6h30xYLW8VOlaM1rGSPUdrExhx43z\n",
              "1BUm1GseBUpQKVztXPwqWgK4IFuB0Wt2V6WGF9sR75T2rMtTBVGtQAdhJFrLW0aihwAHeJE3mAJK\n",
              "dy4mLnNlCnzYf53ilj3hX4N6cBCpyxr9m7ap8NAqe5L8swhD1ucM6u0KyrclV4/OrQkXScgRDk00\n",
              "uvqeVaH/8FfHNPdYfB2noxYliYEIZaXXs4ez22v+cxlaFLregwG93I2RHnxq70A1ncpO1NHzRIaI\n",
              "7OGkkXyhBaHJCHX7sL7MxhczV2QtX4NsGuSiCXzNdO2v2swSOmtdJ42uFB2rJ8YpiCI3YA2ipgyf\n",
              "BGVFQ4VpayKknQlzJbyg8bZQ+aqwYp+btZNLivvxc9+mlfztnssER6WGUwSfQMLNSGcxfMYAKjsn\n",
              "DhpyPgcqKqYXQBHn6eAjDo2R3ia6Mr5VWUa+gRYAoctMUwa/Fo6i8AAABrMBnkF5BH8AABxGG30U\n",
              "Z3DhVAzBkr/DYT1wAS1emTLQlgbmxyHnCFRIiRDiqjK+7t83xnsBNX4FNTD5fKV6SVJZYla+3x6x\n",
              "AASpit+iThk4UJvIFVH6GVZeAfKZ03XnInQ6jqypUSuFNOYgRFiTwSFdnPQ3Tqr2ibnb8XtU+Pj+\n",
              "+++Cr4w6nkE0sK1fufkskI8Ss8xAHPkrznXU9LGIECmBBYI7xRfI9Bb2/Aj8dAzYS4hZKndSTQvi\n",
              "4T8o/rsYEhe7j/OKHslodE88ZHsVBmoczWhadnClJX1DeHvCI1wpAGqeLbB++IOOaSBNf8DyJ3GV\n",
              "XKenG9Pl3ZoVfP//WvcL97y2xK+2l9swqPfs07d38R/Qy4YB1OmMwINMC4rZAumvuHNOfOv4NpeX\n",
              "hOOsXOYjBigXKMshp5lXE5ewNy+i50dsKqF8XkTL0JhQBVvQ2rI8W1Qr1rYPnZgviTwyrnSmwJGv\n",
              "mY5LtAuxByNzIiFNhILWPWzW39CdBIuYP3dY36NnfcxJ3rFZBsUxpjfy1qYHd+mEPPhBdP/nK6f2\n",
              "ZTh1CTM2UJmxgX2n22cxoE5w1N9AI0mzB8fFNtz1eyf06BH19TIkPEjmg8zLLIookcJRU8z4xggp\n",
              "zL2OFyO2EQYJP9R0gNsdiCKj0l/GOzAmLZ0bOgRqxf6wVpV//8a+UJAXe7wZcGaDFdR9Xr60an6h\n",
              "2T36TjLgrvDI7M1FbsMJBC1O/XEqebPw+um636OotL+LFQVwnvExDGAmSZd91S9xeCQpZRCFdSOE\n",
              "97p0xCsmEKd4wtOlDr50cuyhVWkSGYcDdIeN4IkeUmCAK99uyE9QrbvIcB034MSYWlLnYMkmJYWB\n",
              "07SE1l2ryFB7iDSc182LH8ErcPGqtMvOz+0eE0yaGKJK224qnptJgGNTFDSaJTbNsWQlmJ2cU924\n",
              "HImCNT3Ji7frrpijKm5UcCvC9Vp9zjqMIoalw5DmofHMxYSHq32mCczPi2EYJsP/FA1HmOttHqwX\n",
              "2Wop/XZZPycvtqwKDBPUmy/AMwotkGkvYu59Z2mrl/2jnIhq5QbbdozZUDmn5bNYgGU+kBaxCHyK\n",
              "KF4Ee+4oTHmkqGGvhfcgm3lPQR0hCLveFBntXxY/oFi2C4UrOUhanMomQ549ZULxyygzCEFBrDEK\n",
              "AZ1uWvgA6o5RuJW7NbNFf/7eDtylLsEhBttYnRENQwTmebVMYeG/KCVztbVCfKLU6A3to8kSISMC\n",
              "vnd5cQqYZ4F/f+Jlih1lV0r5IZ6d3QPdwEL8qlO1XjjMXcLBefruPTLi215vw7v7NyKoSbmkbk3w\n",
              "fNeXnXJvUUWZ6cCXSJ212wifm0xQ3FE+pt9dDF1BIOx2mbmKNgrZfdievFXBYgnqeeumOZLwo8wg\n",
              "AjEVSakzD2wNnOVLfQ3LQ/Eo/HBkC1VG+dcQeQ/EBAmz6trLFYQkmDDmE7gFXi1m2fvyvsi4bS3l\n",
              "Ge0dRmClEeyr0LNfSDUQoSFnchh92VPnQN+AbjspGEbS1PT7RCu/xDlLy/JfhE7Mi/qFx3MGWDB3\n",
              "9Rz4tnkvNmlybltQ42KsQ4nVOVxZTvStcf105iiCGFDkifQ3TpQGD+LM+6RLIXkMt8DLuOgq9FO4\n",
              "cHw42q/WTjharzkOZAvvVw1NXR31l8wi0zNE+wTn3cj1DyFUGxFJ4JGskAuS+UhuQqtH8IgegPn5\n",
              "QfCOtoGDymYCFRptDG7cs4oW/5wp2imcKe6vzhBamZ+f4smRqyk1K8lNojys567fI7GT1yW1Rxtf\n",
              "+LGUmTQnhE6cB/3Jx96gb5vhnnxnvZAp7q62XdQ5YpkIbZNzuKasoX7dvgGWk/2JcumyT6GiS56Z\n",
              "BuYaVVHoxWC2Wt1pgBSRbFnBRFZwcs+UO9ysIgHNwW3VN6jKXRBMzs8wK1z8qF5LvyZNMbNB1V3L\n",
              "sqRSyncQG9ufNStmxyH93QkWF4zHUik5A/AK/I0O673zgDldZToWXWAYxNKXWrodtMwhYxUK3IKF\n",
              "UaSspJC7hsrIyk6QIgK3SH6treUfKySY4U/ytjLzoqazYGcopwkTPDDF7IjDB6O2lrM0lKBE256T\n",
              "br+EyvzohSzmhBLimbH4JDUni9h4dINFVsS92P6ScuL8yzQl5ZjMgqUYu2vKOwVv2MTL4k9y/Rws\n",
              "mvB3CT0yn1u3twFdjQIMcxKc0h4C+vTODr6G0bdmFzgWFrLC3tuHkdO1A52M+UwmjjldjrjfSaUR\n",
              "eKfn6I2oesRLWJoWr3dqdSYHtPSxbJpNUGTH+wzaHJqeQowFTKBOuajcyAFDEylvUwAABhdBmkM8\n",
              "IZMphBT//taMsAAAfX5rFbXgl7qc7TpFzl2YGz1S8hqPLyGRa9xxAAvBqmRjNXLfjGBI5gwFCV1a\n",
              "Iy5wS1LmHSA5m6hEwICjWaWM8P7k+J24i1nA8DE+LCZIPlVc/sqQuIBC3jQw184xXJFLNUEO8Nvn\n",
              "F+/XaPeh1pTETGFTm5r3ZNGVpntU6QmiqrCSvPVstjocsg9kavdG0szXmc2cpBmfqEaThfYRp7Wj\n",
              "fHxxzNzCWWNLkWTJSKPiybjlXiIrJVlGcrqX5INU5Z9Lw0Ut4airh3Y8yyg9M/OfWeZhK2GnoXAE\n",
              "VX5sZ13HiE6Ovl8UpbT6EojFmoY1WRAaC1ivNTCHQeGAswWg94NRuh5sK14Am7dsgWKqpGvQ4Ah1\n",
              "KMf3PEL3Jk8AQJJXrVOD/26fIoPik7t0AtOoXBofWAZFV6a7zilLKnDGw0dnrrWDi4RhsKpW1MPO\n",
              "KUlsnDiMoFB5YOFKvKjwK4FOJ98W9b8tUTg+hTJcpHOhvHskFyd6FxsyVyRTDMltybdmA1QytEo1\n",
              "3OG8W5oPmZs4kU5sA/reuKt3O2ex10lqhWcJ+A9765cYsjF2dTs90aRgIHPjNJ5bGfPqAOIaPFHJ\n",
              "X7klD8lGCv96JVwI9GJqVtZS8/jmthAIBbokdgUd97HbbUhbCwRfU0hkAYxU+kjq/AknBGo0KWMh\n",
              "thsgMZ9WCOiVDUoKhCvITIR3U504tkyzABF0zNh3fw26WisdTE/HPWnMsXSK2EyTfPfH391Kb2Bt\n",
              "yo257gZG8JvMaXCNaJZ7Yr5mJgOch1RKeY8YxhsoKZhnK8jaK3HWzInyBzgCl4n2ior2zFrrMZpz\n",
              "exEDnF99Ey11LgBm4PPFrYzR+KxYZ81DA5he724hhWbj+2uGxizO+34OyTV6+ES0yGU7ZXxl6BCQ\n",
              "viJH/dpx4hS281+GueTNUBT/M6wUDExg4wPxxx2XHw+hNY4tdTsb0/Le0F4mNHQok0DNteT+Wo38\n",
              "rCLmzUCnsKLn5c55HMdx1xCkJZs6+BFOELCj1xtBiJkB1bMdW3XFrtqzNfBLMc2Si9aUB4Nwi5qw\n",
              "WMpDS6NBFXY7rJDw26B4xLXtoeP1IDGjpAbXN1/DOMgXPWaDJQXRGXsitHk6N6NHFkegcYGExiQ9\n",
              "Ortk7YEs/QlcQ++1cFtvlLJ3Gv8PTZiCPCYXQ1bHE80tAY1pTINaiG24vJIYY5CChAFhO8vkCXlx\n",
              "z6Zfyn2r3x5OrZnWgPVipTLfrOvenPVi++TbeIaz7Qu/hF7J6Uv98dA4QQIhqe5fLi28WzSJjGeE\n",
              "Nt9LnfwX1L+8sr87Zskr9cltfPODGkAHDw+jRgY899tRtER4MayF4fTDaMWrdMvTqjqojV3lzx5G\n",
              "mGRB2Q4ysXcQRX/Ew+6TnxcHYFyglRbpr2vaxvdNTxzt5vyrH0D2PP652fWZjNaccpZpJqIzVOD0\n",
              "d5yv8IuoVIT35NshBh/GXRGaPa8KlG3FSdtHRUXMvkvURuuj+s2ZNn3hWImSdxwbBfG2oNUCo7XD\n",
              "5J/inY0OmyHBowAuH1x0y02bXUuoHq+mlSRv4pE10byu+81ODk+5mBiADSpSNA3aNHh7wdm4D/tQ\n",
              "g3r8nKVvPjq2w0sCGE3BZgWPOgIig4uCRnHqlYfaO4OE6ybbCBI5NOOpKi8er8FEFN2skYiBBpaP\n",
              "m0Uq1N6Y6hS8ZdXuHvp3mHGo1YlsCS889P0vr6j/5RJaOOyrR6alnJVWBw1Fwj4OZzfrH9H/4Cbg\n",
              "SQHR8BLfwbrKT7Bb7bEsPK4WTB6FrvM7tShS5eW6rRj5pWGEU3BP4dz8UVZVVuOuAkJlgyo34iTm\n",
              "35qjL5TV42NxZ77D+375CSJVynZ779TNOhHiHwpYqNHm6Jqu9GgcXwtiuJa4WU8Tg6zek6BL9NFe\n",
              "SZQEOT6KgGnIiWaNg3QP+TotjX/sfLJSuk4awamxUoP9g9jNUSwHempCkQzbgPE929a9bFC8AEKQ\n",
              "/0NGjlxSojCUJOMMk3Vnuop6ytmSxHgI/NyOWnqQZWYKIDhYfvMkghZcvTBWtNwaxzfQmLe1kdzQ\n",
              "O5r3NGnQXf3tde0yCoB/gAAABtRBmmdJ4Q8mUwIKf/7WjLAAAAbT5tD63rOMPoCc24KfLKAqkK41\n",
              "0qJqGRcZThtb19/+j68T5Yv1RdTAW6qwM3X2DZTKrCLBS9ZLTMeGRaErlnA8JgEa6QBg/5MuI5Jm\n",
              "Fz0s0pXrgCAJuLadegy0TAWC6ZUwjOkoJ+9Akt0rTeRbtoTqvjNQdtozLYz+NJ4rR2vJrQtQcXT1\n",
              "vxDvXtnGBlRG7vGwzOTaJPJuSpULj4JAJIvx1tf3PcbEnzKGeRYSfvpqpTUklzQf35fhGivccdGX\n",
              "59safHpjfZot8iiUah1X6//fspMhXQ5MwaX9BZTSgUQ4MdZcJqEUlhBXhQI3YlOy4ZObU5vLzXaX\n",
              "LflBeuCgHN4HrJvVp9hXagiOWrzYNgbiwCfkn1hbJse+1ljAy5DjKjQjDpfrrzQKrpq11MqayTDQ\n",
              "qJyE8a+xIwKoH81/anJO/e3hxUlItQ2wtk1O+b4g/FCzMcs8lQ1PVfU06U2kKSeXnUAm6BGhqR/m\n",
              "k/3zcoYuFzegjUfFyDm/F3UJWdExBfGEtVMKDnZkrNNZZGBYnVf2eVMpwbxEiOSV81p4xS90Z32e\n",
              "a8G//GH0GfXd0VgerNEWN0gnsQUX76WKHNWum55dt2LVgAcZcYe6VFQK64sr7YAjYH4VkHW6LsGc\n",
              "xWIcfe93d56y+vKc3fxezcMNqZ7ME36o9u8i9u+1KuSamn9nwpo/rDolDPyk0md6FDJF6MNkkGN7\n",
              "KnfJCKEfXIc6x+tbi+bguPXn8ZT3SuxTMF5LXrecyav69uPkIbVIj/P7GiQIy5jbOfnbFBcLuLWN\n",
              "SXA5/3NxTai4lIG077I4VPB10VehMA/B79qHODhYgbe/U786JHvubXSvS0ldCUfOcnqMHlOVvCQp\n",
              "+ymduEI7XN1npax0tn5rhkpjvLnKaGAoE4vpqIvny6iuhTb1hBwqVIY8RE+CMYjYYI9dM8AXmY8m\n",
              "zUGpgbjlKr78lKZCfdKHiDleGBDRSN0Q976qeYPtXYtL7rPZZg6wggPj0w88UCGhx4yQnJNEokLK\n",
              "sRaRRk4DkYnW6j/3KftNAn51VGc0jPZJCQi+blXNOj6CvYjjouYSgroGghR1A962mttZ0RgHZ1GS\n",
              "F7cGyhKLGaS76suV6GR9n7M0P7OnBjEd51r6ICEPZMOlnd+qk2SoJGl66oVFVGjHDCl0cOB6VgJr\n",
              "UuHUtSrd5hrnhekfLvqYgJ11Il/LywrSQHn6g6hoj3fqBiSXbfbtMqwPXnnoNEZIySP/GNW4NWHB\n",
              "Uro7mi0b2gTv2yCEOV2mdqBm6OU0LWyByI+853OldnOmtFCA0Q9jf6xNGbz7V5SYtRpMthLxsANo\n",
              "mYiIy3lXwXr9QIpIqOOYgZ0GJzn88Npu/b9yKbGNTvJ+iq8WB7V8ZRiwLCdsCeeCWyiEFuWqfWks\n",
              "gA+vBmv3JNikwCReeMQR8jldfENdCsmrb5YwwE2NPLXxd477vVsHNIuddRVOe7/sdjiQ7DLbbgux\n",
              "FsmRyF8gOk/h9RRNIz7FodoqxworA3AQWvW8WZ6ORcBH/waQA2CJgK2S+xi473Ma280FJqs/cm7S\n",
              "ZOP+ZZU6jPH1u0HiLXRNuYY4ByBlF4RzvKjSBF+uYJFSLCbvHEG27MqDQ3YX+NREoLX8GCNJ+I15\n",
              "6ztSNOC788wEwjkyzIoYYsV3v/ouoopJeeqJsArTFIOef11PCXNDd+po/U/dmfZQAF8sJK1NJhQE\n",
              "e55XHIGMJlkqjiN81m9a+ee1KtnxheMH6AsCZt0DhtEHtU+FSPiR2ZNlKqtaAmGTbPtRViTRzzRb\n",
              "BOJedbLVmRR8lfO9qZvDgllpXJPkGW12tieFalZGWr33R0mMcSOHPCEiFP7F+hWBvdjdosZ50VKr\n",
              "iqQd82ZOjxzyBK52bWo89FBL92JfF0d0savbzCE+tSXeHwHSk8MBFGKXdlfNjv7IVCpVNqL9vANZ\n",
              "0tOmz4kQW1hpywH35sO5i9+D4wGRZSBQMjd6dRT4zBZs3Fr2rO7l/fd7jntu2EaL/y5bquB4JUCS\n",
              "gsw5gLvle24nyZQqV9Be7OLHR2qZ9s8EgR0t2bEOe6AmtBewkzyvSo9tFYQQdp4bQYCAMQQjxQwE\n",
              "k9FuBTUMQZUqvYRXEOHj38QftfMbi/7vZXGmxf5nq1ZYdrYQo2FSi291wEq8oB5fDLBuSzRQ0uph\n",
              "tvIt0BzwncX+TuZ1ObyO3w3ks4mxpBWJL9ElrhhGXWl+LDh9662m7fe2F+gEO1fNfpYeVFZNwLDG\n",
              "D91bIDdjsL9/yFYtX/189uIlAiy6Tf8f1BB2g7jDOufaVf7SA+kzglb3v7XZsSZl1S60uQPMQtAF\n",
              "VQAABWpBnoVFETwS/wAAAwAhoweYSxfWR1JrADipz5Oq1KUrEvJEh7Ap6C4gjG+9J9Jr1IHdIvSU\n",
              "+D6Lo6ghgB3HipMuhq0P1YwTpdimq0fsrkGmCDbtt1Ry6y9zr4gzsWza07+a3J6EWOEr2OI4+95o\n",
              "Xyp481yTI79EFGl+YiLMxBzRluLEMwKn8ItutHuV5Yqv2OzSD3jrcLcF427U3Quuq4hukUXfog2w\n",
              "9AaJIyKsHFutk1u6X5Mok1WKstqxbGjIAWl0cOPAIug7kQ95Lqmed5JVMQlS59A7o97A7wN4dk2n\n",
              "iOXmw2ll0+uBhme6o88ZKqEkPKF55RPGa9Kgk6EVujxPGw+MZZO8c6yo+lANnktcjTAxYrpOt2C3\n",
              "JcCjFQHOy18IdDxsDMr+OwcCKNakZ0K1AC1/v5zb5G4QvyDpyoPSP0QhWTeiHSwoGoNhDsC61jdo\n",
              "8LbnY/mfn2gqvbA5M0KOfwxvUYviS+zdI3eQ28/7VlTC5cIvMjF5Rof1SCF+b3JiNcMUjhmjIf7n\n",
              "+yvzi4TyvWm7aKOadFEKRfFJU11raxF3gnLbGnsANDalHWf/WiuOQS1eaZDsDLMILlMYOMPz9nPy\n",
              "eOcgoVc7zjg0vC/ml6RyC4CfVH2dpNvobN/GzLf14nqvSYuIU+kFHMPxoEuVw4pdCGN+8w6ipz4R\n",
              "jedq28tVw/MhAQAdxB641eC/oVoEugX64olfAz+pIMLoBRUkzSYwoLC6t3plhp6iwpInFdnRm9WO\n",
              "XXISjLw7aRNVdASTQob1P6DycNEmyLtUKrGBFFR0yQPg6ve95WcZUD8Gprmtc34Jta8iE/nU6kdg\n",
              "OH0SIaC2nI8CtRmf79nbfJT+ddIqx631ovMYHKq3O1T2muGTp8eC6xJSEvaXaE91bFwatWp2nzOX\n",
              "YWhP2TVlP3OxqUn/i/d80lXVW6Pmp9EoSRCLQ2a9FOtvNti3MIhYYGJ7TwqqbCaMgtLWhbIihWWf\n",
              "3OZklzqETId+XfRIcE9/r4VC1BVcZS8V4BvoGsXHDTYzhEm+ngJYWLHprgflBN8XVIcpmjHa1iXn\n",
              "XMfXWinz4cBT7hgJeJXWozxwgVRMEdDvlThw90mnvyO+XxIF4d5BfVTDpiPttg0Skmh/4jK8ZVuJ\n",
              "BteLbuIeozHAq7CfaG9XPLYNk3/3SKcqmQUUd6/Lrcin2I4f3rmMiz9g4N/CBb4BgXimV0VFSaCa\n",
              "sVvfJHVHfbYqq8KjmO7BANGXqFpxWLTes75H7CQi2+7F2u6pKHEB/EuBUoB7atKsE1WsAFmxlAO9\n",
              "GOvyDlGzTAeLFhzPdJgd7lVQa2XdtE/EClWU/x3qPiKdIPIuWZ4WtJc4dUEhfcF+Z34XZATnL77n\n",
              "Eltz+0FsMM7AVMKgXfny4Bkp1jU4TIfJ20ngJfr8WkMpd8qvSdUm/rAYT2ia19z53hO72IPRI/dM\n",
              "+oT9EA+pAIA7sV5n4GxRB2HNp1QxAXlAhecf0QFFMiSTverhoviBgNx1Ak0vyMaMsyu8CczqYbad\n",
              "bDHtU3mDyKSsldcxEY1yXGF4X8A238BCbx0DFP2IC6OaUTzU120kq7pVwLT6o7SzbwHj0AB/kxf0\n",
              "KD+/XKHvkzPSYZoBrDw+0g2HST86JL/L+VyClX0xuu0wMHoedakTpyJ4Ba7Qm9a5eByXwdZpUzdo\n",
              "SVlprqX2PxKeO5uL6b41bNHXQghhH3EPnEB7+ea4IaurA7HapRQ5ttadBhPOuMuvBm6QwnZWwit7\n",
              "TVjZOPskRBKSsnYkMEArSiAPijVGT0wf0k/yTX4O/4m2x6upNhQ+9NyALgddOYBbz2Rr8sXT4okM\n",
              "2UjlTqHPQ0w7u8Pas1gWcMRZ6BtuYoEAAAVMAZ6kdEEfAAADAC1bS+lhSmWJMx26gAbhlBt+IgmU\n",
              "eoTsmTzlMTS6IG25oGZkZGzFX7ElmeXIE83+aWpkbSunbF26+mDlYW/IfODDEoUwsflh832Xe2Pw\n",
              "Uc3Ww9ziy2R/EdOsOMOGXCTHeCUV66GmFb/KCkRVYpRwdf+5V/1J2VKXcE+Ijm7oIfIkjBiO+0ZH\n",
              "1wNdTX4miMn+FpWYJn3t+xD0WyR+AmQS1WxNe9B8eSloz+dkrueTLEv492s3JHoJst2gGtPYn3vL\n",
              "w9K6uthWy9+RxRI2NLcr0P7M+DO1pTfAhp3Dl5cumwQJ40pbnlyzivMtV0H1uorWYrfBckOM8Lw3\n",
              "YbdWRtlAWK7PJ2B2emMFRr64r7Z68aR1RPrgmQIxJ0v0+p/MjMrPN/GdaFfKNf/U9v+uj/4r4ib3\n",
              "giDxtPpEZdjuMpTEB4m35+mzTR+krbcAaOqNywsSnlYdKjkzvYX08ZapQVvLjMe3TT8gnkZvzbZ1\n",
              "eeyCrqWo1xRbtSEcEN/HEQhIufeS5soHSlaTz0Fdf+NSPkVE1MaH+xvC9hMEgWFb8Wj8ibglfpaM\n",
              "gJWrqdOJac2AKa+UwP2eP707hfqk4qfFdcK+h03LRLMy+Z+1xBdgUBYE6VKc6BnsDlKM+rbYh4eQ\n",
              "Y9lVmuBJc39lPkozbjrPrvjK8bmf+6ByZdNhOowQAZgxoyv7U4C3TeGTxVqA4ddrKs/XNZ2CJx3u\n",
              "Jb86KOnWJFL4/vkv0dN6P9OyVfirXeuIsYB08douLZcHkyagLOyVrIdipvzNGcI+TrAk55OPSSmy\n",
              "f6JWXxc8Oa8bfe+AbUGHukOpe29k24bH8aXfDIMPKVvAu9N2q6pJiGCz/x8a9bLhrm67KJTQT5wx\n",
              "P+M3EszRYdvBky7xNDdUOc0BLvcJ9QcerXQKgfH9AAqxI5/0Vt5RD0v9kgvK9QGL1WkH/4sdnu+o\n",
              "KVuDmquWM+Ul3BFFIjIiz6VXs7TO+6s525FmBDBrT/lau0K3NBtKtLlwvnvgg0jXv1TXjTu+O3kS\n",
              "ed1SCKDHiofyNTlOIF2vuCmvLhTJHJNqKOPPnWIhKr7nbjK/3CVRfvbdCirsU31D8F7pZmnVKeNB\n",
              "ZQTT+vI93DUY4O1MgltePFUyYKkVnFrbyEpcLjGVrdF881KDbxtbckEVVjVe2oJiNzdkmiHhwZ0f\n",
              "jAHcsQJJCRgUL7q6ko0+nro7Dll0t06VUp5ZPae98gxD5332cpkd1mT1BKb97wWKGvZYAsxvSq3Y\n",
              "j+lBkBVGWSSKRwmZP18K624KSR7ZzdsvR54lxDAjpuNYCgHK12i+tMMbFKpg2P38aqZatMkYmpyf\n",
              "kpi9aFuEewCgAxHmBuvqksN96mfbKqvx4l6OUDPXwH5IxMaXcLB5vljJOOLelOxcGAkVZwvn5lF2\n",
              "TvbAhG4LoVmeng96+cF8T6zSBggdVZbe3nRKYJ3yb445lsXI1cd4da/HhhCsSCS8JVv0rla6GxiC\n",
              "YO3e9fiyoQhF95oKNGR03m3qn5LS6bKkyCivvHjkZCZto10Y1zE+VsDRtSzxNTlRYHx7o2C9lzhB\n",
              "0Wqla54CjMLbPyr7+6Mg2uWgwlBKtF10lm7NcO0VSfKd/r8egnWCP4Iu/09B9i85275EnMrK5G/A\n",
              "1wvrmQLWCaAckhdga+Rdwk2Z9zs61pa/IOv+Lr+7rX0Iex0shXbusTcyteUdyFgwn0dX9QDEwzFO\n",
              "0at1xbQYvf2kPK5RRq1ocLezu06gK+OEqniJ5tEtUS18f8t/gVgmdesxanmSfW6S5ihWlrOp11VD\n",
              "LbvH3KfBGrYyodMFOPSBAAAEygGepmpBHwAAAwAtX0hr/3kBDWu079YBEVqr8AD+EYZfebNV77mx\n",
              "r342UxNiwEhrQUwYZcbsOOC874mK8K6zxjP0HHZ5d2FEwUNV+Tyol9VIcg+AwgcguJXHlTW8Iazs\n",
              "IV9uXm7jZ769jYZm+AjW013f1zt1ablz/0Ygtp94WvxRHF+fcF5tnv7tzfCS6NDZKKZteAPkYYyv\n",
              "4pHnq41fKVwI+SIrozyVN6rS612jkf8RVGa4nzMrkPIfI2PvY2qRdNEfjjDPmSlF+fVCkcVzBJfD\n",
              "3J2nIkB6y/Awuge4LplgH82QsxyP5m8Ly+kWkOJaglQg8C3z8d7AtHFKCLAZiLzk7SwCpNa9NNLF\n",
              "SPYun3jt3LzFLBOSG/h/sepB1/DhoA81Z/KDMsWouqzlpymcpeZrKs3+2XSquQjv5UgUPvTrkfvg\n",
              "9g/57sNhn1hdedWssIHZIJsmunFKo7Qan8DioOcR7rnyxn16H8MUlukqRNf/02AIsYePcLBUbplo\n",
              "4dbQX5lOlYa5Ya41czNsGTLzNdDayfL+e+HYQFLawWQAoFZX2PGjPArGv6xLjrlTyKBg9EqkWx76\n",
              "LQGKkAqmuFCHuPGgTfSGJkNU+HzPc/K3xBOyHLfnW9aRSewmfs3REp9730PLdM+/HxkMyDSf+8/R\n",
              "dSqVmap8vPhInuIqZv7uMeQ8g8XNRg6tBo66Z0KidMa1bvPhvuByGQ+XcNLI0aLqganOWTyVIVDo\n",
              "Mn1qyNRzy0ZrFEGFRGw2qSWmPcPsazQfBDcBZuOk3b8uHnaIxvBem7a1yjRj/z82RhBJRjNfgCfr\n",
              "w/n7slNeebONPkuyXNl4J6VYWAx9m8hujBF9PlF5LNOraWkutk/YJjeIw7p8e2sf3n2/GEciL78Q\n",
              "xXerv/8aR94zms96IZxjPVJxR/rJFGh1eDhQbXYA9Fbeqt3zKPBc5ijvW9KTvhcsnOXfUOVi56rS\n",
              "e86MVYRn5Ka8n30+dxUABBxU4WQcyw5V2Nf50eGwh55q2VWlGOOBzFMI0kaVmUSE8aTz7AcRixd1\n",
              "fVwf2D8A4NreQ3A5OiURX1g1b/OV208N1JIndHU6Znwlrca2/SF8PUHZERmsekoS/QsoO39d5ys0\n",
              "NwCEwMyMuqwGGwwu88CvarDwqdsoBA9+CF/nIB14v/LoaDV7KmlVLMYTbMp2V5ETs5cjTL6KzI4k\n",
              "n7telDOnkENv81upKrANkUe1i+gPmngfe3dPIlvhQEf/qgtIgS/2TDXgUTvPxW8Rn812R5rUJHqS\n",
              "IVSj4jNqZcRx5Y6HNCfOMZPoBhxDhay5zK7JtBEW0G6rRN8dCFSPhkc9nPrF+wavAo7j3vA+lJ2e\n",
              "nko7c+sdUsEv50V9TXtG+jfhW/D7BfYN7/qv57Z97KTEZ12cfbtro6F9AqiDNQXPwEwWNZ6ZO+Sn\n",
              "iH39Amja4Wt8fI/MpI0UM9XuI8rxydn8NtIC84mQDKHvU1vckT21nWJ0X7a1XGhGruNujR/vo+dl\n",
              "PLH3e5EmL8cePJ8EwneH12uMyryejuME6iwggRsFKm5NsWr2IBTlBLdi4i875d5e6tI68X19c30x\n",
              "wAQalhKp+bq/e1FQThQszc6NbmV2Y9XMT4rF34U62QVAog4sTb52rJqsEHk+hW+BAAAEDEGaqUmo\n",
              "QWiZTBTwU//+1oywAAAG++ax0eP2vr9aRIkGNoMAVKmOCoAf+t7Ai1GktUdo91j8n0Gdwo8pK6ti\n",
              "lk14N7vTBAzMausnl1R+grLdpGRPupUXECg7MNTlGk5mQvJ8hYsc76Mnl8p7Ie1yq9VmHeOT6BmG\n",
              "hgMhcQAUatrf+Wb5Oa/mLUHG5BDWwv/2WY4g6G3D/8TnLLeH5ZVOf0UbpJ4Bj6MFlaM6+LBP12qe\n",
              "DduqqF334sgv1O+VLu5gxjKNaYlKuI4/ezEKcIIWjl1xQB3WmygzpH9Im1tccW9Qi1tuPWePaXfp\n",
              "RZTMNjZOEBIEBPbkyIlhoTOf6Kb4bFn1j5FZwMe84+/a/OjRZhzM+t8/fAWP4bahJhy0MqzhHUSL\n",
              "OxMh/cEXlgi39V0v829rAY7t9oJpOj02IDHXN2SJaQjP/LtF0nXqR9Ul1BK515DtfkjYwe+2xFQt\n",
              "gTTnZfxCW9NBrrkGV02n2c1+E0+YEQ4JMQPT5HcR6m2pEzTNLuAi54vjh8bhHGLZkJgF/l4X+nBi\n",
              "F+mVQwaUjoGYFNJalyfuFvJ0qAHB7TCa0nJ6qW6/4MqopT14OeD7TUuFecMk4Ae1/fTaBpmuIBbq\n",
              "VWWKrleHCTaK40Hr3EGC5BoKOfXlUyKuYbCA8rJY7cmlBq6GrRlEN0WSOmi/gnJnQO6/Y+qVz0lU\n",
              "ArbWldhiXcCxx0A9IqVgYb5LYFuyg3TZKmY16Elf0MFewfg5XDEYlT2s74bxOucT98Ax1zAv2Q8x\n",
              "lLAJ4Nq9vZS6oldLoYqe6QkoAl5321X0sDsigZoYm04O0QGuTc3KPf7GzGc7SR1+gLn7OPEQcJb+\n",
              "2lL25iqO6zRE4rxdsgyPcSxc59M9itydlnz+2JpiwUyk6y841/B6EO9onbF/QMKoOmn7pKnX9P0+\n",
              "ninHXkv6bRMvtqBjRcyyC0Merkn3Fp+Z3zRXg8FutDpM9quNlzb0pC/A5vyrhp48PzzXvjWyaz3c\n",
              "/mC+pExGDus9f4HSubQ/vkYtCeQxX7MNkLtPwPN15VWPB/NDx2+p59t2xtbE8rz1WnBQGSs54n3W\n",
              "P4zzLhFn+ECRg8/QuAC+Vh7eYhX+7tYR9Jk0QYVUl8xFKxqPvT8L4B30nyDOMy56qtSYKpr6xaSX\n",
              "1ofu5tbSmwuSfTh1KS/gA+8du6qAsVpGI34seBktSmL2tAXwBzV//Q1pAtsY/Z8kj+fDKqBs+CWU\n",
              "D20Jn4PRNOgKaGizodAtNBBfNOnAt9GKqp+PvHyRTHMhNj4ej172IdAZX6GchZDeBTv/m060J14A\n",
              "7WTpCbqbxV504ydhQZ7ZQvsdSMuZq08eMmltdmfPd7V37VYZxz59Iqi0BAZFB6INozDfG+wvhl7y\n",
              "dJ/9ccAAAAA9AZ7IakEfAAADAC1d3V9iyhFxLDncv4NAqsZBxmrdpNvxvkduUtp3/HjIdLo0/wHy\n",
              "KdggZ7OEi8BNanRXwAAAB1dBmsxJ4QpSZTAgn//+tSqAAABEFHXtfD51J5YzLPPCjH0dWYhNmQAV\n",
              "8N3qcV27uVwbBOz3yo0p9oyfxTGYeF1WKG6rH2d33q3X17CEoGRT7cy9/7mPpf1ZX/HTvJQ9+gsa\n",
              "UBilLvE5slJgz31vmjlVuYyINe9kqgTXU+1pZMBlK0flYOvVMxa6gg45jJHRvszJC/yoHmTWp59m\n",
              "qGbbC8V9/cp3PNCzLBW9/a8t1BVB1kIdSdC023S+U1wzPGapl1f2nsuGPosMfc07cwtGEKZLGq4K\n",
              "tzYoiHs7EGYDMbJVHJzilL6D12qtMI/W4h6DE+/bBgguLSkpGILcRFw/tbLEi6tQ4EY+Qu7XyG+u\n",
              "5gHZcbikyExaViTNlJa4e7x2N3Gu//NO+Ffu+WWQRbnnMjf1yXkRVL2LwSPwRWdx1El/Oe1FMv+D\n",
              "w1ygob2xuCE32cCzS54PgLCexrK74aFgyaduqcoYllwjF+awu7ZRXtrPubmub+dJ+5OwN8ifGb5m\n",
              "/P/ekOIPfPakrLAuCz7z/FvUUWmbrC0JjXG1IaF/sp0gnUyRU3sLX84uajMpwhZL+NvfyLa6OxoA\n",
              "kk6bEe386Y9Bj3eXuSHTKFJKyBsRQ894dfJPRIfqndaLas1/5g8q62B16jn2Bk6OrRdPiV5J9Wu3\n",
              "h/PzVy4yfkCC8Un5InF+PVdo67A6EGrDTN5prN7UEcEoI8y4Jq62/2Ezb0Q7LA5v81zXQp9D9zGx\n",
              "YrvH7Iy33TPCuM0/CGSUIj5dqYLUcf5GMeKSWoK8CgYteTXchkmh7rraSx6SnvcTJADxKjuTd0gp\n",
              "6OzBzsAmpdRxH2ZRDbV+pU1vB8BGXEzbXEHOWwEbJinIUXCfSZUYLg5tNYbNWZea1t1/oFYgnfF+\n",
              "pj+MaWqnWIag+iulWMOCQX8MvzcVfNT29euqgSc/NY9qUBUxZoyUJGGejtDxPD/bd6McfcyUrP+k\n",
              "Mcu77fjbP/ffngSXp+p/yvD0/U3sK34IFXZePMUzFetbjN6kF2WU8xGWI4bFOV4vIAQZ+LiiJdaB\n",
              "oQdBr9l/7fCwNpgu5URlJUwzJklYrZ9tHHIceZggMizh4YhoPmoTOUiJ3/SBdrWd8kZCRdmU+zve\n",
              "dBOG89tiB7nPzWDkGGE5JdY2hjv4gCk8MQE/VH+OaRmY3nT207tCLcrZ0PNwYi80UzloVarwd4oc\n",
              "QFttYTKXbav28mxD/2/NjDJCNgEGiF6qBw2QBWlaOHczHogS9FIMQiuLXXzQR6mtcJCw1yfl+mLB\n",
              "zKs+lj7mglbvA1YzmmHUx1rqIWbIS1kaMwLucPT/A4lht6jt54w9+jvyLroAbLSCswQaGWUcU0Z2\n",
              "n0deZGJtckO9fGRZwc9SRX8BM9+iLbNMc38vDJwCW5K6uN8cFukB699UYIGUa/cF0Lxd/6QfsOrf\n",
              "jJau977on0BRDZAAiuzS9D4eo7QTh9RRAWbBy4hn0k/65hxf3UaK+0uoEX9fLrzeChjuQDZqfKAJ\n",
              "fMtp6qOjltpomNyHMs8u5LVZvfhAMQZTtPtRSdqT66lCTnia+3ZxVH5e3D8XHIVMhJ6mxzp8sHey\n",
              "OE6CALO72d9+7cLBqKP4QxxPhx7gFdi3SjSIxvbxqembU7N4z5JxGULznm+cEepkxNkqOYBOujsf\n",
              "829MWB5hsvRilXV81wj9RuVKnhDoTQDoKh/bcx2HauzFwgxx5nMhZ79NUTc//mdiTqcyUmRnaU0e\n",
              "zH389UxtixprAfxbpgxmWdxzFgXipnEQqIfW8aVSbHQdguBQ5NSk+Oe2nbW3uIWuj5/n2oJBGKoc\n",
              "HNYYFrzcrexQSDV+ESp38tsXrcYeDD24szZwsav6ucm9trCY/Wk0KDsRGLIVwjr/0mDCKBS4SIG9\n",
              "uyQ9ZL/QS7/voS88W0d7/GPDsJo+AYqvoaR0oZ6MvryTRabHK4qtzNPTNxZHMHph4kQQAbjC56Oe\n",
              "x+0MInt3nA0ywqhUZv9ADqpvMLOkKGl9mJxyl2TCNZJaWQELtCzY022DSSms4fVq29CCdUhKddPu\n",
              "rwsvuGrcLO6Cy8bs4ny209/oSvm8oifNPZyMsfqyA9LpnVGm0ngK0V6jMH8h7XQBQFXuHOLQf+dA\n",
              "USbMzWThKhYtBFwqqSWGc6rELunsaWe1S+8gjxRaJjQQgRe1XVO8tfv2xglBS2sEgTK6F3WYPig7\n",
              "cHlAZYpK3QXZDEog2t4H4XR6W0G6Y4WD13sycowWUbQUm1yqd16hX5MC2YEffEhRM+88s7nWc+vg\n",
              "MtJp7AuEKE03+hXebf1uVj0yzsw8um5hhmxT+WrG6cH15XQfxO7lpqgeUfGh39QGiP4rNRfN1Flf\n",
              "5C/h6A40aqShSE15DaQtWam4Brwvp1BD6eKHmmAGCy4UpWmaJ7odI5nX0MB/PopRXlflPfSu8IBk\n",
              "ILds13PPsOxo/52IO9hKAk46jlBCyZQeNsbAKD5Wr0cEEkGnjEb7UjZaLxjGBPJKWyq7z97nXL+5\n",
              "wc5eFUsVt4v4NNHwAOqBAAAEqEGe6kU0TBH/AAADAC1cqAmhRiA7eHPw/yLYorDjvw4AbsN/YS5J\n",
              "lNdfJyZA4tnhjQD2ekWBCuTvIbXyJhJtSuyoXgdBwQKjR26NU5V1rNOJHjCeI552cG/M3CCQGyny\n",
              "rz3uXotpZGOY4HfnGXu+BDFdWyPHUoTvgczkpOKiRs8jEOGl2d9oYG3tgtxTIXCBSYfIj5ZVb+O2\n",
              "OlMsjBReYGqlbnB0aZqLImhTr5+rw/R9rPwcMR7eOv5uXLvizGHcZGaX89XCBbKkv0Z4eSKmZPGN\n",
              "tekYMBOeYvK90V4CtX6X/dIlxqMPQ9zjQVGenMp4iC/RzDTrR140f2Tq9GFYkvgsyio9/S+/gftL\n",
              "8R4EmWYAUeOyMgVHzdw/JWe0+qL86LA1KP/qhH4qRywrRctVGfqeNASvxqJQN3BFfF/fi0lP9EqO\n",
              "wr6W6MM6H0pHBc0Nf1gmusk77fEaUTd3HXSRp7TBvr+OPQqHJjZtQKdhhg8ZysuB2tAFV55v0QWJ\n",
              "SyTa42LsIqWul0aKsN2ZqFMhSD8bb18Gp060XGQbR7AdlGWbk5MSj114yDwmyFAcUfpywkP1R63+\n",
              "st91gSzXjm4SCSYFcUyDDldAqxa6l0fjZJoyP+Rrq9BY/6wbofCejk36c3nS98yEx9un9fAVVo39\n",
              "G6u/WH7giEKb/Bm7sF2Ojrl6hDHh+Gn6Hs5+VviX84w3Z3t8SycXThU42P54XbWtOOPoDmnRm8pM\n",
              "YOw7cT0pVGSQQRm+MCVcWDD4NGm+0sn9BDwVsgBUzXf+KP/h3PdCo8VxiyRh71BfjE8MPa829ESt\n",
              "cLdg/Xk9njOiO0lVKXxZ8cwEgAS6v8QSORVT94gn6c8r/ObE1slYdElLZsTlf8hcTgiMLoi00tCJ\n",
              "M+h0UbdhYsA/vDS1Eo6OhoiP8wa565kxcVuBtrFzVJhYev95+oNOwQA8+2a7Ml2uYL+Uexh+Xt1A\n",
              "yOI3IEr2/PtT5Pb/GupuhvVVjxwRQRTMsmeL1dixfJ+p9s1bJmdZjmGy21sCJ8i+SmRfGrLmrOaR\n",
              "AEG2Q9ICJOANBjH33ThQ24bgrNjhDBK/NDRzMJRPIWAn7uDwNlJWUFO3rZ7htlNDb/5j+cOFlbbn\n",
              "PiB8JT/G26TcraSsFMx6upAqBV75QNYLocxuALwdKoIYL8gJJvJ2rfvXP2vRWY3chH3jIynseqEV\n",
              "YtHu0kzDzu7bIqHzIwt4TB1SYpM2H/hUTmH6kVuid9E5dSLGaWOwhPXhBwmaQOoP6GC7kGZktTfI\n",
              "MxjVI8Lr23kOY4F4hpTOUS0JGcF7icye6VcYImnDrDqcnbCZyyfdxCg5TSxIV65cq1JI2/MIthHB\n",
              "yFdWWc8nzJRRhXx6I57CkP8xQ5g4+zhHLojUMsqdQJfudOWyDaUEYRQiR+5S+rITcTMKakAyR8Cs\n",
              "5aBfupM3ySiPfqrRMk/T2h4dRlSeH2nVGywWbcEOqVTtxLSfT44TM2uswhG11cVceRBpKe3tT+EE\n",
              "FQpueYz2w9RIE8NoBXQqi1flvgsfF6oLMGNpSgAut62r+IEVTuuROcGB0gQr5x3IhC+6NL7JUUoi\n",
              "3H0wzte0OY5CxLda66AAAAQIAZ8LakEfAAADAC1fSGwig/jIY8wAKx9mQNSf8ThTKo50Y9ZRXxSx\n",
              "tD8wj/7xq+66OR6l3UlZkSKbW0n7FaMz1//jeC05oVKqtJN2YMvFaeSznpKlTUy5mPC+TkVcOIwR\n",
              "SDPD/GlYByiwvbZKWELQqNLJpoz/yLLSz8H21C8xkwTk5UiDAF3OoaTL3WxE8K1SukqXQx9BZUkN\n",
              "zcjJ92BPfl0sNsfLilo9zOaUntXgyKtjX3gLInzmMsoYKKkNIvdP3hQI1CJlbQdMoZ18T6U4W619\n",
              "oQk6/4nqmiYKDDYMFcaXu86KkQ9D5+xtleqAeF0P9oD9Q0r9SLzPO/HjNrpdbwZVqj9qFb5tWDmh\n",
              "/1na1ShmjxLaMZFf++IYSBiXKSgkSMD5Wm/mPVXbf18c0/ibQ0sqBRpt7pnBVV/mhKy87aA1DGrH\n",
              "3s5EeQYF8pJFAQqwmvsyVPRqHeYnm1by/M/5Ue14gQiJ6o7W+/b8/oExUMa87IuXESqyqLJo5IzO\n",
              "0Qhh/A05OdFHp4kKS0SqQwLrbXqlAJxjLdG1MdIYn1KyO0x61tCSlxnuELcWw+9vPYUkSoTC793j\n",
              "u4IXAXy0ZmyRNqH4BKG7W+gnvFM+1+ADECmBQqzZyLRIN1ax/yZgKr0PVKH4QVOfgWr123OBID0R\n",
              "s+OBkouLfIDWaFE/AT+bv2nAj9focz/bpiOkgU4yqyenTQMb4w2g/40EPgqgaqVTmXgfZKGx9Jam\n",
              "l1y6Cyco8kYg7wNphAHKyPPa5Hfrl7moZ+Hq5kxE5/oS5MJfycyQjgFUa9AhqgRewzm5iEq+lBzN\n",
              "Va05DVKWv/arOKGs613jE5EDlDaUCP9HoN2Z2z31fYO9A15TM+PvXHXnLZiwTgNluTjFGPAox2qC\n",
              "QqCiPFZOKPfSed1t69tx07hqet3ObY6ciEWuWxEL7l2duKbWCQIIGOwkRr9Poi9ywMlSZCMwb7FA\n",
              "r/UNygZLLpfUxMhHmNHHaMb0ldAN71VlGD5QeTHSaGsr6mNxiKbj7ecL/ggaPRS/EnrOs0HGA+/8\n",
              "me/lBg+XRUONhEBXU/Tti59mUlAERtph9VrGqIVL38UEgYJ2RNJUBr9JsA4jPYHZH0zdWhcYlus4\n",
              "YFAJfbFbghnD2lN7ZnF0sn7Rew0kRoCSZp1dFnkEflVLCItRaLX/WMqjBBjw1XOFl/jFu0tZpuTd\n",
              "L8gO+DiU2hiI5Sy2avtMtTseiM8Suj2Kw6ZmwGGSIlMSixshD+Hn4FX7oUiDbG2bgPqi7lXJJ4//\n",
              "Nwkqirv0sjA6INxUNSsJEk+1Gk24Yt6BOZoKNOiabVrnPy35/qyN8P5TtLB5KWZKZRpL1ZiECvhL\n",
              "MIXr2plIb9AViwTihfabCYTs6eE+Ki2uAAAANkGbD0moQWiZTAgj//61KoAAAER+zdQt1W+XyqtF\n",
              "K4SQJQNLJYg6zRgIPGGAACWgBkERPMACvwAABMpBny1FESwR/wAAAwAvIW4XX6iWPSVlAAt/95YK\n",
              "SYqgolES/p0H4xPIQt0fd2Fr5dmvVntS5Ad7Y30FO0QNJ7fk+5UZ8PbJ2fCPdG+4FTI9EHJf2IOP\n",
              "nnC+3+gPoWm8eWWf1qaFSP9cZuhZ7Ur50I/ks16MDrMEAYFrEcfHte2HgL11pSFZ98j34LjZ2iMk\n",
              "B5rYpFRwGeRpeZJfZnv5UkK6shx9YePxU8l5b2ocW3WrF0Qapurv5QD1giHtdoKNrWkwOXA7MAtt\n",
              "6KmJ80QKm81LYkBwImLwkXfBX4efx1q5G1RN5L03j4r8GlKN4DjS4hqy5Ka5jWhV3svTg0+6Hitm\n",
              "a0ruIjGbYD/hJLOOxk7PJi00BT2v74e5A17N4u2yxjoE/atFC7BiLYn1OtSodwtXz7TH4RYZcEQl\n",
              "oXa51a2EWWXBLL4VTbMp4S2IMUT54+1uYkILYYIiuf+e5F4wFOAMJu5Jt8MoTSxV3+mpwS51f1Kg\n",
              "9XfALYYxumV8fJXtd66uEJNreNSjDGX9xkQ2wq/GyCe7i1+Ne6mtkm+qQqJx6dTjFKBj0QgAZ4V6\n",
              "LrhJr8bAvGXwWCeOU91Ny7L/twkKu7y+j6SUKyHMOiQN/7G8CilDcdRpKbe8dVSCEo1HgakZwfqH\n",
              "VdiPsWg47Ehf9Z4921exetwByrFKgL49Xq6on7jNW8fBvrACA6KLwRRsAKgEkRUldJsXPiBORBqX\n",
              "X3DE7xUOn2909tueJ7qbjZo3L2KSzJaBEuRKZ7gQ9nqfCirFS2mzvHbsgx/2gTEi8Lso+dNWCeau\n",
              "um7359RVXH+92zXEOlOnSqWViJNxw8RNPo19Zv2wLVii0FGzETLmFcOOcE1p6oppWJp+tpN3WicR\n",
              "rVM0kUFR/6U6nFtDiGpy7nwlwwBnAxevVkh0qoUBuIlrwKFPLcjyjc8xOzenmE6zMF5R5N/r/JGd\n",
              "wz3rXlLKn/RbWFFFyBkojaC873qgZeqP/pIfKYxaeoD5x19tYf5sIa1uUHa8G9CS/6Eqk6eNjcAM\n",
              "aJGtpawYvpSmn8hNPZq1VTQjRjdBaTQ1RDwUZdq4q7wfH4wSolE5XSBST/1k1vDOFMV3JrZztF4v\n",
              "vRvCxcsUWlTax6n/HuvT9ZdqdaXGTXH9/Iacgf0pREKrcDkNrb3Bfgq63ngVHRvdlAi57CFdA+ss\n",
              "MNp3onpOIvOYGKVtr+/qNIlj5CGKsCadF6Rgo0N/Pdle4qG23tgdlHnIz3kXfpkLMpfl3v/cIJZG\n",
              "0Gle/wgshoP+g2iu21ABekFDMUqIA2fi98e2Cl7uhJFeTzkr1gfwH42CnRwiJTL2TLI+eUyo1zj2\n",
              "PUxHA7RYkeJ9esCTSvEp6+XVAAyj8voH8+REA5Xl6On2x4UvfSrUEtmqZhyUZnDXMi1NpmyCV0Mt\n",
              "xDLv7EpfJGVCVl9Tp9DAbpESOQvvqCn+wZfEXBT63aTyaS4coOSy+Rjam2ZWKTUO6orrBlqZhSov\n",
              "GDUEKd5T6O0pUOHPJVwvqQfdK/3wABIQUQH41Sbt7+adj9tCxnX/HdP5WnTUnuszEwEQXHNvOEJv\n",
              "VtpK7vANGQ/f24aOphqVMbHHgNxxnjWOazrn4W6pV75C/fIvzmiuKB7Aeasz+mHjppM9VmYENMbv\n",
              "pQAAACcBn05qQR8AAAMAMO1sxACnzJpvPOBIIQA6GAEyT7MPnUS8GlAAAg8AAAPebW9vdgAAAGxt\n",
              "dmhkAAAAAAAAAAAAAAAAAAAD6AAAEsAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAB\n",
              "AAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAAwh0cmFrAAAA\n",
              "XHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAEsAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAoAAAAHgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEA\n",
              "ABLAAAAYAAABAAAAAAKAbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAwABVxAAAAAAALWhk\n",
              "bHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAACK21pbmYAAAAUdm1oZAAA\n",
              "AAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAetzdGJsAAAA\n",
              "s3N0c2QAAAAAAAAAAQAAAKNhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAoAB4ABIAAAASAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMWF2Y0MBZAAW/+EA\n",
              "GGdkABas2UCgPaEAAAMAAwAAAwAUDxYtlgEABmjr48siwAAAABx1dWlka2hA8l8kT8W6OaUbzwMj\n",
              "8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAAEAAADAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAIBjdHRz\n",
              "AAAAAAAAAA4AAAABAAAYAAAAAAEAACQAAAAAAQAADAAAAAABAAAYAAAAAAEAADwAAAAAAQAAGAAA\n",
              "AAABAAAAAAAAAAEAAAwAAAAAAQAAJAAAAAABAAAMAAAAAAEAADAAAAAAAgAADAAAAAABAAAwAAAA\n",
              "AAIAAAwAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAQAAAAAQAAAFRzdHN6AAAAAAAAAAAAAAAQAAAX\n",
              "tAAAB60AAAa3AAAGGwAABtgAAAVuAAAFUAAABM4AAAQQAAAAQQAAB1sAAASsAAAEDAAAADoAAATO\n",
              "AAAAKwAAABRzdGNvAAAAAAAAAAEAAAAsAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAA\n",
              "AAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1\n",
              "OC4yOS4xMDA=\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6e0lEQVR4nO3deXwV1f3/8fe9We5NyMKSDUIgAgIimGACMW6IBrEi1q60WqFR8VsFa5t+24JWUrUa21rl20JFqdtPq9BadxHRKK5RJBBlR0RIWG4WQhYSkpvcO78/Yi6mJJCEO7kZeD0fj3mQTM6Z+WRY8ubMmTM2wzAMAQAAWIQ90AUAAAB0BeEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYSnCgC/A3r9erffv2KTIyUjabLdDlAACATjAMQ7W1tRo0aJDs9mOPrZx04WXfvn1KSkoKdBkAAKAbSkpKNHjw4GO2OenCS2RkpKSWbz4qKirA1QAAgM6oqalRUlKS7+f4sZx04aX1VlFUVBThBQAAi+nMlA8m7AIAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEshvAAAAEvpkfCyePFiJScny+l0KiMjQ2vWrDlm+6qqKs2ZM0cDBw6Uw+HQyJEjtWLFip4oFQAA9HLBZp9g+fLlysnJ0ZIlS5SRkaGFCxdq6tSp2rZtm+Li4o5q73a7NWXKFMXFxem5555TYmKidu/erb59+5pdKgAAsACbYRiGmSfIyMjQhAkTtGjRIkmS1+tVUlKSbrnlFs2bN++o9kuWLNGf//xnbd26VSEhIV0+X01NjaKjo1VdXa2oqKgTrh8AAJivKz+/Tb1t5Ha7VVhYqKysrCMntNuVlZWlgoKCdvu8/PLLyszM1Jw5cxQfH6+xY8fq3nvvlcfjabd9Y2Ojampq2mwAAODkZWp4qaiokMfjUXx8fJv98fHxcrlc7fbZuXOnnnvuOXk8Hq1YsUJ33HGH/vKXv+gPf/hDu+3z8vIUHR3t25KSkvz+fQAAgN6j1z1t5PV6FRcXp0ceeURpaWmaMWOGbr/9di1ZsqTd9vPnz1d1dbVvKykp6eGKgVNbc1OTDrvbHxkFADOYOmE3JiZGQUFBKi0tbbO/tLRUCQkJ7fYZOHCgQkJCFBQU5Nt3xhlnyOVyye12KzQ0tE17h8Mhh8Ph/+IBHNfOPaV64VfXS5KyH3xY/QclBrgiAKcCU0deQkNDlZaWpvz8fN8+r9er/Px8ZWZmttvnvPPO044dO+T1en37tm/froEDBx4VXAAERr27WQ+s2qbrHnjFt6/oi70BrAjAqcT020Y5OTlaunSpnnzySW3ZskU33XST6urqlJ2dLUmaOXOm5s+f72t/0003qbKyUrfeequ2b9+u1157Tffee6/mzJljdqkAjsMwDL24fq8uvv9d/fXtHTrzYJHva0P6mPrgIgD4mL7Oy4wZM1ReXq4FCxbI5XIpNTVVK1eu9E3iLS4ult1+JEMlJSXpjTfe0C9/+UudddZZSkxM1K233qrf/va3ZpcK4BiKSqp05yubtL64SpI0OuywhtXv8n39QMlujUjPCExxAE4ppq/z0tNY5wXwr9KaBv1x5VY9v67ltlB4aJDmTB6hYVtf0+bVb/rajT5vkqb9/NeBKhOAxXXl57fpIy8ArKmhyaN/vL9Tf1/9peq/fproe2cP1m8uG6UI72Et/cc7kqSM7/xQn7zwL1WU7A5kuQBOIYQXAG0YhqHXN7p074ot2nPwsCTp7CF9lTv9TKUk9ZUkfbDsX/I0N2vgyNE6K+syffLCv1S5d488zc0KCuafFQDm4l8ZAD6b9lXrrlc265OvKiVJA6Odmvet0boyZZBsNpskyd1wWJ+tanlR6oTp31XkgFiFhoXJffiwDu7fq5ikoQGrH8CpgfACQBWHGvWXVdu07NMSGYbkCLbrfyYN188mDVN4aNt/Jja+vUoNdYfUb+AgDU/PkM1m04Ckodq/fasqSnYTXgCYjvACnMLczV49+dEu/TX/C9U2NkuSpqcM0rxvjVZi37Cj2ns9HhWueEmSlDbtO7LbWxaTjE1Kbgkvxbulc3uufgCnJsILcAoyDEP5W8p0z4ot+qqiTpI0LjFaC6aP0YTk/h322/bxB6opL1NYVLTGTLrYt3/A16MtTNoF0BMIL8ApZntpre5+dbPe/6JCkhQT4dBvLhul7589WHa7rcN+hmFo7cvPS5LGX3aFQkKPvJaj9VbRAcILgB5AeAFOEVX1bj345nY9/UmxPF5DoUF2XXf+aZozebginSHH7V+88TOV7fpSwQ6HUi+d1uZrMUNawktVmUtNDQ0KcTpN+R4AQCK8ACe9Zo9X//ykWA+8uV3Vh5skSVPPjNdtl5+hoQP6dPo4a19pGXUZe9EUhUW2XUAqPCpa4dF9VV9dpQN7ipUwYqT/vgEA+C+EF+Ak9v4X5brrlc36ouyQJGl0QqQWXDFG546I6dJxynd/pV2frZPNZlf6FVe12yYmaaiKq6tUUbKb8ALAVIQX4CT0VUWd7nlts97aUiZJ6hceopxLR+nHE5IUHNT197G2jrqcfs55io5LaLdNTNJQFW/8jEm7AExHeAFOIjUNTfpb/hd64qNdavIYCrbbNDMzWbdecrqiw48/r6XdY1aUa+tH70lqWZSuIzxxBKCnEF6Ak4DHa+hfa0t0/xvbdKDOLUm6aFSsfjdtjEbERZzQsde9/rK8Ho+SxoxTwvDTO2wXOyRZEuEFgPkIL4DFfbzzgO56ZbM276+RJA2L7aM7rhijyaPiTvjYjfV12pC/UpKUfmXHoy6SNGBwkiSp7mClDtfWHDWpFwD8hfACWFRJZb3yXt+iFRtckqQoZ7B+kTVS12YOVUg35rW057M3X5f78GENGDxEp6WmH7NtaFi4omLjVVNeqoqS3UoaM84vNQDAfyO8ABb0UtFe/fq5z+Vu9spuk67OGKKcKaPUv0+o387haW7S+tdfliSlT/+u78WMxxIzZCjhBYDpCC+Axbz2+X79cnmRvIaUOWyAcq8co9EJ/r9Fs+WDd3XoYKUi+vXXGedP6lSfmKSh2lm4hpV2AZiK8AJYyKpNLt26bL28hvTD9MG677tnHXNJ/+4yDMP3ePT4b12poODOPakUwxNHAHqAf26MAzDdO9vKNOeZdWr2GroqdZDyTAoukvRV0Vod2FOs0LAwpUz5Vqf7+cJL8W4ZhmFKbQBAeAEs4MMdFfrZU4Vq8hi6fFyC7v9BioJMCi6SfC9gHHfJZXKEd/4VAv0TB8seFKTG+jodqjxgVnkATnGEF6CXW/NVpW54cq0am73KOiNe//ej8d1aJbezXF9+oZLNG2QPCtLZ37qyS32DgkPUb2CiJG4dATAP4QXoxdYVH1T242t0uMmjSSNjtfia8X57DLojn34912X0uRcqKia2y/19K+0W7/JnWQDgQ3gBeqmNe6s167E1qnN7lDlsgB6+Nk2O4CBTz1lV6tIXH38oqeXx6O6ISRoiiZEXAOYhvAC90FZXjX7y6CeqbWjWhOR+evSn6XKGmBtcJKnwtRdlGF4lp5yt2KGndesYMbwmAIDJCC9AL7OjrFbXLP1EVfVNSk3qq8d+OkHhoeavanC4tkYbV78pqfujLtKRJ44q95TI6/X4pTYA+CbCC9CLfFVRp6uXfqIDdW6NTYzSk9dNVKSze2+D7qqiVa+pubFRccnDNWRsSrePEx0Xr+BQh5qb3KpyufxYIQC0ILwAvURJZb2uXvqxymobNTohUk9dl6HosJ4JLk3uRq1f+aqklhcwduZVAB2x24M0YHDLvBdW2gVgBsIL0Avsqzqsq//xsfZXN2h4bB89dX2G+vnxPUXHs/ndt3W4plpRsXEadc75J3w8VtoFYCbCCxBgZTUNuuYfn6ik8rCGDgjXM7PPUWyko8fO7/V6VPjaC5KktMu/LXvQiU8M9j1xxOPSAExAeAECqOJQo67+xyf6qqJOiX3D9MzscxQf5ezRGr5c+4kO7t8nZ58Ijb34Ur8ck5EXAGYivAABUlXv1k/+8Yl2lB1SQpRTz84+R4l9w3q8jtZF6VIuvVyhTv+cv/Vx6YOufWp2u/1yTABoRXgBAqCmoUnXPrpGW121iolw6JnZGRoyILzH69i7dbP2b9+qoOBgjb9sut+O26dffzn7RMjwelW5b4/fjgsAEuEF6HGHGps167E12rC3Wv37hOqZ2RkaFhsRkFpaR13GXHix+vTt57fj2my2I68J4NYRAD8jvAA9qN7drOse/1Tri6sUHRaip6/P0Mj4yIDUUrlvj74s/ESSlHbFd/x+fFbaBWAWwgvQQxqaPJr9/9Zqza5KRTqC9dT1EzVmUFTA6ln76guSYWh4eoYGJCb5/fitk3ZZ6wWAvxFegB7Q2OzRTU8X6sMdBxQeGqQnrpuoswb3DVg9dVUHtfm9tyWd2KsAjqX1celyHpcG4Gc9El4WL16s5ORkOZ1OZWRkaM2aNR22feKJJ2Sz2dpsTmfPPjoK+FOTx6tbnlmvd7aVyxli12M/naC0of6bX9Id61e+Kk9TkwaePkqJo8aYco6YpGRJUm1FuRrr6005B4BTk+nhZfny5crJyVFubq7WrVunlJQUTZ06VWVlZR32iYqK0v79+33b7t0MO8Oamj1e/WJ5kVZtLlVosF3/mDlB5wwbENCa3A2H9dmq1yRJE6Z/74ReBXAszogIRfRv+V4P7OHvMAD/MT28PPDAA5o9e7ays7M1ZswYLVmyROHh4Xrsscc67GOz2ZSQkODb4uPjzS4T8Duv19Bvnvtcr32+XyFBNi35ydk6//SYQJelje+8qYa6Q+qbMFDDJ2SYei4WqwNgBlPDi9vtVmFhobKyso6c0G5XVlaWCgoKOux36NAhDR06VElJSfr2t7+tTZs2ddi2sbFRNTU1bTYg0LxeQ7e9sEHPr9+rILtNf/vx2bp4dOBDuNfjUeFrL0mS0q/4juz2E38VwLH4HpcuJrwA8B9Tw0tFRYU8Hs9RIyfx8fFyuVzt9hk1apQee+wxvfTSS3r66afl9Xp17rnnas+e9he6ysvLU3R0tG9LSvL/UxNAVxiGoTtf2aRln5bIbpMWzkjVZWMTAl2WJGn7xx+oprxUYVHRGjPpEtPPx8gLADP0uqeNMjMzNXPmTKWmpmrSpEl6/vnnFRsbq4cffrjd9vPnz1d1dbVvKykp6eGKgbb+9MY2PVmwWzab9Ofvp2h6yqBAlySpJVS1Lko3fuoVCgk1/+WPsaz1AsAEwWYePCYmRkFBQSotLW2zv7S0VAkJnfufaEhIiMaPH68dO3a0+3WHwyGHo+fewAscy/rig3po9ZeSpHuuGqfvpQ0OcEVHlGz6XGVffangUIdSLr28R87ZP3GwZLPpcE216qoO+nUVXwCnLlNHXkJDQ5WWlqb8/HzfPq/Xq/z8fGVmZnbqGB6PRxs2bNDAgQPNKhPwC6/X0O9fbpmf9f20wbo6Y0iAK2qrddRl7OQshUdF98g5QxxO9Y1v+Y8Koy8A/MX020Y5OTlaunSpnnzySW3ZskU33XST6urqlJ2dLUmaOXOm5s+f72t/1113adWqVdq5c6fWrVunn/zkJ9q9e7duuOEGs0sFTsh/1u3RZ3uqFeEI1m8uGxXoctooL96lXUWFstnsSpvm/1cBHEvrei+stAvAX0y9bSRJM2bMUHl5uRYsWCCXy6XU1FStXLnSN4m3uLhYdvuRDHXw4EHNnj1bLpdL/fr1U1pamj766CONGWPOQlqAP9Q2NOmPK7dJkm65eITiInvXwoprvx51OT3jXN9ISE+JGTJUOz4tYOQFgN+YHl4kae7cuZo7d267X1u9enWbzx988EE9+OCDPVAV4D+L3tmhikONSh4Qrp+elxzoctqoPVChrR++K0maYNKrAI4lhselAfhZr3vaCLCaryrq9NgHX0mS7rhijBzB5q6d0lXrXn9ZXo9Hg8eMVcKIkT1+fl942VMsw+vt8fMDOPkQXoAT9IdXN6vJY2jSyFhdPDou0OW00Vhfp8/fel1Sy6sAAqFvwiAFBQerqeGwairKA1IDgJML4QU4Aau3lSl/a5mC7TbdccUY094T1F2fv7VS7sOHNWDwEJ2WmhaQGoKCg9V/UMsj4xUluwJSA4CTC+EF6KYmj1d3v7pZkjTr3GSNiIsIcEVteZqbtO71lyW1vArAZg/cX3deEwDAnwgvQDc9+dEufVlepwF9QvXzS04PdDlH2frhezpUeUB9+vXX6PMvCmgtvCYAgD8RXoBuqDjUqP/L/0KS9OupoxQdFhLgitoyDMP3ePTZ37pSwSGBrS/m69cEsNYLAH8gvADd8JdV21Tb0KyxiVH6QXrvexnorqJCVZTsVogzTGdlXRbocnwjLwf27pGnuTnA1QCwOsIL0EUb91Zr2actLwDNnX6mguy9a5KudORVAGddMlXOPoGfixMVE6sQZ5i8nmZVufYFuhwAFkd4AbrAMFreX2QY0pUpgzQhuX+gSzpK6c4dKtn0uexBQTr78m8HuhxJks1uV0xSy7uemPcC4EQRXoAueOXz/Vq7+6DCQoI0//LRgS6nXZ++/B9J0qjMCxQVExvgao44stLursAWAsDyCC9AJ9W7m5W3Yosk6eaLhmtgdFiAKzpadZlL2z/+UJKUHoBXARwLTxwB8BfCC9BJS1Z/qf3VDRrcL0yzLxwW6HLaVfjaSzIMr4aeNV5xyb2rxgGEFwB+QngBOqGksl4Pv7dTknT75WfIGdK73l8kSYdra7ThnVWSet+oiyTFfv24dFWpS02NDYEtBoClEV6ATsh7fYsam73KHDZAl41NCHQ57fps1Qo1NzYqNnmYho5LDXQ5RwmP7quwqGjJMHRgT0mgywFgYYQX4Dg++rJCKza4ZLdJuVf2vvcXSVKz2631b7wqSZpwxXd6ZY0S814A+AfhBTiGZo9Xd73S8v6iazKGanRCVIArat/m995WfXWVIgfEamTmBYEup0MxQwgvAE4c4QU4hmc/LdFWV62iw0KUM2VkoMtpl+H1au2rL0iS0qZ9W0HBwQGuqGM8Lg3AHwgvQAcMw9D/vdXy/qJfXTpS/fqEBrii9u0o/EQH9++VI7yPxl18aaDLOSbfawIYeQFwAggvQAdqGppVcahRkvSDtN73/qJWa19ueRVAypRvKTQsPMDVHNuAwS3h5dDBSh0+VBvgagBYFeEF6EBZTcvjvFHOYIWF9r5HoyVp77Yt2rd9i4KCgzX+W1cGupzjcoSHKyo2ThKjLwC6j/ACdKC0pmXUJT7KGeBKOrb2lZZXAZxxwWRF9Ot971lqz5F5L4QXAN1DeAE6UFbbMvLSW8NL5b692rH2E0lS+hW9b1G6jrDSLoATRXgBOtA68hIX6QhwJe0rfPUFyTA07OwJGjC4987J+W+s9QLgRBFegA6Ufj3nJa4XjrzUVR3UpvfyJUkTpn8vwNV0zZHwskuGYQS4GgBWRHgBOlBe2zrnpfeNvBS98ao8TU1KGDFSiWecGehyuqTfoETZbDY11tWp9sCBQJcDwIJ672pWQID5Rl4ie9fIS1NDg4pWrZAkTZj+3V77KgBJaqyvU3nxLpXv/koVu1t+Lf/GiEvh659p8rWXBLhKAFZDeAE6UOqbsNu7Rl42vPOmGg7Vqm/8QI2YmBnociS1rPJbVbq/JZx8HVbKd+9STXlpBz2CZA9O1JkXjuvROgGcHAgvQDsMw1BZL3xU2uvxqPC1FyVJadOukt3es+vPeKqq1OhuUmVl2VGjKc2Nje32iRgQo7ihpylmSLJih56mqrJwrX29SvHJ0YobGtej9QM4ORBegHbUHG5WY7NXkhTbi5422v6fhb7RjOYmtza9m68Qh0PBDodCQr/5q7Nlf6hDIQ6H7EEtIafR0yhHkEOGYai5sVGHD9Wq4VCtGg4dUkNdrRpqa9vuO1Tbsv/rjw9XHZTH6223tuCQUA1IGqrYoacpdmhLUIkZkqywiMg27V58cL1sNruGn01wAdA9hBegHa23jKLDQuQM6T2r6+78KF+t8+zfferRTvezBwUrxOHQIeOwDMMrR3OQjGZPt+vo4wxX/Jgzvw4qLSGl38BBxx0Jqq9xa9/2g5KkEWmEFwDdQ3gB2nHkllHvGXVR9R6lO4sU2neg3KO+rSZvkJrdjWpqbDz618ZGNbkbpa8nxno9zWqsb1bI14cy1BJc7EHBckZEyBkRqbDISDkjIuXsE+nb17J9/fWISLmuv0H20jINf/pphZ99dpe/hZ1F5TIMKW5opKJiwvx1ZQCcYggvQDtanzTqTfNdtPF5xTnrlHVOvJS94LjNDcOQp6lJTe6WMLPqi9f11zUPamhUshZdsUTOiEiFOJydflqpubxclftLJZtNzlGjuvUt7CgskyRuGQE4IYQXoB2tt41603wXbXyu5dexnVuUzmazKTg0VMGhoVJEpD7csF6V0U36wVkXKyqm6+GhYcsWSVLoaafJ3qdPl/tzywiAv7BIHdCOXvekUcUX0v7PJHuwNOaqLnd3e9z6cO+HkqTJSZO7VULD5s2SJOeYMd3q33rLKHYIt4wAnBjCC9AO30sZe8vIy4avR12GTZb6DOhy909dn6q+uV6xYbE6Y8AZ3SqhYdPX4eWM7vVvvWXEqAuAE9Uj4WXx4sVKTk6W0+lURkaG1qxZ06l+y5Ytk81m01VXXWVugcB/8b2UsTeMvBjGkVtG477frUO8U/KOJGlS0iTZbd37a99628h5ZtdHXrhlBMCfTA8vy5cvV05OjnJzc7Vu3TqlpKRo6tSpKisrO2a/Xbt26X//9391wQUXmF0icJQjE3Z7wcjL/s+kAzukYKc0elqXuxuGoXf3vCup+7eMPNXVatqzR1L3Rl64ZQTAn0wPLw888IBmz56t7OxsjRkzRkuWLFF4eLgee+yxDvt4PB5dc801uvPOOzVs2DCzSwSOsvIXF+rtX03SmYOiA13KkVGXkVMlR+Sx27Zj28FtctW5FBYcpokJE7tVQuuoS8jgwQqK7vo1+XIdt4wA+I+p4cXtdquwsFBZWVlHTmi3KysrSwUFBR32u+uuuxQXF6frr7/+uOdobGxUTU1Nmw04URGOYA2LjQj8AnVer7Tx+ZaPx57YLaPMgZlyBnfvNphvvks3JusernVr7zZuGQHwH1PDS0VFhTwej+Lj49vsj4+Pl8vlarfPBx98oEcffVRLly7t1Dny8vIUHR3t25KSkk64bqDXKPlYqtkrOaKk0y/t1iFWl6yWJF2UdFG3y/DNdxnT9VtGX67nlhEA/+pVTxvV1tbq2muv1dKlSxUTE9OpPvPnz1d1dbVvKykpMblKoAe1PmU0+goppOujJq46lzYf2CybbLpw8IXdLuNEHpPmlhEAfzN1kbqYmBgFBQWptLS0zf7S0lIlJCQc1f7LL7/Url27NH36dN8+79cvgQsODta2bds0fPjwNn0cDoccjl4wqRLwN0+TtPnFlo/HdW5huv/23p73JEkpsSkaENb1R6wlyVtXJ/dXX0nqenj55i0jVtUF4C+mjryEhoYqLS1N+fn5vn1er1f5+fnKzMw8qv3o0aO1YcMGFRUV+bYrr7xSkydPVlFREbeEcGrZ+a5Uf0AKj5FOu6hbh2id73JCt4y2bZMMQ8FxcQru5Ihoq28+ZRQdyy0jAP5h+usBcnJyNGvWLKWnp2vixIlauHCh6urqlJ2dLUmaOXOmEhMTlZeXJ6fTqbFjx7bp37dvX0k6aj9w0mt9yujMq6Sgrv9VrW+q1yf7P5F0guHlBCbrsjAdADOYHl5mzJih8vJyLViwQC6XS6mpqVq5cqVvEm9xcbHs9l419QYIvKbD0pZXWz7u5lNGH+37SE3eJiVFJmlYdPeXHOjuZF1uGQEwS4+8mHHu3LmaO3duu19bvXr1Mfs+8cQT/i8I6O2+WCW5a6WowVJSRrcO8c1bRp19c3R7ujtZl1tGAMzCkAfQG7U+ZTT2u1I3RiY9Xo/e3/O+pO6vqitJ3sZGNe7YIanr4YVbRgDMQngBepuGGmn7Gy0fd/NdRp9XfK6DjQcVFRql1LjUbpfSuP0LqblZQX37KnjgwE73O1zr1t7tVZK4ZQTA/wgvgMk8Xk+X2te/8HcZzY3SgNOlhLO6dc7WW0YXDL5AIfaQbh1DanvLqCu3nnYWlcvwGtwyAmAKwgvQWcUfS10MIp+Vf6arXrpKO6t2dqp97erV2n3nk9rzfn81J18hdXOuij9W1ZWkhi2t4aVrk3W5ZQTATIQXoDPWPy09/i3plZ9LhtGpLoZh6G/r/qZdNbt001s3qby+/Lh9PPt2y2Y3dGifUzvvW6VDH3zY6RIPHWzUyoc36P38DdpfUa5ge7DOG3Rep/u3p2Fz65NGx5/vUnPgsDa+t1ev/f1znjICYKoeedoIsDxHVMuv65+WHNHS1HuOOypis9n050l/1rWvX6vdNbs1J3+OHr/scfUJ6dNhn76nN8l5abn2rhko94GDKrnhBvX/6U8Vm/NL2UNDj3m+3Rsr9OX6cmm9NEt3q75/pba9dUDJZ0kDEiO6/MSR0dSkxq1bJbUfXpqbPNr3RZWKN1WqeNMBHXTVt/n60HEDuGUEwBQ2w+jkfyMtoqamRtHR0aqurlZUVFSgy8HJZP0/pZdubvl48u3SpN90qltJTYl+8vpPVNlQqXMHnatFlyzqeB7KY9+Sij+Sd1Kuyt6v08FnnpEkOc44Q4l/uV+OYR2v13LQVaftn5bq3Q8K1ae67asAIvo5NHRcjJLHDdDgUf0UHHr8t2U3bNuur779bdn79NHIT9fIZrerurxeuzdWqnjzAe3ddlDNbq+vvc1uU8KwKA0ZM0BDxw5QzOAI2ezdf0QbwKmlKz+/CS9AV3y8RFr525aPL7tPOuemTnXbWLFR171xnQ43H9aVw6/UH877w9EjIdV7pAfPbPn4l5uk6MGqffsd7b/tNnmqqmRzOhU/f776/vAHHY6iVDVUadK/JimsIVJ/GfawqrZ7tGdLpZqbjoSM4BC7Bo/up+SzYjR0bIwi+rX/brCqF1/UntsWqH7C5Wq4/DoVbzyg6vLDbdr0iQ7VkDMHaMiZAzR4dD85+3R/cjCAUxvhhfACM737J+mde1o+/vbfpfHXdKrbe3ve08/f/rk8hkf/c9b/aO74/1q48cO/Sm/eIQ09T8pe4dvdVFqm/fPnqe6jAklS5JQsJdx1l4L79TvqHK98+Ypu++A2jew3Uv+58j+SpGa3R3u2HdTuDQe0a0OFDh1sbNMnJilCyeNilDwuRnFDI1VVVq/iTZX64pVPVV4XLm/QkdtVdrtNA0dE+wLLgMQ+J7QAHgC0IrwQXmAmw5BW/U4qWCTZ7NIPnpTGXNmprs9tf053FtwpScrNzNX3R35jHZeHL5T2fyZNe0CacH3bU3q9qnziSZU9+KDU1KTg+HgN+uMf1eectqvv/mr1r7Rq9yrdeNaNumX8Le2UbujA3jrt2lCh3Rsq5PqqRvrGvwDBofY2t4IkKdzpVfKEwRo6pmV0JTSMqXIA/I/wQniB2QxDevkWaf1Tkj1Eunq5NOKSTnVdtH6RHv78YQXZgvTXi/+qCwdfKFV8IS1Kl+zB0q+2S30GtNv38KZN2ve/v5b7q68km00DbrhBsT+/RbaQELk9bl24/ELVNdXp2WnPamzM8V9merjWrd2bDmjX5wdUvPmAmho8sgfbNGh4tMLefEr9XJ9p7LMPKWzUqC5dHgDoKsIL4QU9weuRnrtO2vyiFBIuXfuiNOT47yEyDEN3fHiHXvryJYUFh+mxqY9p7IZXpHfvk0ZMkX7y3LFPW1+v0rz7VPXvf0uSnOPGKfH+P2tt8F79z1v/o9iwWL31g7dkt3V+JQSv262m6lpVFlcpIrRJhqtEe2/5uWwOh0YVrpUtmNEWAOYivBBe0FOa3dKyH0s73mp5hPr7j0ph/SRPk+RxS96mrz9u/bxZ8rjV1HxYt+x+WR/WF6u/3amnKw8r6WCJ9J2HpZQfderUNatWaf8dC+StrpYtPFxF3xmjt+rX6YJ+6ZqekCVvfb28dXVHtm9+Xl8nT12djLp6eerrpaamds/hPOssnfav5f68YgDQLsIL4QU9yV0vPf1dqbigS93qbDZlD4zXFkeohjQ16amyKvXP2S45O//ntsnl0r7f/Fb1a9Z0tep22RwO2fv0adkiIxQ7Z44iL+nc7TAAOBGEF8ILelpDtfTizdLedVJQsBQU2jIXJqh1C22Zz9Lm41CV2wz9pH6j9hmN6hPkUISjr0LsIQoJCmn59estNCj0yOdBIQq2Bx/5XEEatnKT+rz/mbwhQUodeo6CIyJbAkh4uOx9+iioNZB8/flRH3/9ObeHAAQK4YXwAgvZWb1T1628TgcaDpzwsS4ZcokWTl544kUBQA/rys9v/psFBNiw6GF6/Xuva0/tHjV5m1o2T1P7H3/jc7fX3eZrNtnaPnoNACcpwgvQC4QFh+n0fqcHugwAsATeKg0AACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACylR8LL4sWLlZycLKfTqYyMDK1Zs6bDts8//7zS09PVt29f9enTR6mpqXrqqad6okwAAGABpoeX5cuXKycnR7m5uVq3bp1SUlI0depUlZWVtdu+f//+uv3221VQUKDPP/9c2dnZys7O1htvvGF2qQAAwAJshmEYZp4gIyNDEyZM0KJFiyRJXq9XSUlJuuWWWzRv3rxOHePss8/WtGnTdPfddx+3bU1NjaKjo1VdXa2oqKgTqh0AAPSMrvz8NnXkxe12q7CwUFlZWUdOaLcrKytLBQUFx+1vGIby8/O1bds2XXjhhe22aWxsVE1NTZsNAACcvEwNLxUVFfJ4PIqPj2+zPz4+Xi6Xq8N+1dXVioiIUGhoqKZNm6a//e1vmjJlSrtt8/LyFB0d7duSkpL8+j0AAIDepVc+bRQZGamioiJ9+umnuueee5STk6PVq1e323b+/Pmqrq72bSUlJT1bLAAA6FHBZh48JiZGQUFBKi0tbbO/tLRUCQkJHfaz2+0aMWKEJCk1NVVbtmxRXl6eLrrooqPaOhwOORwOv9YNAAB6L1NHXkJDQ5WWlqb8/HzfPq/Xq/z8fGVmZnb6OF6vV42NjWaUCAAALMbUkRdJysnJ0axZs5Senq6JEydq4cKFqqurU3Z2tiRp5syZSkxMVF5enqSWOSzp6ekaPny4GhsbtWLFCj311FN66KGHzC4VAABYgOnhZcaMGSovL9eCBQvkcrmUmpqqlStX+ibxFhcXy24/MgBUV1enm2++WXv27FFYWJhGjx6tp59+WjNmzDC7VAAAYAGmr/PS01jnBQAA6+k167wAAAD4G+EFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYCuEFAABYSo+El8WLFys5OVlOp1MZGRlas2ZNh22XLl2qCy64QP369VO/fv2UlZV1zPYAAODUYnp4Wb58uXJycpSbm6t169YpJSVFU6dOVVlZWbvtV69erR//+Md65513VFBQoKSkJF166aXau3ev2aUCAAALsBmGYZh5goyMDE2YMEGLFi2SJHm9XiUlJemWW27RvHnzjtvf4/GoX79+WrRokWbOnHnc9jU1NYqOjlZ1dbWioqJOuH4AAGC+rvz8NnXkxe12q7CwUFlZWUdOaLcrKytLBQUFnTpGfX29mpqa1L9/f7PKBAAAFhJs5sErKirk8XgUHx/fZn98fLy2bt3aqWP89re/1aBBg9oEoG9qbGxUY2Oj7/OampruFwwAAHq9Xv200X333adly5bphRdekNPpbLdNXl6eoqOjfVtSUlIPVwkAAHqSqeElJiZGQUFBKi0tbbO/tLRUCQkJx+x7//3367777tOqVat01llnddhu/vz5qq6u9m0lJSV+qR0AAPROpoaX0NBQpaWlKT8/37fP6/UqPz9fmZmZHfb705/+pLvvvlsrV65Uenr6Mc/hcDgUFRXVZgMAACcvU+e8SFJOTo5mzZql9PR0TZw4UQsXLlRdXZ2ys7MlSTNnzlRiYqLy8vIkSX/84x+1YMECPfPMM0pOTpbL5ZIkRUREKCIiwuxyAQBAL2d6eJkxY4bKy8u1YMECuVwupaamauXKlb5JvMXFxbLbjwwAPfTQQ3K73fr+97/f5ji5ubn6/e9/b3a5AACglzN9nZeexjovAABYT69Z5wUAAMDfCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSCC8AAMBSeiS8LF68WMnJyXI6ncrIyNCaNWs6bLtp0yZ973vfU3Jysmw2mxYuXNgTJQIAAIswPbwsX75cOTk5ys3N1bp165SSkqKpU6eqrKys3fb19fUaNmyY7rvvPiUkJJhdHgAAsBjTw8sDDzyg2bNnKzs7W2PGjNGSJUsUHh6uxx57rN32EyZM0J///Gf96Ec/ksPhMLs8AABgMaaGF7fbrcLCQmVlZR05od2urKwsFRQU+OUcjY2NqqmpabMBAICTl6nhpaKiQh6PR/Hx8W32x8fHy+Vy+eUceXl5io6O9m1JSUl+OS4AAOidLP+00fz581VdXe3bSkpKAl0SAAAwUbCZB4+JiVFQUJBKS0vb7C8tLfXbZFyHw8HcGAAATiGmjryEhoYqLS1N+fn5vn1er1f5+fnKzMw089QAAOAkZerIiyTl5ORo1qxZSk9P18SJE7Vw4ULV1dUpOztbkjRz5kwlJiYqLy9PUssk382bN/s+3rt3r4qKihQREaERI0aYXS4AAOjlTA8vM2bMUHl5uRYsWCCXy6XU1FStXLnSN4m3uLhYdvuRAaB9+/Zp/Pjxvs/vv/9+3X///Zo0aZJWr15tdrkAAKCXsxmGYQS6CH+qqalRdHS0qqurFRUVFehyAABAJ3Tl57flnzYCAACnFsILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwFMILAACwlB4JL4sXL1ZycrKcTqcyMjK0Zs2aY7b/97//rdGjR8vpdGrcuHFasWJFT5QJAAAswPTwsnz5cuXk5Cg3N1fr1q1TSkqKpk6dqrKysnbbf/TRR/rxj3+s66+/XuvXr9dVV12lq666Shs3bjS7VAAAYAE2wzAMM0+QkZGhCRMmaNGiRZIkr9erpKQk3XLLLZo3b95R7WfMmKG6ujq9+uqrvn3nnHOOUlNTtWTJkuOer6amRtHR0aqurlZUVJT/vhEAAGCarvz8NnXkxe12q7CwUFlZWUdOaLcrKytLBQUF7fYpKCho016Spk6d2mH7xsZG1dTUtNkAAMDJy9TwUlFRIY/Ho/j4+Db74+Pj5XK52u3jcrm61D4vL0/R0dG+LSkpyT/FAwCAXsnyTxvNnz9f1dXVvq2kpCTQJQEAABMFm3nwmJgYBQUFqbS0tM3+0tJSJSQktNsnISGhS+0dDoccDod/CgYAAL2eqSMvoaGhSktLU35+vm+f1+tVfn6+MjMz2+2TmZnZpr0kvfnmmx22BwAApxZTR14kKScnR7NmzVJ6eromTpyohQsXqq6uTtnZ2ZKkmTNnKjExUXl5eZKkW2+9VZMmTdJf/vIXTZs2TcuWLdPatWv1yCOPmF0qAACwANPDy4wZM1ReXq4FCxbI5XIpNTVVK1eu9E3KLS4ult1+ZADo3HPP1TPPPKPf/e53uu2223T66afrxRdf1NixY80uFQAAWIDp67z0NNZ5AQDAenrNOi8AAAD+RngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWQngBAACWYlp4qays1DXXXKOoqCj17dtX119/vQ4dOnTMPo888oguuugiRUVFyWazqaqqyqzyAACARZkWXq655hpt2rRJb775pl599VW99957uvHGG4/Zp76+Xpdddpluu+02s8oCAAAWZzMMw/D3Qbds2aIxY8bo008/VXp6uiRp5cqVuvzyy7Vnzx4NGjTomP1Xr16tyZMn6+DBg+rbt2+Xzl1TU6Po6GhVV1crKiqqu98CAADoQV35+R1sRgEFBQXq27evL7hIUlZWlux2uz755BN95zvf8du5Ghsb1djY6Pu8urpaUstFAAAA1tD6c7szYyqmhBeXy6W4uLi2JwoOVv/+/eVyufx6rry8PN15551H7U9KSvLreQAAgPlqa2sVHR19zDZdCi/z5s3TH//4x2O22bJlS1cOecLmz5+vnJwc3+der1eVlZUaMGCAbDZbj9ZyqqipqVFSUpJKSkq4NdfDuPaBwXUPDK57YATquhuGodra2uNOLZG6GF5+9atf6ac//ekx2wwbNkwJCQkqKytrs7+5uVmVlZVKSEjoyimPy+FwyOFwtNnX1Xky6J6oqCj+QQkQrn1gcN0Dg+seGIG47scbcWnVpfASGxur2NjY47bLzMxUVVWVCgsLlZaWJkl6++235fV6lZGR0ZVTAgAAtGHKo9JnnHGGLrvsMs2ePVtr1qzRhx9+qLlz5+pHP/qRbzho7969Gj16tNasWePr53K5VFRUpB07dkiSNmzYoKKiIlVWVppRJgAAsCDT1nn55z//qdGjR+uSSy7R5ZdfrvPPP1+PPPKI7+tNTU3atm2b6uvrffuWLFmi8ePHa/bs2ZKkCy+8UOPHj9fLL79sVpnoBofDodzc3KNu18F8XPvA4LoHBtc9MKxw3U1Z5wUAAMAsvNsIAABYCuEFAABYCuEFAABYCuEFAABYCuEF7Vq8eLGSk5PldDqVkZHR5pH29lRVVWnOnDkaOHCgHA6HRo4cqRUrVvRQtSePrl73hQsXatSoUQoLC1NSUpJ++ctfqqGhoYeqPTm89957mj59ugYNGiSbzaYXX3zxuH1Wr16ts88+Ww6HQyNGjNATTzxhep0no65e++eff15TpkxRbGysoqKilJmZqTfeeKNnij2JdOfPfKsPP/xQwcHBSk1NNa2+ziC84CjLly9XTk6OcnNztW7dOqWkpGjq1KlHrZrcyu12a8qUKdq1a5eee+45bdu2TUuXLlViYmIPV25tXb3uzzzzjObNm6fc3Fxt2bJFjz76qJYvX67bbruthyu3trq6OqWkpGjx4sWdav/VV19p2rRpmjx5soqKivSLX/xCN9xwAz9Eu6Gr1/69997TlClTtGLFChUWFmry5MmaPn261q9fb3KlJ5euXvdWVVVVmjlzpi655BKTKusCA/gvEydONObMmeP73OPxGIMGDTLy8vLabf/QQw8Zw4YNM9xud0+VeFLq6nWfM2eOcfHFF7fZl5OTY5x33nmm1nkyk2S88MILx2zzm9/8xjjzzDPb7JsxY4YxdepUEys7+XXm2rdnzJgxxp133un/gk4RXbnuM2bMMH73u98Zubm5RkpKiql1HQ8jL2jD7XarsLBQWVlZvn12u11ZWVkqKChot8/LL7+szMxMzZkzR/Hx8Ro7dqzuvfdeeTyenirb8rpz3c8991wVFhb6bi3t3LlTK1as0OWXX94jNZ+qCgoK2vw+SdLUqVM7/H2Cebxer2pra9W/f/9Al3LSe/zxx7Vz507l5uYGuhRJXXy3EU5+FRUV8ng8io+Pb7M/Pj5eW7dubbfPzp079fbbb+uaa67RihUrtGPHDt18881qamrqNX/Qe7vuXPerr75aFRUVOv/882UYhpqbm/Wzn/2M20Ymc7lc7f4+1dTU6PDhwwoLCwtQZaee+++/X4cOHdIPf/jDQJdyUvviiy80b948vf/++woO7h2xgZEXnDCv16u4uDg98sgjSktL04wZM3T77bdryZIlgS7tpLZ69Wrde++9+vvf/65169bp+eef12uvvaa777470KUBpnvmmWd055136l//+pfi4uICXc5Jy+Px6Oqrr9add96pkSNHBrocn94RodBrxMTEKCgoSKWlpW32l5aWKiEhod0+AwcOVEhIiIKCgnz7zjjjDLlcLrndboWGhppa88mgO9f9jjvu0LXXXqsbbrhBkjRu3DjV1dXpxhtv1O233y67nf+bmCEhIaHd36eoqChGXXrIsmXLdMMNN+jf//73Ubfw4F+1tbVau3at1q9fr7lz50pq+Q+rYRgKDg7WqlWrdPHFF/d4XfzrhjZCQ0OVlpam/Px83z6v16v8/HxlZma22+e8887Tjh075PV6ffu2b9+ugQMHElw6qTvXvb6+/qiA0hogDV5ZZprMzMw2v0+S9Oabb3b4+wT/evbZZ5Wdna1nn31W06ZNC3Q5J72oqCht2LBBRUVFvu1nP/uZRo0apaKiImVkZASmsIBOF0avtGzZMsPhcBhPPPGEsXnzZuPGG280+vbta7hcLsMwDOPaa6815s2b52tfXFxsREZGGnPnzjW2bdtmvPrqq0ZcXJzxhz/8IVDfgiV19brn5uYakZGRxrPPPmvs3LnTWLVqlTF8+HDjhz/8YaC+BUuqra011q9fb6xfv96QZDzwwAPG+vXrjd27dxuGYRjz5s0zrr32Wl/7nTt3GuHh4cavf/1rY8uWLcbixYuNoKAgY+XKlYH6Fiyrq9f+n//8pxEcHGwsXrzY2L9/v2+rqqoK1LdgSV297v+tNzxtRHhBu/72t78ZQ4YMMUJDQ42JEycaH3/8se9rkyZNMmbNmtWm/UcffWRkZGQYDofDGDZsmHHPPfcYzc3NPVy19XXlujc1NRm///3vjeHDhxtOp9NISkoybr75ZuPgwYM9X7iFvfPOO4ako7bWaz1r1ixj0qRJR/VJTU01QkNDjWHDhhmPP/54j9d9MujqtZ80adIx26NzuvNn/pt6Q3ixGQbjywAAwDqY8wIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACyF8AIAACzl/wMVNtuMYs3uaAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LEFT HAND\n",
        "#vid = left_m[20000,:,:,:]\n",
        "vid = lefth_3d[20000,:,:,:]\n",
        "\n",
        "def animation_frame(v):\n",
        "    lx, ly = get_hand_points(v)\n",
        "    ax.clear()\n",
        "    for i in range(len(lx)):\n",
        "        ax.plot(lx[i], ly[i])\n",
        "    plt.xlim(xmin, xmax)\n",
        "    plt.ylim(ymin, ymax)\n",
        "\n",
        "xmin = vid[:,:,0].min() - 0.1\n",
        "xmax = vid[:,:,0].max() + 0.1\n",
        "ymin = vid[:,:,1].min() - 0.1\n",
        "ymax = vid[:,:,1].max() + 0.1\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "(l,) = ax.plot([], [])\n",
        "animation = FuncAnimation(fig, func=animation_frame, frames=vid, interval=300)\n",
        "\n",
        "HTML(animation.to_html5_video())"
      ],
      "metadata": {
        "id": "8v4UyKjeqs4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def animation_frame(f):\n",
        "    frame = sign[sign.frame==f]\n",
        "    left = frame[frame.type=='left_hand']\n",
        "    right = frame[frame.type=='right_hand']\n",
        "    pose = frame[frame.type=='pose']\n",
        "    face = frame[frame.type=='face'][['x', 'y']].values\n",
        "    lx, ly = get_hand_points(left)\n",
        "    rx, ry = get_hand_points(right)\n",
        "    px, py = get_pose_points(pose)\n",
        "    ax.clear()\n",
        "    ax.plot(face[:,0], face[:,1], '.')\n",
        "    for i in range(len(lx)):\n",
        "        ax.plot(lx[i], ly[i])\n",
        "    for i in range(len(rx)):\n",
        "        ax.plot(rx[i], ry[i])\n",
        "    for i in range(len(px)):\n",
        "        ax.plot(px[i], py[i])\n",
        "    plt.xlim(xmin, xmax)\n",
        "    plt.ylim(ymin, ymax)\n",
        "        \n",
        "print(f\"The sign being shown here is: {train[train.path==f'{path_to_sign}'].sign.values[0]}\")\n",
        "\n",
        "## These values set the limits on the graph to stabilize the video\n",
        "xmin = sign.x.min() - 0.2\n",
        "xmax = sign.x.max() + 0.2\n",
        "ymin = sign.y.min() - 0.2\n",
        "ymax = sign.y.max() + 0.2\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "l, = ax.plot([], [])\n",
        "animation = FuncAnimation(fig, func=animation_frame, frames=sign.frame.unique())\n",
        "\n",
        "HTML(animation.to_html5_video())"
      ],
      "metadata": {
        "id": "1Heo1XgprKgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Flow Model"
      ],
      "metadata": {
        "id": "MqOs8F8e_gP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datx = np.concatenate((d1,d2,d3,d4), axis=1)\n",
        "datx.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVMk4bAx7EyS",
        "outputId": "c291e2fd-b774-4e32-95a3-cfc8d45d02c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94477, 4, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I19hFfEGDJ6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVER\n",
        "class ASLData(Dataset):\n",
        "    def __init__(self, datx, datay):\n",
        "        self.datax = datx\n",
        "        self.datay = datay\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.datax[index, :], self.datay[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datay)\n",
        "\n",
        "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
        "class ASLModel(nn.Module):\n",
        "    def __init__(self, p):\n",
        "        super(ASLModel, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.batchnorm0 = nn.BatchNorm1d(datx.shape[1]*datx.shape[2])\n",
        "        self.dropout0 = nn.Dropout(p)\n",
        "        \n",
        "        self.layer1 = nn.Linear(datx.shape[1]*datx.shape[2], 512)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.layer2 = nn.Linear(512, 512)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.layerFC = nn.Linear(512, 250)\n",
        " \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        # x = self.batchnorm0(x)\n",
        "    \n",
        "        x = self.layer1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layerFC(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OZknILM8LvVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############\n",
        "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"++++using GPU++++\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"++++using CPU++++\")\n",
        "\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "start_time = time.perf_counter()\n",
        "print(\"DATAX SHAPE IN\", datx.shape)\n",
        "\n",
        "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
        "print(\"DATAX SHAPE IN2\", datx.shape)\n",
        "datax = torch.tensor(datx)  # Convert to Torch Tensor\n",
        "\n",
        "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
        "\n",
        "train_data = ASLData(trainx, trainy)\n",
        "valid_data = ASLData(testx, testy)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
        "\n",
        "model = ASLModel(0.2).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    model.train()\n",
        "    \n",
        "    train_loss_sum = 0.\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    train_bar = train_loader\n",
        "    for x,y in train_bar:\n",
        "        x = torch.Tensor(x).float().to(device)\n",
        "        y = torch.Tensor(y).long().to(device)  \n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        train_loss_sum += loss.item()\n",
        "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "        train_total += 1\n",
        "        sched.step()\n",
        "        \n",
        "    val_loss_sum = 0.\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    for x,y in val_loader:\n",
        "        x = torch.Tensor(x).float().to(device)\n",
        "        y = torch.Tensor(y).long().to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            val_loss_sum += loss.item()\n",
        "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "            val_total += 1\n",
        "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
        "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
        "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Save the pytorch model\n",
        "py_model_path = f\"{WORKING_DIR}/py_model.pt\"\n",
        "torch.save(model, py_model_path)\n",
        "\n",
        "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:16:57.114241Z",
          "iopub.execute_input": "2023-03-13T18:16:57.115451Z",
          "iopub.status.idle": "2023-03-13T18:23:25.123968Z",
          "shell.execute_reply.started": "2023-03-13T18:16:57.115400Z",
          "shell.execute_reply": "2023-03-13T18:23:25.122556Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670b40d7-81a7-49ec-b2c2-5987bffbebed",
        "id": "jQfZtRfQ96qS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++using CPU++++\n",
            "DATAX SHAPE IN (94477, 4, 40)\n",
            "DATAX SHAPE IN2 (94477, 4, 40)\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:0 > Train Loss: 2.8135, Train Acc: 0.3496\n",
            "Epoch:0 > Val Loss: 1.9060, Val Acc: 0.5312\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:1 > Train Loss: 1.9440, Train Acc: 0.5136\n",
            "Epoch:1 > Val Loss: 1.6431, Val Acc: 0.5890\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:2 > Train Loss: 1.6881, Train Acc: 0.5695\n",
            "Epoch:2 > Val Loss: 1.4856, Val Acc: 0.6358\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:3 > Train Loss: 1.5130, Train Acc: 0.6087\n",
            "Epoch:3 > Val Loss: 1.3907, Val Acc: 0.6559\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:4 > Train Loss: 1.3722, Train Acc: 0.6425\n",
            "Epoch:4 > Val Loss: 1.3308, Val Acc: 0.6741\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:5 > Train Loss: 1.2620, Train Acc: 0.6663\n",
            "Epoch:5 > Val Loss: 1.2895, Val Acc: 0.6830\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:6 > Train Loss: 1.1817, Train Acc: 0.6855\n",
            "Epoch:6 > Val Loss: 1.2596, Val Acc: 0.6886\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:7 > Train Loss: 1.1132, Train Acc: 0.7026\n",
            "Epoch:7 > Val Loss: 1.2353, Val Acc: 0.6971\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:8 > Train Loss: 1.0610, Train Acc: 0.7151\n",
            "Epoch:8 > Val Loss: 1.2226, Val Acc: 0.7019\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:9 > Train Loss: 1.0146, Train Acc: 0.7269\n",
            "Epoch:9 > Val Loss: 1.2122, Val Acc: 0.7044\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:10 > Train Loss: 0.9760, Train Acc: 0.7358\n",
            "Epoch:10 > Val Loss: 1.2006, Val Acc: 0.7113\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:11 > Train Loss: 0.9516, Train Acc: 0.7411\n",
            "Epoch:11 > Val Loss: 1.2024, Val Acc: 0.7089\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:12 > Train Loss: 0.9282, Train Acc: 0.7448\n",
            "Epoch:12 > Val Loss: 1.2022, Val Acc: 0.7108\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:13 > Train Loss: 0.9086, Train Acc: 0.7513\n",
            "Epoch:13 > Val Loss: 1.1978, Val Acc: 0.7122\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:14 > Train Loss: 0.8837, Train Acc: 0.7558\n",
            "Epoch:14 > Val Loss: 1.2011, Val Acc: 0.7120\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:15 > Train Loss: 0.8795, Train Acc: 0.7585\n",
            "Epoch:15 > Val Loss: 1.1912, Val Acc: 0.7132\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:16 > Train Loss: 0.8660, Train Acc: 0.7627\n",
            "Epoch:16 > Val Loss: 1.1897, Val Acc: 0.7140\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:17 > Train Loss: 0.8563, Train Acc: 0.7651\n",
            "Epoch:17 > Val Loss: 1.1869, Val Acc: 0.7156\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:18 > Train Loss: 0.8518, Train Acc: 0.7651\n",
            "Epoch:18 > Val Loss: 1.1913, Val Acc: 0.7158\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:19 > Train Loss: 0.8466, Train Acc: 0.7669\n",
            "Epoch:19 > Val Loss: 1.1886, Val Acc: 0.7164\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:20 > Train Loss: 0.8418, Train Acc: 0.7670\n",
            "Epoch:20 > Val Loss: 1.1865, Val Acc: 0.7158\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:21 > Train Loss: 0.8361, Train Acc: 0.7691\n",
            "Epoch:21 > Val Loss: 1.1880, Val Acc: 0.7169\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:22 > Train Loss: 0.8330, Train Acc: 0.7707\n",
            "Epoch:22 > Val Loss: 1.1868, Val Acc: 0.7173\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:23 > Train Loss: 0.8316, Train Acc: 0.7692\n",
            "Epoch:23 > Val Loss: 1.1840, Val Acc: 0.7170\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:24 > Train Loss: 0.8343, Train Acc: 0.7689\n",
            "Epoch:24 > Val Loss: 1.1877, Val Acc: 0.7169\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:25 > Train Loss: 0.8278, Train Acc: 0.7717\n",
            "Epoch:25 > Val Loss: 1.1875, Val Acc: 0.7173\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:26 > Train Loss: 0.8285, Train Acc: 0.7714\n",
            "Epoch:26 > Val Loss: 1.1892, Val Acc: 0.7180\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:27 > Train Loss: 0.8255, Train Acc: 0.7722\n",
            "Epoch:27 > Val Loss: 1.1849, Val Acc: 0.7173\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:28 > Train Loss: 0.8240, Train Acc: 0.7728\n",
            "Epoch:28 > Val Loss: 1.1896, Val Acc: 0.7149\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:29 > Train Loss: 0.8262, Train Acc: 0.7727\n",
            "Epoch:29 > Val Loss: 1.1873, Val Acc: 0.7146\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:30 > Train Loss: 0.8222, Train Acc: 0.7726\n",
            "Epoch:30 > Val Loss: 1.1803, Val Acc: 0.7159\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:31 > Train Loss: 0.8242, Train Acc: 0.7707\n",
            "Epoch:31 > Val Loss: 1.1832, Val Acc: 0.7171\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:32 > Train Loss: 0.8235, Train Acc: 0.7713\n",
            "Epoch:32 > Val Loss: 1.1876, Val Acc: 0.7178\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:33 > Train Loss: 0.8255, Train Acc: 0.7711\n",
            "Epoch:33 > Val Loss: 1.1931, Val Acc: 0.7156\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:34 > Train Loss: 0.8245, Train Acc: 0.7723\n",
            "Epoch:34 > Val Loss: 1.1838, Val Acc: 0.7178\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:35 > Train Loss: 0.8267, Train Acc: 0.7714\n",
            "Epoch:35 > Val Loss: 1.1881, Val Acc: 0.7163\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:36 > Train Loss: 0.8236, Train Acc: 0.7730\n",
            "Epoch:36 > Val Loss: 1.1884, Val Acc: 0.7167\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:37 > Train Loss: 0.8286, Train Acc: 0.7718\n",
            "Epoch:37 > Val Loss: 1.1838, Val Acc: 0.7158\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:38 > Train Loss: 0.8213, Train Acc: 0.7736\n",
            "Epoch:38 > Val Loss: 1.1880, Val Acc: 0.7182\n",
            "==================================================\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:39 > Train Loss: 0.8196, Train Acc: 0.7729\n",
            "Epoch:39 > Val Loss: 1.1839, Val Acc: 0.7176\n",
            "==================================================\n",
            "#### ELAPSED TIME: 570.7428148920008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tsLearn\n",
        "https://tslearn.readthedocs.io/en/stable/quickstart.html "
      ],
      "metadata": {
        "id": "xZ3qB-rXRXPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tslearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gzkGWmhqXpu",
        "outputId": "d6ab8c33-0285-4ef8-fa34-5193dc4be085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tslearn in /usr/local/lib/python3.9/dist-packages (0.5.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tslearn) (1.22.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from tslearn) (0.56.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from tslearn) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from tslearn) (1.10.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from tslearn) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->tslearn) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->tslearn) (67.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->tslearn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pts_hand =    [PRIM_HAND(\"THUMB_TIP\"),\n",
        "               PRIM_HAND(\"INDEX_FINGER_TIP\"),\n",
        "               PRIM_HAND(\"MIDDLE_FINGER_TIP\"),\n",
        "               PRIM_HAND(\"RING_FINGER_TIP\"), \n",
        "               PRIM_HAND(\"PINKY_FINGER_TIP\"),\n",
        "               PRIM_HAND(\"THUMB_IP\"),\n",
        "               PRIM_HAND(\"INDEX_FINGER_PIP\"),\n",
        "               PRIM_HAND(\"MIDDLE_FINGER_PIP\"),\n",
        "               PRIM_HAND(\"RING_FINGER_PIP\"), \n",
        "               PRIM_HAND(\"PINKY_FINGER_PIP\")]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
        "dx = datax[:,:,PRIM_HAND(\"THUMB_TIP\"),:]\n",
        "print(\"dx in\", dx.shape)\n",
        "dx = datax.reshape(datax.shape[0], datax.shape[1], -1)\n",
        "print(\"dx out\", dx.shape)\n",
        "\n",
        "trainx, testx, trainy, testy = train_test_split(dx, datay, test_size=0.15, random_state=42)\n",
        "\n",
        "knn = KNeighborsTimeSeriesClassifier(n_neighbors=5)\n",
        "knn.fit(trainx, trainy)\n",
        "\n",
        "y_hat = knn.predict(testx)\n",
        "\n",
        "knn.score(testx, testy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "6TNtaJg0Rq-u",
        "outputId": "c4c43b01-157f-419d-9ec6-c60d5d47cecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dx in (94477, 16, 3)\n",
            "dx out (94477, 16, 345)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-95ad8d123854>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/neighbors/neighbors.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    518\u001b[0m             X = check_dims(X, X_fit_dims=self._ts_fit.shape, extend=True,\n\u001b[1;32m    519\u001b[0m                            check_n_features_only=True)\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_precompute_cross_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ts_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/neighbors/neighbors.py\u001b[0m in \u001b[0;36m_precompute_cross_dist\u001b[0;34m(self, X, other_X)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ts_metric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dtw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             X_ = cdist_dtw(X, other_X, n_jobs=self.n_jobs,\n\u001b[0m\u001b[1;32m     65\u001b[0m                            **metric_params)\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ts_metric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ctw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/metrics/dtw_variants.py\u001b[0m in \u001b[0;36mcdist_dtw\u001b[0;34m(dataset1, dataset2, global_constraint, sakoe_chiba_radius, itakura_max_slope, n_jobs, verbose)\u001b[0m\n\u001b[1;32m   1233\u001b[0m            \u001b[0mSignal\u001b[0m \u001b[0mProcessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1978.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \"\"\"  # noqa: E501\n\u001b[0;32m-> 1235\u001b[0;31m     return _cdist_generic(dist_fun=dtw, dataset1=dataset1, dataset2=dataset2,\n\u001b[0m\u001b[1;32m   1236\u001b[0m                           \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                           \u001b[0mcompute_diagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/metrics/utils.py\u001b[0m in \u001b[0;36m_cdist_generic\u001b[0;34m(dist_fun, dataset1, dataset2, n_jobs, verbose, compute_diagonal, dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdataset2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_time_series_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         matrix = Parallel(n_jobs=n_jobs, prefer=\"threads\", verbose=verbose)(\n\u001b[0m\u001b[1;32m     79\u001b[0m             delayed(dist_fun)(\n\u001b[1;32m     80\u001b[0m                 \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    264\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/metrics/dtw_variants.py\u001b[0m in \u001b[0;36mdtw\u001b[0;34m(s1, s2, global_constraint, sakoe_chiba_radius, itakura_max_slope)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_nans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_nans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/utils/utils.py\u001b[0m in \u001b[0;36mto_time_series\u001b[0;34m(ts, remove_nans)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_nans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mts_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mts_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mts_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tslearn/utils/utils.py\u001b[0m in \u001b[0;36mts_size\u001b[0;34m(ts)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mts_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0msz\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_all_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2405\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m     \"\"\"\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = knn.predict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "FykRLuEM73Sj",
        "outputId": "5b0edd36-01a7-446f-a896-04c031c62ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsTimeSeriesClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsTimeSeriesClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsTimeSeriesClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsTimeSeriesClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHw_h3v2Obz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "EPQeoQkNROdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Tree Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "\n",
        "# Split the data into training and test sets\n",
        "trainx, testx, trainy, testy = train_test_split(datax.reshape(datax.shape[0], -1), datay, test_size=0.15, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(trainx, trainy)\n",
        "\n",
        "y_pred = rf.predict(testx)\n",
        "accuracy = accuracy_score(testy, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "AfFnh22EStqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROCKET"
      ],
      "metadata": {
        "id": "-8XmCir6b27E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sktime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1JJNKeJc9lO",
        "outputId": "7407fa86-a8d2-4cd7-d6a4-cea670127ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sktime\n",
            "  Downloading sktime-0.16.1-py3-none-any.whl (16.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.3.0,>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.9/dist-packages (from sktime) (0.56.4)\n",
            "Collecting deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy<1.25,>=1.21.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.22.4)\n",
            "Requirement already satisfied: pandas<1.6.0,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.4.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from sktime) (1.10.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from deprecated>=1.2.13->sktime) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.53->sktime) (67.6.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.53->sktime) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0,>=1.1.0->sktime) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0,>=1.1.0->sktime) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.1.0->sktime) (1.16.0)\n",
            "Installing collected packages: deprecated, sktime\n",
            "Successfully installed deprecated-1.2.13 sktime-0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sktime.transformations.panel.rocket import (\n",
        "    MiniRocket,\n",
        "    MiniRocketMultivariate,\n",
        "    MiniRocketMultivariateVariable,\n",
        ")\n"
      ],
      "metadata": {
        "id": "n97bgMzYabGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FILTER TO REDUCE DATASET SIZE \n",
        "datax = datax[datay < 20]\n",
        "datay = datay[datay < 20]\n",
        "print(\"DATAX\", datax.shape, datay.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrUteGYJhI7-",
        "outputId": "0bab36ca-7c6b-44f6-e968-ea61601e62dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATAX (7528, 12, 40, 3) (7528,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iDniWmD7MZR",
        "outputId": "12a6b680-74d4-44d6-cc30-0d3c149fe630"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09646017699115045"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# FIXED SIZE MODEL\n",
        "#datax = np.nan_to_num(datax, copy=False)\n",
        "datax = datax[:,:,-1]\n",
        "datax = datax.swapaxes(1,2) # swap frame with data\n",
        "trainx, testx, trainy, testy = train_test_split(datax, datay, test_size=0.15, random_state=42)\n",
        "\n",
        "minirocket_multi = MiniRocketMultivariate()\n",
        "minirocket_multi.fit(trainx)\n",
        "X_train_transform = minirocket_multi.transform(trainx)\n",
        "\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train_scaled_transform = scaler.fit_transform(X_train_transform)\n",
        "\n",
        "#classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
        "classifier = SGDClassifier(loss='log')\n",
        "classifier.fit(X_train_scaled_transform, trainy)\n",
        "\n",
        "X_test_transform = minirocket_multi.transform(testx)\n",
        "X_test_scaled_transform = scaler.transform(X_test_transform)\n",
        "classifier.score(X_test_scaled_transform, testy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAVED MULTI MODEL"
      ],
      "metadata": {
        "id": "cdbwn-tLnLfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### MULTI MODEL SETUP\n",
        "class ASLData(Dataset):\n",
        "    def __init__(self,d1,d2,d3,d4,datay):\n",
        "        self.d1 = d1\n",
        "        self.d2 = d2\n",
        "        self.d3 = d3\n",
        "        self.d4 = d4\n",
        "\n",
        "        self.datay = datay\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.d1[index, :], self.d2[index, :],self.d3[index, :],self.d4[index, :], self.datay[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datay)\n",
        "\n",
        "# https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
        "class ASLModel(nn.Module):\n",
        "    def __init__(self, p):\n",
        "        super(ASLModel, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        L1OUT = 512  #1024 was ok\n",
        "        L2OUT = 512\n",
        "        self.layer_ph = nn.Linear(d1.shape[1]*d1.shape[2], L1OUT)\n",
        "        self.batchnorm_ph = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_sh = nn.Linear(d2.shape[1]*d2.shape[2], L1OUT)\n",
        "        self.batchnorm_sh = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_po = nn.Linear(d3.shape[1]*d3.shape[2], L1OUT)\n",
        "        self.batchnorm_po = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        "        self.layer_li = nn.Linear(d4.shape[1]*d4.shape[2], L1OUT)\n",
        "        self.batchnorm_li = nn.BatchNorm1d(L1OUT)\n",
        "\n",
        " \n",
        "        self.layer1 = nn.Linear(4*L1OUT, L2OUT)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(L2OUT)\n",
        "\n",
        "        self.layerFC = nn.Linear(L2OUT, 250)\n",
        " \n",
        "        \n",
        "    def forward(self, phand, shand, pose, lips):\n",
        "        \n",
        "        ph = self.flatten(phand)       \n",
        "        ph = self.layer_ph(ph)\n",
        "        ph = self.batchnorm_ph(ph)\n",
        "        ph = self.relu(ph)\n",
        "        ph = self.dropout(ph)\n",
        "\n",
        "        sh = self.flatten(shand)       \n",
        "        sh = self.layer_sh(sh)\n",
        "        sh = self.batchnorm_sh(sh)\n",
        "        sh = self.relu(sh)\n",
        "        sh = self.dropout(sh)\n",
        "       \n",
        "        po = self.flatten(pose)       \n",
        "        po = self.layer_po(po)\n",
        "        po = self.batchnorm_po(po)\n",
        "        po = self.relu(po)\n",
        "        po = self.dropout(po)\n",
        "        \n",
        "        li = self.flatten(lips)       \n",
        "        li = self.layer_li(li)\n",
        "        li = self.batchnorm_li(li)\n",
        "        li = self.relu(li)\n",
        "        li = self.dropout(li)\n",
        "\n",
        "        x = torch.cat((ph.view(ph.size(0), -1),\n",
        "                       sh.view(sh.size(0), -1),\n",
        "                       po.view(po.size(0), -1),\n",
        "                       li.view(li.size(0), -1)), dim=1)\n",
        "        \n",
        "        # x = self.batchnorm0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.layerFC(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "b2VWSGXaoH5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MULT TRAINING\n",
        "# !!! TRAINING DOES NOT RUN ON MAC OS - (cuda)\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"++++using GPU++++\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"++++using CPU++++\")\n",
        "\n",
        "EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "start_time = time.perf_counter()\n",
        "print(\"DATAX SHAPE IN\", datax.shape)\n",
        "\n",
        "#datax = datax.reshape(datax.shape[0],datax.shape[1], -1) #.swapaxes(1,2)\n",
        "print(\"DATAX SHAPE IN2\", datax.shape)\n",
        "datax = torch.tensor(datax)  # Convert to Torch Tensor\n",
        "\n",
        "traind1, testd1, traind2, testd2, traind3, tesdt3,traind4,testd4, trainy, testy = train_test_split(d1, d2, d3, d4, datay, test_size=0.15, random_state=42)\n",
        "\n",
        "train_data = ASLData(traind1, traind2, traind3, traind4, trainy)\n",
        "valid_data = ASLData(testd1, testd2, tesdt3, testd4, testy)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n",
        "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n",
        "\n",
        "model = ASLModel(0.2).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "sched = torch.optim.lr_scheduler.StepLR(opt, step_size=300, gamma=0.95)\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    model.train()\n",
        "    \n",
        "    train_loss_sum = 0.\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    train_bar = train_loader\n",
        "    for x1,x2,x3,x4,y in train_bar:\n",
        "        x1 = torch.Tensor(x1).float().to(device)\n",
        "        x2 = torch.Tensor(x2).float().to(device)\n",
        "        x3 = torch.Tensor(x3).float().to(device)\n",
        "        x4 = torch.Tensor(x4).float().to(device)\n",
        "\n",
        "        y = torch.Tensor(y).long().to(device)  \n",
        "        y_pred = model(x1,x2,x3,x4)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        train_loss_sum += loss.item()\n",
        "        train_correct += np.sum((np.argmax(y_pred.detach().cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "        train_total += 1\n",
        "        sched.step()\n",
        "        \n",
        "    val_loss_sum = 0.\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    model.eval()\n",
        "    for x1,x2,x3,x4,y in val_loader:\n",
        "        x1 = torch.Tensor(x1).float().to(device)\n",
        "        x2 = torch.Tensor(x2).float().to(device)\n",
        "        x3 = torch.Tensor(x3).float().to(device)\n",
        "        x4 = torch.Tensor(x4).float().to(device)\n",
        "        y = torch.Tensor(y).long().to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            y_pred = model(x1,x2,x3,x4)\n",
        "            loss = criterion(y_pred, y)\n",
        "            val_loss_sum += loss.item()\n",
        "            val_correct += np.sum((np.argmax(y_pred.cpu().numpy(), axis=1) == y.cpu().numpy()))\n",
        "            val_total += 1\n",
        "    print(f\"DIM={DIMS} FRAMES={FRAMES_OUT}, FEAT={PTS_IN_FRAME}\")                          \n",
        "    print(f\"Epoch:{i} > Train Loss: {(train_loss_sum/train_total):.04f}, Train Acc: {train_correct/len(train_data):0.04f}\")\n",
        "    print(f\"Epoch:{i} > Val Loss: {(val_loss_sum/val_total):.04f}, Val Acc: {val_correct/len(valid_data):0.04f}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# Save the pytorch model\n",
        "py_model_path = f\"{WORKING_DIR}/py_model.pt\"\n",
        "torch.save(model, py_model_path)\n",
        "\n",
        "print(\"#### ELAPSED TIME:\", time.perf_counter()-start_time)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-13T18:16:57.114241Z",
          "iopub.execute_input": "2023-03-13T18:16:57.115451Z",
          "iopub.status.idle": "2023-03-13T18:23:25.123968Z",
          "shell.execute_reply.started": "2023-03-13T18:16:57.115400Z",
          "shell.execute_reply": "2023-03-13T18:23:25.122556Z"
        },
        "trusted": true,
        "id": "RlbigS0EqZP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "abd9d96a-34d7-41e6-c9df-ac34cdecc2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++using CPU++++\n",
            "DATAX SHAPE IN (94477, 16, 115, 3)\n",
            "DATAX SHAPE IN2 (94477, 16, 115, 3)\n",
            "DIM=3 FRAMES=16, FEAT=115\n",
            "Epoch:0 > Train Loss: 3.2170, Train Acc: 0.2702\n",
            "Epoch:0 > Val Loss: 2.5417, Val Acc: 0.3978\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-59006d85676f>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}